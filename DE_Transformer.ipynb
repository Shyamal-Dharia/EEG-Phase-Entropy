{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "\n",
      "Source data: 918 samples (including any synthetic)\n",
      "Target data: 10 samples (single participant)\n",
      "PTE Batch Shape: torch.Size([32, 11, 5, 6, 6])\n",
      "PSD Batch Shape: torch.Size([32, 6, 5])\n",
      "Labels Batch Shape: torch.Size([32])\n",
      "Participant IDs Batch Shape: torch.Size([32])\n",
      "TARGET PTE Batch Shape: torch.Size([10, 11, 5, 6, 6])\n",
      "TARGET PSD Batch Shape: torch.Size([10, 6, 5])\n",
      "TARGET Labels Shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "def load_combined_data(\n",
    "    pte_directory,         # Directory containing the PTE .npz files\n",
    "    DE_directory,         # Directory containing the PSD .npz files\n",
    "    target_participant,\n",
    "    batch_size,\n",
    "    selected_classes=[\"alz\", \"ctrl\"],   # Which classes to load\n",
    "    selected_channels=None,             # Channels to select\n",
    "    apply_smote=True                    # Whether to apply SMOTE on the source data\n",
    "):\n",
    "    \"\"\"\n",
    "    Load data from separate directories for PTE and PSD, normalize, optionally apply SMOTE,\n",
    "    and create DataLoaders for source and target domains.\n",
    "\n",
    "    Args:\n",
    "        pte_directory (str):\n",
    "            Path to the directory containing .npz files with PTE data.\n",
    "        psd_directory (str):\n",
    "            Path to the directory containing .npz files with PSD data.\n",
    "        target_participant (int):\n",
    "            Subject ID to be used as the target domain.\n",
    "        batch_size (int):\n",
    "            Batch size for the source DataLoader.\n",
    "        selected_classes (list):\n",
    "            List of class labels to include (e.g., [\"alz\", \"ctrl\"]).\n",
    "        selected_channels (list or None):\n",
    "            List of channel names to select. If None, all channels are used.\n",
    "        apply_smote (bool):\n",
    "            If True, SMOTE is applied to the source data to handle class imbalance.\n",
    "\n",
    "    Returns:\n",
    "        source_dataloader (DataLoader):\n",
    "            DataLoader for the source domain with tuples: (pte_data, psd_data, labels, participant_ids).\n",
    "            If SMOTE is applied, synthetic samples are assigned `participant_id = -1`.\n",
    "        target_dataloader (DataLoader):\n",
    "            DataLoader for the target domain with tuples: (pte_data, psd_data, labels).\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Setup\n",
    "    # -------------------------------------------------------------------------\n",
    "    ch_names = [\n",
    "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz'\n",
    "    ]\n",
    "    label_map = {cname: idx for idx, cname in enumerate(selected_classes)}\n",
    "\n",
    "    if selected_channels is None:\n",
    "        selected_channels = ch_names\n",
    "\n",
    "    # Get channel indices\n",
    "    try:\n",
    "        selected_indices = [ch_names.index(ch) for ch in selected_channels]\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"One or more selected channels are not in ch_names: {e}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Collect and sort .npz files for PTE and PSD\n",
    "    # -------------------------------------------------------------------------\n",
    "    pte_files = [f for f in os.listdir(pte_directory) if f.endswith(\".npz\")]\n",
    "    psd_files = [f for f in os.listdir(DE_directory) if f.endswith(\".npz\")]\n",
    "\n",
    "    # Sort by subject ID (assuming filenames like 'sub-10_*_alz.npz')\n",
    "    def extract_sub_id(filename):\n",
    "        match = re.search(r'sub-(\\d+)_.*\\.npz', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "\n",
    "    pte_files_sorted = sorted(pte_files, key=extract_sub_id)\n",
    "    psd_files_sorted = sorted(psd_files, key=extract_sub_id)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3) Prepare lists for source and target data (with participant IDs)\n",
    "    # -------------------------------------------------------------------------\n",
    "    source_pte_data_list, source_pte_labels_list, source_pte_pid_list = [], [], []\n",
    "    target_pte_data_list, target_pte_labels_list = [], []\n",
    "    source_psd_data_list, source_psd_labels_list, source_psd_pid_list = [], [], []\n",
    "    target_psd_data_list, target_psd_labels_list = [], []\n",
    "\n",
    "    # Separate MinMaxScalers for PTE and PSD\n",
    "    pte_scaler = MinMaxScaler()\n",
    "    psd_scaler = MinMaxScaler()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Load PTE data\n",
    "    # -------------------------------------------------------------------------\n",
    "    for file in pte_files_sorted:\n",
    "        match = re.search(r'sub-(\\d+)_.*_(\\w+)\\.npz', file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subject_id = int(match.group(1))\n",
    "        label_str = match.group(2).lower()\n",
    "\n",
    "        # Skip if label not in selected classes\n",
    "        if label_str not in selected_classes:\n",
    "            continue\n",
    "\n",
    "        label_idx = label_map[label_str]\n",
    "        full_path = os.path.join(pte_directory, file)\n",
    "\n",
    "        data_npz = np.load(full_path, allow_pickle=True)\n",
    "        if \"pte_data\" not in data_npz:\n",
    "            continue  # no PTE data\n",
    "\n",
    "        pte_data = data_npz[\"pte_data\"]  # shape: [N, 12, 5, 19, 19] (example)\n",
    "\n",
    "        # Select channels in the 4th and 5th dimensions (adjust if shape differs)\n",
    "        # For example: pte_data[:, :11, :, selected_indices, :][:, :11, :, :, selected_indices]\n",
    "        # Modify as needed for your real data shape\n",
    "        pte_data = pte_data[:, :11, :, selected_indices, :][:, :11, :, :, selected_indices]\n",
    "\n",
    "        # Normalize across the last dimension\n",
    "        orig_shape = pte_data.shape\n",
    "        pte_data_flat = pte_data.reshape(-1, orig_shape[-1])\n",
    "        pte_data_flat = pte_scaler.fit_transform(pte_data_flat)\n",
    "        pte_data = pte_data_flat.reshape(orig_shape)\n",
    "\n",
    "        # Build labels\n",
    "        labels = np.full((pte_data.shape[0],), label_idx, dtype=int)\n",
    "\n",
    "        if subject_id == target_participant:\n",
    "            # Target domain\n",
    "            target_pte_data_list.append(pte_data)\n",
    "            target_pte_labels_list.append(labels)\n",
    "        else:\n",
    "            # Source domain\n",
    "            source_pte_data_list.append(pte_data)\n",
    "            source_pte_labels_list.append(labels)\n",
    "            # Store participant IDs (one per sample)\n",
    "            source_pte_pid_list.extend([subject_id] * pte_data.shape[0])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Load PSD data\n",
    "    # -------------------------------------------------------------------------\n",
    "    for file in psd_files_sorted:\n",
    "        match = re.search(r'sub-(\\d+)_.*_(\\w+)\\.npz', file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subject_id = int(match.group(1))\n",
    "        label_str = match.group(2).lower()\n",
    "\n",
    "        if label_str not in selected_classes:\n",
    "            continue\n",
    "\n",
    "        label_idx = label_map[label_str]\n",
    "        full_path = os.path.join(DE_directory, file)\n",
    "\n",
    "        data_npz = np.load(full_path, allow_pickle=True)\n",
    "        if \"DE_features\" not in data_npz:\n",
    "            continue\n",
    "\n",
    "        psd_data = data_npz[\"DE_features\"]  # shape: [N, 12, n_channels, n_bands], etc.\n",
    "        # print(psd_data.shape)\n",
    "        \n",
    "        # Select channels (assume 2nd dimension is channels):\n",
    "        # e.g., psd_data[:, :, selected_indices, :]\n",
    "        psd_data = psd_data[:, selected_indices, :]\n",
    "\n",
    "        # Normalize\n",
    "        orig_shape = psd_data.shape\n",
    "        psd_data_flat = psd_data.reshape(-1, orig_shape[-1])\n",
    "        psd_data_flat = psd_scaler.fit_transform(psd_data_flat)\n",
    "        psd_data = psd_data_flat.reshape(orig_shape)\n",
    "\n",
    "        labels = np.full((psd_data.shape[0],), label_idx, dtype=int)\n",
    "\n",
    "        if subject_id == target_participant:\n",
    "            target_psd_data_list.append(psd_data)\n",
    "            target_psd_labels_list.append(labels)\n",
    "        else:\n",
    "            source_psd_data_list.append(psd_data)\n",
    "            source_psd_labels_list.append(labels)\n",
    "            source_psd_pid_list.extend([subject_id] * psd_data.shape[0])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Concatenate source & target data\n",
    "    # -------------------------------------------------------------------------\n",
    "    def concat_arrays(array_list):\n",
    "        return np.concatenate(array_list, axis=0) if array_list else None\n",
    "\n",
    "    # Source PTE\n",
    "    source_pte_data = concat_arrays(source_pte_data_list)\n",
    "    source_pte_labels = concat_arrays(source_pte_labels_list)\n",
    "    source_pte_pids = np.array(source_pte_pid_list) if source_pte_pid_list else None\n",
    "\n",
    "    # Target PTE\n",
    "    target_pte_data = concat_arrays(target_pte_data_list)\n",
    "    target_pte_labels = concat_arrays(target_pte_labels_list)\n",
    "\n",
    "    # Source PSD\n",
    "    source_psd_data = concat_arrays(source_psd_data_list)\n",
    "    source_psd_labels = concat_arrays(source_psd_labels_list)\n",
    "    source_psd_pids = np.array(source_psd_pid_list) if source_psd_pid_list else None\n",
    "\n",
    "    # Target PSD\n",
    "    target_psd_data = concat_arrays(target_psd_data_list)\n",
    "    target_psd_labels = concat_arrays(target_psd_labels_list)\n",
    "\n",
    "    # print(\"\\nSource PTE data shape:\", source_pte_data.shape if source_pte_data is not None else None)\n",
    "    # print(\"Source PSD data shape:\", source_psd_data.shape if source_psd_data is not None else None)\n",
    "    # print(\"Target PTE data shape:\", target_pte_data.shape if target_pte_data is not None else None)\n",
    "    # print(\"Target PSD data shape:\", target_psd_data.shape if target_psd_data is not None else None)\n",
    "    \n",
    "    # Quick sanity check\n",
    "    if (\n",
    "        source_pte_data is None or source_pte_labels is None or\n",
    "        source_psd_data is None or source_psd_labels is None\n",
    "    ):\n",
    "        raise ValueError(\"No valid source data found (PTE or PSD).\")\n",
    "    if (\n",
    "        target_pte_data is None or target_pte_labels is None or\n",
    "        target_psd_data is None or target_psd_labels is None\n",
    "    ):\n",
    "        raise ValueError(\"No valid target data found (PTE or PSD).\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 7) Optionally apply SMOTE on the source data\n",
    "    # -------------------------------------------------------------------------\n",
    "    if apply_smote:\n",
    "        print(\"\\nApplying SMOTE to the source data...\")\n",
    "\n",
    "        # Flatten PTE and PSD for concatenation\n",
    "        orig_pte_shape = source_pte_data.shape\n",
    "        orig_psd_shape = source_psd_data.shape\n",
    "\n",
    "        pte_flat = source_pte_data.reshape(orig_pte_shape[0], -1)\n",
    "        psd_flat = source_psd_data.reshape(orig_psd_shape[0], -1)\n",
    "\n",
    "        # Concatenate features for SMOTE\n",
    "        combined_features = np.concatenate([pte_flat, psd_flat], axis=1)\n",
    "        combined_labels = source_pte_labels  # same as PSD labels in your setup\n",
    "\n",
    "        # SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        combined_resampled, labels_resampled = sm.fit_resample(combined_features, combined_labels)\n",
    "\n",
    "        # Count how many new (synthetic) samples were added\n",
    "        num_original = combined_features.shape[0]\n",
    "        num_new = combined_resampled.shape[0] - num_original\n",
    "        print(f\"SMOTE created {num_new} synthetic samples.\")\n",
    "\n",
    "        # Split back into PTE and PSD\n",
    "        pte_dim = pte_flat.shape[1]\n",
    "        psd_dim = psd_flat.shape[1]\n",
    "\n",
    "        pte_resampled = combined_resampled[:, :pte_dim]\n",
    "        psd_resampled = combined_resampled[:, pte_dim:]\n",
    "\n",
    "        # Reshape back\n",
    "        source_pte_data = pte_resampled.reshape(\n",
    "            -1,\n",
    "            orig_pte_shape[1],\n",
    "            orig_pte_shape[2],\n",
    "            orig_pte_shape[3],\n",
    "            orig_pte_shape[4]\n",
    "        )\n",
    "        source_psd_data = psd_resampled.reshape(\n",
    "            -1,\n",
    "            orig_psd_shape[1],\n",
    "            orig_psd_shape[2]\n",
    "        )\n",
    "\n",
    "        # Update labels\n",
    "        source_pte_labels = labels_resampled\n",
    "        source_psd_labels = labels_resampled\n",
    "\n",
    "        # For new (synthetic) samples, assign participant_id = -1 so they can be excluded in threshold tuning\n",
    "        pid_extended = np.concatenate([\n",
    "            source_pte_pids,\n",
    "            np.full(num_new, -1, dtype=int)\n",
    "        ])\n",
    "        source_pte_pids = pid_extended\n",
    "        source_psd_pids = pid_extended\n",
    "    else:\n",
    "        print(\"\\nSMOTE not applied to the source data.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 8) Convert to PyTorch Tensors\n",
    "    # -------------------------------------------------------------------------\n",
    "    def to_tensor(data, dtype=torch.float):\n",
    "        return torch.from_numpy(data).type(dtype)\n",
    "\n",
    "    source_pte_data_tensor = to_tensor(source_pte_data, torch.float)\n",
    "    source_psd_data_tensor = to_tensor(source_psd_data, torch.float)\n",
    "    source_labels_tensor = to_tensor(source_pte_labels, torch.long)\n",
    "    source_pid_tensor = to_tensor(source_pte_pids, torch.long)\n",
    "\n",
    "    target_pte_data_tensor = to_tensor(target_pte_data, torch.float)\n",
    "    target_psd_data_tensor = to_tensor(target_psd_data, torch.float)\n",
    "    target_labels_tensor = to_tensor(target_pte_labels, torch.long)\n",
    "    # Target doesn't need a participant ID (single participant).\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 9) Build TensorDatasets & DataLoaders\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Source dataset has participant IDs so we can do threshold tuning\n",
    "    source_dataset = TensorDataset(\n",
    "        source_pte_data_tensor,\n",
    "        source_psd_data_tensor,\n",
    "        source_labels_tensor,\n",
    "        source_pid_tensor\n",
    "    )\n",
    "    target_dataset = TensorDataset(\n",
    "        target_pte_data_tensor,\n",
    "        target_psd_data_tensor,\n",
    "        target_labels_tensor\n",
    "    )\n",
    "\n",
    "    source_dataloader = DataLoader(\n",
    "        source_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    target_dataloader = DataLoader(\n",
    "        target_dataset, batch_size=len(target_dataset), shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    return source_dataloader, target_dataloader\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Example usage\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    selected_channels = ['O2', 'C3', 'C4', 'Cz', 'T5', 'T6']\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=6,\n",
    "        batch_size=32,\n",
    "        selected_classes=[\"ctrl\", \"alz\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True    # Control SMOTE usage here\n",
    "    )\n",
    "    print(f\"\\nSource data: {len(source_dataloader.dataset)} samples (including any synthetic)\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples (single participant)\")\n",
    "\n",
    "    # Check a sample from the source DataLoader\n",
    "    for pte_batch, psd_batch, labels_batch, pid_batch in source_dataloader:\n",
    "        print(\"PTE Batch Shape:\", pte_batch.shape)\n",
    "        print(\"PSD Batch Shape:\", psd_batch.shape)\n",
    "        print(\"Labels Batch Shape:\", labels_batch.shape)\n",
    "        print(\"Participant IDs Batch Shape:\", pid_batch.shape)\n",
    "        break\n",
    "\n",
    "    # Check the target DataLoader\n",
    "    for pte_batch, psd_batch, labels_batch in target_dataloader:\n",
    "        print(\"TARGET PTE Batch Shape:\", pte_batch.shape)\n",
    "        print(\"TARGET PSD Batch Shape:\", psd_batch.shape)\n",
    "        print(\"TARGET Labels Shape:\", labels_batch.shape)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from itertools import cycle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    source_dataloader,\n",
    "    target_dataloader,\n",
    "    criterion_label,\n",
    "    criterion_domain,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    device=\"cuda\",\n",
    "    alpha_entropy = 0.01\n",
    "):\n",
    "   \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    accuracy_history = []\n",
    "    domain_accuracy_history = []\n",
    "\n",
    "    # Create an infinite iterator over the target dataloader\n",
    "    target_iter = cycle(target_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_domain_correct = 0\n",
    "        total_domain_samples = 0\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "\n",
    "        for i, batch_src in enumerate(source_dataloader):\n",
    "\n",
    "            if len(batch_src) == 4:\n",
    "                source_pte, source_psd, source_labels, _ = batch_src\n",
    "            else:\n",
    "                source_pte, source_psd, source_labels = batch_src\n",
    "\n",
    "            # Grab target batch\n",
    "            batch_tgt = next(target_iter)\n",
    "            if len(batch_tgt) == 3:\n",
    "                target_pte, target_psd, _ = batch_tgt\n",
    "            else:\n",
    "                # e.g., (target_pte, target_psd) if unlabeled\n",
    "                target_pte, target_psd = batch_tgt\n",
    "\n",
    "\n",
    "            # Move data to device\n",
    "            source_pte = source_pte.to(device)\n",
    "            source_psd = source_psd.to(device)\n",
    "            source_labels = source_labels.to(device)\n",
    "\n",
    "            target_pte = target_pte.to(device)\n",
    "            target_psd = target_psd.to(device)\n",
    "\n",
    "\n",
    "            label_preds, _ = model(\n",
    "                source_pte, source_psd\n",
    "            )\n",
    " \n",
    "            label_preds_target, _ = model(\n",
    "                target_pte, target_psd\n",
    "            )\n",
    "\n",
    "\n",
    "            loss_label = criterion_label(label_preds, source_labels)\n",
    "\n",
    "\n",
    "            total_loss = loss_label\n",
    "            # Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # -------------------------------\n",
    "            # Update Metrics\n",
    "            # -------------------------------\n",
    "            epoch_loss += loss_label.item()\n",
    "\n",
    "            # Label prediction accuracy (source)\n",
    "            _, predicted = torch.max(label_preds, dim=1)\n",
    "            correct = (predicted == source_labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += source_labels.size(0)\n",
    "\n",
    "\n",
    "        epoch_accuracy = 100.0 * total_correct / total_samples if total_samples > 0 else 0\n",
    "        epoch_domain_accuracy = 100.0 * total_domain_correct / total_domain_samples if total_domain_samples > 0 else 0\n",
    "\n",
    "        accuracy_history.append(epoch_accuracy)\n",
    "        domain_accuracy_history.append(epoch_domain_accuracy)\n",
    "\n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        #       f\"Label Acc: {epoch_accuracy:.2f}%, \"\n",
    "        #       f\"Domain Acc: {epoch_domain_accuracy:.2f}%\")\n",
    "\n",
    "    return accuracy_history, domain_accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def test_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    criterion_label: torch.nn.Module,\n",
    "    device: str = \"cuda\",\n",
    "    num_classes: int = 2,\n",
    "    alz_threshold: float = 0.4\n",
    ") -> Tuple[float, float, float, np.ndarray, np.ndarray, np.ndarray, float, int]:\n",
    "  \n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds_softmax = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            # ------------------------------------------------------\n",
    "            # 1) Handle batch size: 3 items or 4 items\n",
    "            # ------------------------------------------------------\n",
    "            # If your test dataloader returns 4 items (pte_batch, psd_batch, labels, pid):\n",
    "            if len(batch) == 4:\n",
    "                pte_batch, psd_batch, labels, _ = batch\n",
    "            elif len(batch) == 3:\n",
    "                pte_batch, psd_batch, labels = batch\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"DataLoader should return (pte_batch, psd_batch, labels) or 4 items. Got {len(batch)} items.\"\n",
    "                )\n",
    "\n",
    "            # Move data to device\n",
    "            pte_batch = pte_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "          \n",
    "            label_preds, _ = model(pte_batch, psd_batch)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 4) Compute classification loss\n",
    "            # ------------------------------------------------------\n",
    "            loss = criterion_label(label_preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 5) Softmax for predicted probabilities\n",
    "            # ------------------------------------------------------\n",
    "            softmax_output = F.softmax(label_preds, dim=1)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 6) Hard predictions\n",
    "            # ------------------------------------------------------\n",
    "            _, predicted = torch.max(softmax_output, dim=1)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 7) Store predictions/probabilities/labels\n",
    "            # ------------------------------------------------------\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_preds_softmax.extend(softmax_output.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 8) Compute average loss\n",
    "    # ------------------------------------------------------\n",
    "    if len(test_dataloader) > 0:\n",
    "        avg_loss = total_loss / len(test_dataloader)\n",
    "    else:\n",
    "        avg_loss = 0.0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 9) Check if the participant has a single ground-truth label\n",
    "    # ------------------------------------------------------\n",
    "    all_labels = np.array(all_labels)\n",
    "    unique_lbls = np.unique(all_labels)\n",
    "    if len(unique_lbls) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Participant's test set has multiple labels: {unique_lbls}. \"\n",
    "            f\"Expected exactly 1 label per participant.\"\n",
    "        )\n",
    "\n",
    "    participant_true_label = unique_lbls[0]\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 10) Participant-level prediction\n",
    "    # ------------------------------------------------------\n",
    "    all_preds = np.array(all_preds)\n",
    "    alz_count = np.sum(all_preds == 1)\n",
    "    alz_ratio = alz_count / max(len(all_preds), 1)\n",
    "\n",
    "    if alz_ratio >= alz_threshold:\n",
    "        participant_pred_label = 1\n",
    "    else:\n",
    "        participant_pred_label = 0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 11) Construct participant-level confusion matrix\n",
    "    # ------------------------------------------------------\n",
    "    participant_conf_mat = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    participant_conf_mat[participant_true_label, participant_pred_label] += 1\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 12) Participant-level accuracy & F1\n",
    "    # ------------------------------------------------------\n",
    "    participant_acc = 100.0 if (participant_true_label == participant_pred_label) else 0.0\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    participant_f1 = f1_score(\n",
    "        [participant_true_label],\n",
    "        [participant_pred_label],\n",
    "        average='macro',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 13) Print debug info\n",
    "    # ------------------------------------------------------\n",
    "    print(f\"\\nParticipant True Label: {participant_true_label}\")\n",
    "    print(f\" -> #Predicted ALZ samples: {alz_count} / {len(all_preds)} = {alz_ratio:.2f}\")\n",
    "    print(f\" -> Threshold = {alz_threshold}; Final Participant Prediction: {participant_pred_label}\")\n",
    "    print(f\" -> Participant Accuracy: {participant_acc:.2f}%\")\n",
    "    print(f\" -> Participant F1 (Macro): {participant_f1:.4f}\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 14) Return results including alz_ratio and true label\n",
    "    # ------------------------------------------------------\n",
    "    all_preds_softmax = np.array(all_preds_softmax)  # shape: [N, num_classes]\n",
    "    return (\n",
    "        avg_loss,\n",
    "        participant_acc,\n",
    "        participant_f1,\n",
    "        participant_conf_mat,\n",
    "        all_preds_softmax,\n",
    "        all_labels,\n",
    "        alz_ratio,\n",
    "        participant_true_label\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def tune_threshold_on_source(\n",
    "    model,\n",
    "    source_dataloader,\n",
    "    device=\"cuda\",\n",
    "    thresholds=[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    num_classes=2\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    sample_preds = defaultdict(list)\n",
    "    participant_label = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in source_dataloader:\n",
    "            # If your source dataloader returns 4 items, including participant_id\n",
    "            if len(batch) == 4:\n",
    "                pte_batch, psd_batch, labels, pid_batch = batch\n",
    "            else:\n",
    "                raise ValueError(\"Expected Dataloader to return (pte, psd, labels, pid).\")\n",
    "\n",
    "            pte_batch = pte_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pid_batch = pid_batch.to(device)\n",
    "\n",
    "            # Forward pass (disable GRL in inference by setting lambda_=0)\n",
    "            label_preds, _ = model(pte_batch, psd_batch)\n",
    "\n",
    "            # Convert predictions to class=0/1\n",
    "            softmax_output = F.softmax(label_preds, dim=1)\n",
    "            _, predicted = torch.max(softmax_output, dim=1)\n",
    "\n",
    "            # Move to CPU\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            pid_batch = pid_batch.cpu().numpy()\n",
    "\n",
    "            # Store predictions for each participant\n",
    "            for pred, true_lbl, pid in zip(predicted, labels, pid_batch):\n",
    "                sample_preds[pid].append(pred)\n",
    "                # We assume all samples from participant pid share the same ground-truth label:\n",
    "                if pid not in participant_label:\n",
    "                    participant_label[pid] = true_lbl\n",
    "                else:\n",
    "                    # Optionally check that the label is consistent\n",
    "                    if participant_label[pid] != true_lbl:\n",
    "                        raise ValueError(f\"Inconsistent labels for participant {pid} in source data.\")\n",
    "\n",
    "    # Now we have sample-level predictions per participant. We'll try each threshold.\n",
    "    best_threshold = None\n",
    "    best_metric_val = -1.0\n",
    "\n",
    "    for thr in thresholds:\n",
    "        # For each threshold, generate participant-level predictions\n",
    "        # by counting how many samples predicted as class=1\n",
    "        part_level_preds = []\n",
    "        part_level_trues = []\n",
    "\n",
    "        for pid, preds_list in sample_preds.items():\n",
    "            true_lbl = participant_label[pid]\n",
    "            n_alz = sum([p == 1 for p in preds_list])\n",
    "            ratio = float(n_alz) / len(preds_list)\n",
    "            # Decide participant-level label\n",
    "            if ratio >= thr:\n",
    "                participant_pred = 1\n",
    "            else:\n",
    "                participant_pred = 0\n",
    "            \n",
    "            part_level_preds.append(participant_pred)\n",
    "            part_level_trues.append(true_lbl)\n",
    "\n",
    "        # Evaluate participant-level performance\n",
    "        # For example, we use F1 (macro):\n",
    "        f1 = f1_score(part_level_trues, part_level_preds, average='macro', zero_division=0)\n",
    "        acc = accuracy_score(part_level_trues, part_level_preds)\n",
    "\n",
    "        print(f\"[Threshold {thr}] -> F1={f1:.4f} | Acc={acc:.4f}\")\n",
    "\n",
    "        # Suppose we pick the threshold that maximizes participant-level F1\n",
    "        if f1 > best_metric_val:\n",
    "            best_metric_val = f1\n",
    "            best_threshold = thr\n",
    "\n",
    "    print(f\"\\n[Best Threshold] = {best_threshold} with F1={best_metric_val:.4f}\")\n",
    "    return best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Prediction Shape: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "# Define the Multi-Head Cross Attention Module\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "\n",
    "        super(MultiHeadCrossAttention, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
    "\n",
    "        # Apply MultiheadAttention; note that nn.MultiheadAttention expects inputs of shape (batch, seq, feature)\n",
    "        attn_output, attn_weights = self.multihead_attn(query, key, value, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        # Apply dropout\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        \n",
    "        # Add & Norm\n",
    "        output = self.layer_norm(query + attn_output)\n",
    "        \n",
    "        return output, attn_weights\n",
    "\n",
    "# Existing Transformer Classes (PteTransformer and PsdTransformer)\n",
    "class PteTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n",
    "        super(PteTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.position_encoding = nn.Parameter(torch.randn(1, 11, input_dim), requires_grad=True)\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)  # Project to desired output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, original_features)\n",
    "        \"\"\"\n",
    "        b = x.shape[0]\n",
    "        # Reshape to (batch_size, 11, input_dim//11) assuming input_dim is divisible by 11\n",
    "        x = x.reshape(b, 11, -1)\n",
    "        x = self.position_encoding + x  # (batch_size, 11, input_dim)\n",
    "        x = self.transformer(x)         # (batch_size, 11, input_dim)\n",
    "        x = self.output_layer(x)        # (batch_size, 11, output_dim)\n",
    "        return x\n",
    "\n",
    "class PsdTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n",
    "        super(PsdTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)  # Project to desired output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, original_features)\n",
    "        \"\"\"\n",
    "        # Assuming x is already of shape (batch_size, T_e, input_dim)\n",
    "        x = self.transformer(x)         # (batch_size, T_e, input_dim)\n",
    "        x = self.output_layer(x)        # (batch_size, T_e, output_dim)\n",
    "        return x\n",
    "\n",
    "# Updated Final Model with Multi-Head Cross Attention and DANN Components\n",
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pte_input_dim, pte_hidden_dim, pte_num_layers, pte_num_heads, pte_output_dim, pte_dropout,\n",
    "                 psd_input_dim, psd_hidden_dim, psd_num_layers, psd_num_heads, psd_output_dim, psd_dropout,\n",
    "                 cross_d_model, cross_num_heads,\n",
    "                 ):\n",
    "        super(FinalModel, self).__init__() \n",
    "\n",
    "        # Initialize PTE and PSD Transformers\n",
    "        self.pte_transformer = PteTransformer(\n",
    "            input_dim=pte_input_dim,\n",
    "            hidden_dim=pte_hidden_dim,\n",
    "            num_layers=pte_num_layers,\n",
    "            num_heads=pte_num_heads,\n",
    "            output_dim=pte_output_dim,\n",
    "            dropout=pte_dropout\n",
    "        )\n",
    "        \n",
    "        self.psd_transformer = PsdTransformer(\n",
    "            input_dim=psd_input_dim,\n",
    "            hidden_dim=psd_hidden_dim,\n",
    "            num_layers=psd_num_layers,\n",
    "            num_heads=psd_num_heads,\n",
    "            output_dim=psd_output_dim,\n",
    "            dropout=psd_dropout\n",
    "        )\n",
    "        \n",
    "        # Initialize Multi-Head Cross-Attention\n",
    "        self.cross_attention = MultiHeadCrossAttention(\n",
    "            d_model=cross_d_model,\n",
    "            num_heads=cross_num_heads,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        # Final Classifier for Label Prediction\n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(768, 2)  # Adjust based on the sequence length (12 here)\n",
    "        )\n",
    "        \n",
    "    def forward(self, pte_input, psd_input):\n",
    "\n",
    "        # Pass through respective transformers\n",
    "        # pte_encoded = self.pte_transformer(pte_input)  # (batch_size, T_pte=11, pte_output_dim=128)\n",
    "        psd_encoded = self.psd_transformer(psd_input)  # (batch_size, T_psd=6, psd_output_dim=128)\n",
    "        \n",
    "        \n",
    "        # Label Prediction\n",
    "        label_pred = self.final_classifier(psd_encoded)  # (batch_size, 2)\n",
    "        \n",
    "        \n",
    "        return label_pred, None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input tensors\n",
    "    # Adjust the shapes based on your actual data\n",
    "    # For illustration, assuming:\n",
    "    # pte_input has 11 time steps, each with (input_dim_pte / 11) features\n",
    "    x_1 = torch.randn(32, 11 * 5 * 6 * 6)  # (batch_size, pte_original_features)\n",
    "    # psd_input has sequence length 6 with 5 features each\n",
    "    x_2 = torch.randn(32, 6, 5)            # (batch_size, psd_seq_length, psd_original_features)\n",
    "    \n",
    "    # Define the model parameters\n",
    "    input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "    hidden_dim_pte = 512\n",
    "    num_layers_pte = 2\n",
    "    num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "    output_dim_pte = 128\n",
    "    dropout_pte = 0.1\n",
    "    \n",
    "    input_dim_psd = 5\n",
    "    hidden_dim_psd = 512\n",
    "    num_layers_psd = 2\n",
    "    num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "    output_dim_psd = 128\n",
    "    dropout_psd = 0.1\n",
    "    \n",
    "    cross_d_model = 128\n",
    "    cross_num_heads = 8   # Number of heads in cross-attention\n",
    "    \n",
    "    # Initialize the DANN model\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "    \n",
    "    # Example forward pass\n",
    "    label_pred, _ = model(x_1, x_2)\n",
    "    print(\"Label Prediction Shape:\", label_pred.shape)        # Expected: (32, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set the seed for PyTorch (both CPU and CUDA)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "    # Ensure deterministic behavior in PyTorch (if applicable)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set the seed for sklearn (via check_random_state)\n",
    "    _ = check_random_state(seed)\n",
    "\n",
    "    print(f\"Seed set to: {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 42\n",
      "\n",
      "===== Training for participant: 1 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 72 synthetic samples.\n",
      "Source data: 920 samples\n",
      "Target data: 9 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Label Accuracy: 71.43%\n",
      "[Threshold 0.2] -> F1=0.7111 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8610 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8610\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 6 / 9 = 0.67\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.54%\n",
      "[Threshold 0.2] -> F1=0.6771 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.7611 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 13 = 0.62\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 76 synthetic samples.\n",
      "Source data: 928 samples\n",
      "Target data: 5 samples\n",
      "Final Training Label Accuracy: 68.42%\n",
      "[Threshold 0.2] -> F1=0.6908 | Acc=0.7231\n",
      "[Threshold 0.3] -> F1=0.8397 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 5 = 0.20\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 66.18%\n",
      "[Threshold 0.2] -> F1=0.7400 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8614 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8769 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8769\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.20%\n",
      "[Threshold 0.2] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8610 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8461 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8610\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 13 = 0.62\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 6 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "Source data: 918 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 68.42%\n",
      "[Threshold 0.2] -> F1=0.7871 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 4 / 10 = 0.40\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 7 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 68.08%\n",
      "[Threshold 0.2] -> F1=0.7688 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.9077 | Acc=0.9077\n",
      "[Threshold 0.5] -> F1=0.8769 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.9077\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 12 = 0.75\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 8 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.31%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.9228 | Acc=0.9231\n",
      "[Threshold 0.5] -> F1=0.8615 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.9228\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 9 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "Source data: 918 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 65.74%\n",
      "[Threshold 0.2] -> F1=0.6259 | Acc=0.6769\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8153 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8153\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 5 / 10 = 0.50\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 60 synthetic samples.\n",
      "Source data: 896 samples\n",
      "Target data: 21 samples\n",
      "Final Training Label Accuracy: 68.97%\n",
      "[Threshold 0.2] -> F1=0.7358 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8767 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8767\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 3 / 21 = 0.14\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 11 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 71.32%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8610 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8922 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8922\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 12 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 65.85%\n",
      "[Threshold 0.2] -> F1=0.7167 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.7490 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.7998 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8301\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 14 = 0.57\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 13 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.64%\n",
      "[Threshold 0.2] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8461 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8919\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 13 = 0.92\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 14 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 69.64%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 15 = 0.67\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 67.52%\n",
      "[Threshold 0.2] -> F1=0.8050 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 5 / 15 = 0.33\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 16 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 65 synthetic samples.\n",
      "Source data: 906 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 67.97%\n",
      "[Threshold 0.2] -> F1=0.6699 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.7400 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8153 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8293\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 17 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.52%\n",
      "[Threshold 0.2] -> F1=0.7756 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.7833 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.8308 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8458 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8458\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 14 = 0.93\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 18 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 65.85%\n",
      "[Threshold 0.2] -> F1=0.6564 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7436 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.7657 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7983 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7983\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 19 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 68.19%\n",
      "[Threshold 0.2] -> F1=0.7688 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8153 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8452\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 15 = 0.47\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.75%\n",
      "[Threshold 0.2] -> F1=0.6834 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8610 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8769 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8769\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 14 = 0.14\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 21 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 70.65%\n",
      "[Threshold 0.2] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8461 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8755\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 15 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 22 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.65%\n",
      "[Threshold 0.2] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8614 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8153 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8755\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 23 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.87%\n",
      "[Threshold 0.2] -> F1=0.8018 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8199 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8458 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 13 = 0.08\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 24 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 65.62%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8922 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8461 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8922\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 25 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 68.19%\n",
      "[Threshold 0.2] -> F1=0.7871 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8767 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8769 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8769\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 11 = 0.64\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 26 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.97%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8610 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8922 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8922\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 14 = 0.57\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 27 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.08%\n",
      "[Threshold 0.2] -> F1=0.6771 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.7436 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7992 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7992\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 28 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.97%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8923 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8923\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 13 = 0.62\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 29 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 69.42%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 30 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 72 synthetic samples.\n",
      "Source data: 920 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 68.75%\n",
      "[Threshold 0.2] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8458 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.7992 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8458\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 31 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 62 synthetic samples.\n",
      "Source data: 900 samples\n",
      "Target data: 19 samples\n",
      "Final Training Label Accuracy: 68.97%\n",
      "[Threshold 0.2] -> F1=0.7688 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8767 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8767\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 19 = 0.53\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 32 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.87%\n",
      "[Threshold 0.2] -> F1=0.7111 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.7257 | Acc=0.7385\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 13 = 0.85\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 33 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 68.64%\n",
      "[Threshold 0.2] -> F1=0.7358 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8308 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8308\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 4 / 11 = 0.36\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 34 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 65 synthetic samples.\n",
      "Source data: 906 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 69.08%\n",
      "[Threshold 0.2] -> F1=0.7027 | Acc=0.7231\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8767 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8767\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 16 = 0.62\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 35 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 68.53%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8153 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8762\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 12 = 0.92\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 36 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.64%\n",
      "[Threshold 0.2] -> F1=0.7027 | Acc=0.7231\n",
      "[Threshold 0.3] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8458 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8610 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8610\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 14 = 0.57\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 37 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 68.08%\n",
      "[Threshold 0.2] -> F1=0.7111 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 12 = 0.08\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 38 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 70.31%\n",
      "[Threshold 0.2] -> F1=0.7834 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8762\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 14 = 0.21\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 39 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 70.54%\n",
      "[Threshold 0.2] -> F1=0.6972 | Acc=0.7231\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8767 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8615 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8767\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 14 = 0.93\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 40 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 66.96%\n",
      "[Threshold 0.2] -> F1=0.7791 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8397 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8150 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8416\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 5 / 16 = 0.31\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 41 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.63%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8452\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 5 / 14 = 0.36\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 42 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 67.08%\n",
      "[Threshold 0.2] -> F1=0.5910 | Acc=0.6615\n",
      "[Threshold 0.3] -> F1=0.6483 | Acc=0.6923\n",
      "[Threshold 0.4] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.8267 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8267\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 16 = 0.06\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 43 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.87%\n",
      "[Threshold 0.2] -> F1=0.7688 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.7804 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7983 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.8153 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8153\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 13 = 0.15\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 44 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 70.42%\n",
      "[Threshold 0.2] -> F1=0.6616 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 14 = 0.07\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 45 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 68.08%\n",
      "[Threshold 0.2] -> F1=0.7834 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8397 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8431\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 14 = 0.29\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 46 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 71.21%\n",
      "[Threshold 0.2] -> F1=0.7834 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 12 = 0.33\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 47 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 66.41%\n",
      "[Threshold 0.2] -> F1=0.6483 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8914 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8914\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 13 = 0.46\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 48 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 66.52%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 49 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.98%\n",
      "[Threshold 0.2] -> F1=0.7688 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8306 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8000 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8582\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.64%\n",
      "[Threshold 0.2] -> F1=0.6972 | Acc=0.7231\n",
      "[Threshold 0.3] -> F1=0.7257 | Acc=0.7385\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 13 = 0.46\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 51 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 70.76%\n",
      "[Threshold 0.2] -> F1=0.7645 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.9066 | Acc=0.9077\n",
      "[Threshold 0.5] -> F1=0.8461 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.9066\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 52 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 71.99%\n",
      "[Threshold 0.2] -> F1=0.7252 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8452 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8452\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 53 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.19%\n",
      "[Threshold 0.2] -> F1=0.7834 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7846 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7969\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 13 = 0.23\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 54 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 72.10%\n",
      "[Threshold 0.2] -> F1=0.8018 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 13 = 0.08\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 55 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 71.99%\n",
      "[Threshold 0.2] -> F1=0.8050 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8461 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8461\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 13 = 0.23\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 56 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 71.32%\n",
      "[Threshold 0.2] -> F1=0.7308 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8615 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8615\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 13 = 0.92\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 57 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.20%\n",
      "[Threshold 0.2] -> F1=0.7252 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8397 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.9059 | Acc=0.9077\n",
      "[Threshold 0.5] -> F1=0.8458 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.9059\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 58 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 71.54%\n",
      "[Threshold 0.2] -> F1=0.5910 | Acc=0.6615\n",
      "[Threshold 0.3] -> F1=0.6483 | Acc=0.6923\n",
      "[Threshold 0.4] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 12 = 0.17\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 59 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.97%\n",
      "[Threshold 0.2] -> F1=0.6483 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7756 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 13 = 0.46\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 66.41%\n",
      "[Threshold 0.2] -> F1=0.6259 | Acc=0.6769\n",
      "[Threshold 0.3] -> F1=0.7580 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 61 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.19%\n",
      "[Threshold 0.2] -> F1=0.6616 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.7688 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7804 | Acc=0.7846\n",
      "[Threshold 0.5] -> F1=0.8143 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8143\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 13 = 0.31\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 62 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 72.88%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8610 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8767 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8767\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 5 / 14 = 0.36\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 63 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.75%\n",
      "[Threshold 0.2] -> F1=0.6616 | Acc=0.7077\n",
      "[Threshold 0.3] -> F1=0.7358 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8452 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 13 = 0.46\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 64 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.75%\n",
      "[Threshold 0.2] -> F1=0.7252 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.8397 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8614\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 14 = 0.43\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 65 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.52%\n",
      "[Threshold 0.2] -> F1=0.7645 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8610 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8610\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 14 = 0.29\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statistics import mode, StatisticsError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize accumulators for participant-level metrics\n",
    "participant_scores = []       # Aggregated scores (e.g., alz_ratio) per participant\n",
    "participant_labels_list = []  # Ground-truth labels per participant\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)  # Ensure reproducibility\n",
    "\n",
    "# Define the model parameters\n",
    "# Define the model parameters\n",
    "input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "hidden_dim_pte = 512\n",
    "num_layers_pte = 2\n",
    "num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "output_dim_pte = 128\n",
    "dropout_pte = 0.4\n",
    "\n",
    "input_dim_psd = 5\n",
    "hidden_dim_psd = 512\n",
    "num_layers_psd = 2\n",
    "num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "output_dim_psd = 128\n",
    "dropout_psd = 0.4\n",
    "\n",
    "cross_d_model = 128\n",
    "cross_num_heads = 8   # Number of heads in cross-attention\n",
    "\n",
    "# Accumulators for overall metrics\n",
    "all_acc = []\n",
    "all_f1 = []\n",
    "all_conf = []\n",
    "\n",
    "# For global sample-level AUC\n",
    "global_probs = []\n",
    "global_labels = []\n",
    "\n",
    "best_thresholds = []  # Store the chosen threshold for each participant\n",
    "\n",
    "for participant in range(1, 66):\n",
    "    print(f\"\\n===== Training for participant: {participant} =====\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 1) Initialize the model\n",
    "    # --------------------------\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 2) Load data\n",
    "    #    (Ensure your source_dataloader returns (pte, psd, labels, participant_id))\n",
    "    # --------------------------\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=participant,\n",
    "        batch_size=128,\n",
    "        selected_classes=[\"ctrl\", \"alz\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Source data: {len(source_dataloader.dataset)} samples\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 3) Define Loss & Optimizer\n",
    "    # --------------------------\n",
    "    class_weights = torch.tensor([0.8, 1.0], dtype=torch.float32, device=device)\n",
    "    criterion_label = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_domain = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5) # 8e-5\n",
    "\n",
    "    # --------------------------\n",
    "    # 4) Train Model (DANN)\n",
    "    # --------------------------\n",
    "    num_epochs = 100\n",
    "    lambda_grl = 0.0  # or use a schedule\n",
    "    label_acc_history, domain_acc_history = train_model(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        target_dataloader=target_dataloader,\n",
    "        criterion_label=criterion_label,\n",
    "        criterion_domain=criterion_domain,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device    )\n",
    "    print(f\"Final Training Label Accuracy: {label_acc_history[-1]:.2f}%\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 5) Tune Threshold on Source\n",
    "    # --------------------------\n",
    "    # This step requires that your source_dataloader yield participant IDs\n",
    "    thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n",
    "    best_thr = tune_threshold_on_source(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        device=device,\n",
    "        thresholds=thresholds_to_try,\n",
    "        num_classes=2\n",
    "    )\n",
    "    best_thresholds.append(best_thr)\n",
    "\n",
    "    # --------------------------\n",
    "    # 6) Test on Target\n",
    "    # --------------------------\n",
    "    # We use the threshold we found above\n",
    "    test_loss, test_acc, test_f1_score_part, participant_conf_mat, \\\n",
    "        participant_preds_softmax, participant_labels, alz_ratio, participant_true_label = test_model(\n",
    "            model=model,\n",
    "            test_dataloader=target_dataloader,\n",
    "            criterion_label=criterion_label,\n",
    "            device=device,\n",
    "            num_classes=2,\n",
    "            alz_threshold=best_thr,  # <--- using the best threshold\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 7) Store Participant-Level Metrics\n",
    "    # --------------------------\n",
    "    all_acc.append(test_acc)\n",
    "    all_f1.append(test_f1_score_part)\n",
    "    all_conf.append(participant_conf_mat)\n",
    "\n",
    "    global_probs.append(participant_preds_softmax)\n",
    "    global_labels.append(participant_labels)\n",
    "\n",
    "    # Collect participant-level score and label for ROC AUC\n",
    "    participant_scores.append(alz_ratio)               # Using alz_ratio as the score\n",
    "    participant_labels_list.append(participant_true_label)  # Ground-truth label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Final Summary ==================\n",
      "Overall Participant-Level Accuracy: 80.00%\n",
      "Overall Participant-Level F1 (Macro): 0.8000\n",
      "Participant-Level Confusion Matrix (summed):\n",
      "[[24  5]\n",
      " [ 8 28]]\n",
      "\n",
      "Best thresholds chosen per participant:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.4, 0.4, 0.5, 0.4, 0.5, 0.4, 0.4, 0.5, 0.5, 0.4, 0.5, 0.5, 0.4, 0.5, 0.3, 0.3, 0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.4, 0.4, 0.4, 0.5, 0.5, 0.4, 0.4, 0.5, 0.5, 0.4, 0.4, 0.4, 0.4, 0.5, 0.5, 0.5, 0.4, 0.4, 0.5, 0.5, 0.3, 0.5, 0.4, 0.5, 0.4, 0.5, 0.5, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.5]\n",
      "Common threshold across all participants: 0.5\n",
      "\n",
      "Participant-Level ROC AUC: 0.8161\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Summarize results across participants\n",
    "# ------------------------------------------------------------------------------\n",
    "mean_accuracy = np.mean(all_acc)\n",
    "mean_f1 = np.mean(all_f1)\n",
    "total_conf_mat = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "print(\"\\n================== Final Summary ==================\")\n",
    "print(f\"Overall Participant-Level Accuracy: {mean_accuracy:.2f}%\")\n",
    "print(f\"Overall Participant-Level F1 (Macro): {mean_f1:.4f}\")\n",
    "print(\"Participant-Level Confusion Matrix (summed):\")\n",
    "print(total_conf_mat)\n",
    "\n",
    "# Show distribution of best thresholds across participants\n",
    "print(\"\\nBest thresholds chosen per participant:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "# If you want a single global threshold, you can do:\n",
    "try:\n",
    "    common_threshold = mode(best_thresholds)\n",
    "except StatisticsError:\n",
    "    # Fallback if no unique mode exists\n",
    "    common_threshold = np.median(best_thresholds)\n",
    "print(f\"Common threshold across all participants: {common_threshold}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Compute Participant-Level ROC AUC\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "participant_scores = np.array(participant_scores)           # shape: [num_participants]\n",
    "participant_labels = np.array(participant_labels_list)     # shape: [num_participants]\n",
    "\n",
    "# Check if there are both classes present\n",
    "unique_participant_labels = np.unique(participant_labels)\n",
    "if len(unique_participant_labels) == 2:\n",
    "    participant_auc = roc_auc_score(participant_labels, participant_scores)\n",
    "    print(f\"\\nParticipant-Level ROC AUC: {participant_auc:.4f}\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(participant_labels, participant_scores)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {participant_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Participant-Level ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, save the ROC curve plot\n",
    "    plt.savefig('participant_level_roc_curve.png')\n",
    "else:\n",
    "    print(\"\\nParticipant-Level ROC AUC not computed (only one class present).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[24  5]\n",
      " [ 8 28]]\n",
      "Accuracy:  0.800\n",
      "Precision: 0.848\n",
      "Recall:    0.778\n",
      "F1 score:  0.812\n",
      "Specificity: 0.828\n",
      "ROC AUC:   0.816\n",
      "Avg Precision: 0.854\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79        29\n",
      "           1       0.85      0.78      0.81        36\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.80      0.80      0.80        65\n",
      "weighted avg       0.80      0.80      0.80        65\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  5]\n",
      " [ 8 28]]\n",
      "Accuracy:    0.800\n",
      "Precision:   0.848\n",
      "Recall:      0.778\n",
      "Specificity: 0.828\n",
      "F1 Score:    0.812\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participant_predictions = []\n",
    "for i in range(len(all_acc)):\n",
    "    if participant_labels[i] == 1:  # Non-control\n",
    "        predicted = 1 if all_acc[i] == 100.0 else 0\n",
    "    else:                           # Control\n",
    "        predicted = 0 if all_acc[i] == 100.0 else 1\n",
    "    participant_predictions.append(predicted)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, average_precision_score)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "# 1. If you want binary predictions, pick a threshold (commonly 0.5).\n",
    "# threshold = 0.5\n",
    "# participant_pred = (participant_scores >= threshold).astype(int)\n",
    "\n",
    "participant_pred = participant_predictions\n",
    "# 2. Confusion matrix (needs binary predictions)\n",
    "cm = confusion_matrix(participant_labels, participant_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Accuracy, Precision, Recall, F1 (all use binary predictions)\n",
    "acc = accuracy_score(participant_labels, participant_pred)\n",
    "prec = precision_score(participant_labels, participant_pred)\n",
    "rec = recall_score(participant_labels, participant_pred)\n",
    "f1 = f1_score(participant_labels, participant_pred)\n",
    "spec = specificity_score(participant_labels, participant_pred)\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 score:  {f1:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "\n",
    "# 4. ROC AUC (needs the raw probability or score, not just a hard prediction)\n",
    "auc = roc_auc_score(participant_labels, participant_scores)\n",
    "print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "# 5. Average Precision (also uses the raw score)\n",
    "avg_prec = average_precision_score(participant_labels, participant_scores)\n",
    "print(f\"Avg Precision: {avg_prec:.3f}\")\n",
    "\n",
    "# 6. Classification report (includes precision, recall, f1 for each class)\n",
    "report = classification_report(participant_labels, participant_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example confusion matrices (replace with your actual data)\n",
    "# all_conf = [\n",
    "#     [[22, 7],\n",
    "#      [4, 32]],\n",
    "#     # Add more confusion matrices if needed\n",
    "# ]\n",
    "\n",
    "# Sum the confusion matrices\n",
    "cm = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "# Unpack the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0        # a.k.a. Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:    {accuracy:.3f}\")\n",
    "print(f\"Precision:   {precision:.3f}\")\n",
    "print(f\"Recall:      {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1 Score:    {f1:.3f}\")\n",
    "\n",
    "# Define class labels\n",
    "labels = ['CN', \"AD\"]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    annot_kws={\"size\": 16}  # Increase annotation font size here\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = torch.tensor([1.0, 0.8], dtype=torch.float32, device=device)\n",
    "# Confusion Matrix:\n",
    "# [[25  4]\n",
    "#  [ 7 29]]\n",
    "# Accuracy:    0.831\n",
    "# Precision:   0.879\n",
    "# Recall:      0.806\n",
    "# Specificity: 0.862\n",
    "# F1 Score:    0.841\n",
    "## class_weights = torch.tensor([1.0, 0.6], dtype=torch.float32, device=device)\n",
    "# Confusion Matrix:\n",
    "# [[26  3]\n",
    "#  [ 7 29]]\n",
    "# Accuracy:    0.846\n",
    "# Precision:   0.906\n",
    "# Recall:      0.806\n",
    "# Specificity: 0.897\n",
    "# F1 Score:    0.853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ALZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 42\n",
      "\n",
      "===== Training for participant: 37 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Label Accuracy: 63.75%\n",
      "[Threshold 0.2] -> F1=0.7884 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7819 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7884\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 12 = 0.25\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 38 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 62.66%\n",
      "[Threshold 0.2] -> F1=0.6700 | Acc=0.6731\n",
      "[Threshold 0.3] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8051 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7786 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8051\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 7 / 14 = 0.50\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 39 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 61.41%\n",
      "[Threshold 0.2] -> F1=0.8269 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.8441 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8003 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8441\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 8 / 14 = 0.57\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 40 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 59.53%\n",
      "[Threshold 0.2] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8402 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.7744 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8402\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 16 = 0.12\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 41 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 66.88%\n",
      "[Threshold 0.2] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8612 | Acc=0.8654\n",
      "[Threshold 0.5] -> F1=0.8402 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8612\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 42 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 63.12%\n",
      "[Threshold 0.2] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8402 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8402\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 16 = 0.06\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 43 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 62.66%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7512 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7604\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 44 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 61.56%\n",
      "[Threshold 0.2] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.8188 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8188\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 14 = 0.07\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 45 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 59.06%\n",
      "[Threshold 0.2] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7451 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7661\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 14 = 0.07\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 46 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 62.81%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7512 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7969\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 12 = 0.08\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 47 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.62%\n",
      "[Threshold 0.2] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.8188 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8188\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 13 = 0.08\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 48 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 61.41%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7097 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7661\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 16 = 0.38\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 49 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 63.59%\n",
      "[Threshold 0.2] -> F1=0.8253 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8253\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 13 = 0.31\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.78%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8030\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 9 / 13 = 0.69\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 51 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 62.34%\n",
      "[Threshold 0.2] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7744 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7273 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7846\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 52 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 66.88%\n",
      "[Threshold 0.2] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.8051 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7744 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8051\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 12 = 0.50\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 53 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 59.22%\n",
      "[Threshold 0.2] -> F1=0.7204 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7097 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.6504 | Acc=0.6923\n",
      "[Threshold 0.5] -> F1=0.6227 | Acc=0.6731\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7204\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 54 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 60.31%\n",
      "[Threshold 0.2] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.3] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7744 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7273 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8030\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 13 = 0.08\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 55 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 63.44%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7786 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7786\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 13 = 0.31\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 56 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.34%\n",
      "[Threshold 0.2] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8237 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.7693 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8375\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 11 / 13 = 0.85\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 57 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 57.19%\n",
      "[Threshold 0.2] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7927 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8188\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 58 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 64.38%\n",
      "[Threshold 0.2] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7636 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7786 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.6854 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7865\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 12 = 0.17\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 59 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.00%\n",
      "[Threshold 0.2] -> F1=0.8065 | Acc=0.8077\n",
      "[Threshold 0.3] -> F1=0.8051 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7744 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8065\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 13 = 0.15\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 62.50%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7097 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8003\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 61 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 61.25%\n",
      "[Threshold 0.2] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7786 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8030\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 5 / 13 = 0.38\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 62 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 62.19%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7636 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.8003 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8003\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 14 = 0.14\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 63 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 59.06%\n",
      "[Threshold 0.2] -> F1=0.6518 | Acc=0.6538\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.8188 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8188\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 4 / 13 = 0.31\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 64 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 60.16%\n",
      "[Threshold 0.2] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.6770 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8188\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 65 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 63.12%\n",
      "[Threshold 0.2] -> F1=0.8074 | Acc=0.8077\n",
      "[Threshold 0.3] -> F1=0.8051 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8074\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 5 / 14 = 0.36\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 66 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 62.89%\n",
      "[Threshold 0.2] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7693 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8216\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 9 = 0.89\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 67 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 66.28%\n",
      "[Threshold 0.2] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.7927 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7927 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8188\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 5 / 10 = 0.50\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 68 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 64.71%\n",
      "[Threshold 0.2] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8375\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 9 = 0.22\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 69 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 59.11%\n",
      "[Threshold 0.2] -> F1=0.7512 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.6770 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.5457 | Acc=0.6346\n",
      "[Threshold 0.5] -> F1=0.5248 | Acc=0.6346\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7512\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 10 = 0.70\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 70 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 131 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 7 samples\n",
      "Final Training Label Accuracy: 65.62%\n",
      "[Threshold 0.2] -> F1=0.7308 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8375 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8375\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 7 = 0.29\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 71 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 64.19%\n",
      "[Threshold 0.2] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7693 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7969\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 10 = 0.70\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 72 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 63.93%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7512 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7661\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 10 = 0.90\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 73 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 138 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 64.19%\n",
      "[Threshold 0.2] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7927 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8188\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 14 = 0.50\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 74 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 140 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 62.50%\n",
      "[Threshold 0.2] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7744 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7876 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7878\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 16 = 0.56\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 75 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 136 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 65.76%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7927 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8154\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 76 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 63.41%\n",
      "[Threshold 0.2] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8402 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.7876 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8402\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 77 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 135 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 62.37%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.6671 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8003\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 11 = 0.18\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 78 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 138 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 63.54%\n",
      "[Threshold 0.2] -> F1=0.6882 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7304\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 14 = 0.14\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 79 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.10%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7562 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8003\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 80 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 139 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 66.80%\n",
      "[Threshold 0.2] -> F1=0.8269 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.9021 | Acc=0.9038\n",
      "[Threshold 0.4] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.9021\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 15 = 0.07\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 81 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.10%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7786 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7927 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7693 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7927\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 82 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 136 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 67.45%\n",
      "[Threshold 0.2] -> F1=0.8077 | Acc=0.8077\n",
      "[Threshold 0.3] -> F1=0.8253 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8375 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8375\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 12 = 0.08\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 83 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 139 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 61.72%\n",
      "[Threshold 0.2] -> F1=0.6670 | Acc=0.6731\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7204 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7333 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7333\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 15 = 0.13\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 84 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 64.71%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8154\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 6 / 10 = 0.60\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 85 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 67.06%\n",
      "[Threshold 0.2] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7693 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8154\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 4 / 9 = 0.44\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 86 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 63.28%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7786 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7744 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7693 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7786\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 9 = 0.78\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 87 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 63.28%\n",
      "[Threshold 0.2] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7927 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7201 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7927\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 10 = 0.90\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 88 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 64.19%\n",
      "[Threshold 0.2] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8154\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 4 / 13 = 0.31\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statistics import mode, StatisticsError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize accumulators for participant-level metrics\n",
    "participant_scores = []       # Aggregated scores (e.g., alz_ratio) per participant\n",
    "participant_labels_list = []  # Ground-truth labels per participant\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)  # Ensure reproducibility\n",
    "\n",
    "# Define the model parameters\n",
    "# Define the model parameters\n",
    "input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "hidden_dim_pte = 512\n",
    "num_layers_pte = 2\n",
    "num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "output_dim_pte = 128\n",
    "dropout_pte = 0.4\n",
    "\n",
    "input_dim_psd = 5\n",
    "hidden_dim_psd = 512\n",
    "num_layers_psd = 2\n",
    "num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "output_dim_psd = 128\n",
    "dropout_psd = 0.4\n",
    "\n",
    "cross_d_model = 128\n",
    "cross_num_heads = 8   # Number of heads in cross-attention\n",
    "\n",
    "# Accumulators for overall metrics\n",
    "all_acc = []\n",
    "all_f1 = []\n",
    "all_conf = []\n",
    "\n",
    "# For global sample-level AUC\n",
    "global_probs = []\n",
    "global_labels = []\n",
    "\n",
    "best_thresholds = []  # Store the chosen threshold for each participant\n",
    "\n",
    "for participant in range(37, 89):\n",
    "    print(f\"\\n===== Training for participant: {participant} =====\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 1) Initialize the model\n",
    "    # --------------------------\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 2) Load data\n",
    "    #    (Ensure your source_dataloader returns (pte, psd, labels, participant_id))\n",
    "    # --------------------------\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=participant,\n",
    "        batch_size=128,\n",
    "        selected_classes=[\"ctrl\", \"ftd\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Source data: {len(source_dataloader.dataset)} samples\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 3) Define Loss & Optimizer\n",
    "    # --------------------------\n",
    "    class_weights = torch.tensor([1.0, 0.8], dtype=torch.float32, device=device)\n",
    "    criterion_label = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_domain = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5) # 8e-5\n",
    "\n",
    "    # --------------------------\n",
    "    # 4) Train Model (DANN)\n",
    "    # --------------------------\n",
    "    num_epochs = 100\n",
    "    lambda_grl = 0.0  # or use a schedule\n",
    "    label_acc_history, domain_acc_history = train_model(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        target_dataloader=target_dataloader,\n",
    "        criterion_label=criterion_label,\n",
    "        criterion_domain=criterion_domain,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device    )\n",
    "    print(f\"Final Training Label Accuracy: {label_acc_history[-1]:.2f}%\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 5) Tune Threshold on Source\n",
    "    # --------------------------\n",
    "    # This step requires that your source_dataloader yield participant IDs\n",
    "    thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n",
    "    best_thr = tune_threshold_on_source(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        device=device,\n",
    "        thresholds=thresholds_to_try,\n",
    "        num_classes=2\n",
    "    )\n",
    "    best_thresholds.append(best_thr)\n",
    "\n",
    "    # --------------------------\n",
    "    # 6) Test on Target\n",
    "    # --------------------------\n",
    "    # We use the threshold we found above\n",
    "    test_loss, test_acc, test_f1_score_part, participant_conf_mat, \\\n",
    "        participant_preds_softmax, participant_labels, alz_ratio, participant_true_label = test_model(\n",
    "            model=model,\n",
    "            test_dataloader=target_dataloader,\n",
    "            criterion_label=criterion_label,\n",
    "            device=device,\n",
    "            num_classes=2,\n",
    "            alz_threshold=best_thr,  # <--- using the best threshold\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 7) Store Participant-Level Metrics\n",
    "    # --------------------------\n",
    "    all_acc.append(test_acc)\n",
    "    all_f1.append(test_f1_score_part)\n",
    "    all_conf.append(participant_conf_mat)\n",
    "\n",
    "    global_probs.append(participant_preds_softmax)\n",
    "    global_labels.append(participant_labels)\n",
    "\n",
    "    # Collect participant-level score and label for ROC AUC\n",
    "    participant_scores.append(alz_ratio)               # Using alz_ratio as the score\n",
    "    participant_labels_list.append(participant_true_label)  # Ground-truth label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Final Summary ==================\n",
      "Overall Participant-Level Accuracy: 61.54%\n",
      "Overall Participant-Level F1 (Macro): 0.6154\n",
      "Participant-Level Confusion Matrix (summed):\n",
      "[[19 10]\n",
      " [10 13]]\n",
      "\n",
      "Best thresholds chosen per participant:\n",
      "[0.2, 0.4, 0.3, 0.4, 0.4, 0.4, 0.3, 0.5, 0.3, 0.4, 0.5, 0.2, 0.2, 0.3, 0.3, 0.3, 0.2, 0.2, 0.5, 0.4, 0.4, 0.2, 0.2, 0.3, 0.4, 0.5, 0.5, 0.3, 0.2, 0.2, 0.3, 0.4, 0.2, 0.5, 0.4, 0.3, 0.4, 0.2, 0.4, 0.4, 0.3, 0.4, 0.4, 0.3, 0.4, 0.4, 0.5, 0.4, 0.4, 0.3, 0.4, 0.5]\n",
      "Common threshold across all participants: 0.4\n",
      "\n",
      "Participant-Level ROC AUC: 0.7016\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Summarize results across participants\n",
    "# ------------------------------------------------------------------------------\n",
    "mean_accuracy = np.mean(all_acc)\n",
    "mean_f1 = np.mean(all_f1)\n",
    "total_conf_mat = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "print(\"\\n================== Final Summary ==================\")\n",
    "print(f\"Overall Participant-Level Accuracy: {mean_accuracy:.2f}%\")\n",
    "print(f\"Overall Participant-Level F1 (Macro): {mean_f1:.4f}\")\n",
    "print(\"Participant-Level Confusion Matrix (summed):\")\n",
    "print(total_conf_mat)\n",
    "\n",
    "# Show distribution of best thresholds across participants\n",
    "print(\"\\nBest thresholds chosen per participant:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "# If you want a single global threshold, you can do:\n",
    "try:\n",
    "    common_threshold = mode(best_thresholds)\n",
    "except StatisticsError:\n",
    "    # Fallback if no unique mode exists\n",
    "    common_threshold = np.median(best_thresholds)\n",
    "print(f\"Common threshold across all participants: {common_threshold}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Compute Participant-Level ROC AUC\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "participant_scores = np.array(participant_scores)           # shape: [num_participants]\n",
    "participant_labels = np.array(participant_labels_list)     # shape: [num_participants]\n",
    "\n",
    "# Check if there are both classes present\n",
    "unique_participant_labels = np.unique(participant_labels)\n",
    "if len(unique_participant_labels) == 2:\n",
    "    participant_auc = roc_auc_score(participant_labels, participant_scores)\n",
    "    print(f\"\\nParticipant-Level ROC AUC: {participant_auc:.4f}\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(participant_labels, participant_scores)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {participant_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Participant-Level ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, save the ROC curve plot\n",
    "    plt.savefig('participant_level_roc_curve.png')\n",
    "else:\n",
    "    print(\"\\nParticipant-Level ROC AUC not computed (only one class present).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19 10]\n",
      " [10 13]]\n",
      "Accuracy:  0.615\n",
      "Precision: 0.565\n",
      "Recall:    0.565\n",
      "F1 score:  0.565\n",
      "Specificity: 0.655\n",
      "ROC AUC:   0.702\n",
      "Avg Precision: 0.698\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66        29\n",
      "           1       0.57      0.57      0.57        23\n",
      "\n",
      "    accuracy                           0.62        52\n",
      "   macro avg       0.61      0.61      0.61        52\n",
      "weighted avg       0.62      0.62      0.62        52\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19 10]\n",
      " [10 13]]\n",
      "Accuracy:    0.615\n",
      "Precision:   0.565\n",
      "Recall:      0.565\n",
      "Specificity: 0.655\n",
      "F1 Score:    0.565\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participant_predictions = []\n",
    "for i in range(len(all_acc)):\n",
    "    if participant_labels[i] == 1:  # Non-control\n",
    "        predicted = 1 if all_acc[i] == 100.0 else 0\n",
    "    else:                           # Control\n",
    "        predicted = 0 if all_acc[i] == 100.0 else 1\n",
    "    participant_predictions.append(predicted)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, average_precision_score)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "# 1. If you want binary predictions, pick a threshold (commonly 0.5).\n",
    "# threshold = 0.5\n",
    "# participant_pred = (participant_scores >= threshold).astype(int)\n",
    "\n",
    "participant_pred = participant_predictions\n",
    "# 2. Confusion matrix (needs binary predictions)\n",
    "cm = confusion_matrix(participant_labels, participant_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Accuracy, Precision, Recall, F1 (all use binary predictions)\n",
    "acc = accuracy_score(participant_labels, participant_pred)\n",
    "prec = precision_score(participant_labels, participant_pred)\n",
    "rec = recall_score(participant_labels, participant_pred)\n",
    "f1 = f1_score(participant_labels, participant_pred)\n",
    "spec = specificity_score(participant_labels, participant_pred)\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 score:  {f1:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "\n",
    "# 4. ROC AUC (needs the raw probability or score, not just a hard prediction)\n",
    "auc = roc_auc_score(participant_labels, participant_scores)\n",
    "print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "# 5. Average Precision (also uses the raw score)\n",
    "avg_prec = average_precision_score(participant_labels, participant_scores)\n",
    "print(f\"Avg Precision: {avg_prec:.3f}\")\n",
    "\n",
    "# 6. Classification report (includes precision, recall, f1 for each class)\n",
    "report = classification_report(participant_labels, participant_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example confusion matrices (replace with your actual data)\n",
    "# all_conf = [\n",
    "#     [[22, 7],\n",
    "#      [4, 32]],\n",
    "#     # Add more confusion matrices if needed\n",
    "# ]\n",
    "\n",
    "# Sum the confusion matrices\n",
    "cm = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "# Unpack the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0        # a.k.a. Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:    {accuracy:.3f}\")\n",
    "print(f\"Precision:   {precision:.3f}\")\n",
    "print(f\"Recall:      {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1 Score:    {f1:.3f}\")\n",
    "\n",
    "# Define class labels\n",
    "labels = ['CN', \"AD\"]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    annot_kws={\"size\": 16}  # Increase annotation font size here\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
