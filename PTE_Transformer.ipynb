{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "\n",
      "Source data: 918 samples (including any synthetic)\n",
      "Target data: 10 samples (single participant)\n",
      "PTE Batch Shape: torch.Size([32, 11, 5, 6, 6])\n",
      "PSD Batch Shape: torch.Size([32, 6, 5])\n",
      "Labels Batch Shape: torch.Size([32])\n",
      "Participant IDs Batch Shape: torch.Size([32])\n",
      "TARGET PTE Batch Shape: torch.Size([10, 11, 5, 6, 6])\n",
      "TARGET PSD Batch Shape: torch.Size([10, 6, 5])\n",
      "TARGET Labels Shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "def load_combined_data(\n",
    "    pte_directory,         # Directory containing the PTE .npz files\n",
    "    DE_directory,         # Directory containing the PSD .npz files\n",
    "    target_participant,\n",
    "    batch_size,\n",
    "    selected_classes=[\"alz\", \"ctrl\"],   # Which classes to load\n",
    "    selected_channels=None,             # Channels to select\n",
    "    apply_smote=True                    # Whether to apply SMOTE on the source data\n",
    "):\n",
    "    \"\"\"\n",
    "    Load data from separate directories for PTE and PSD, normalize, optionally apply SMOTE,\n",
    "    and create DataLoaders for source and target domains.\n",
    "\n",
    "    Args:\n",
    "        pte_directory (str):\n",
    "            Path to the directory containing .npz files with PTE data.\n",
    "        psd_directory (str):\n",
    "            Path to the directory containing .npz files with PSD data.\n",
    "        target_participant (int):\n",
    "            Subject ID to be used as the target domain.\n",
    "        batch_size (int):\n",
    "            Batch size for the source DataLoader.\n",
    "        selected_classes (list):\n",
    "            List of class labels to include (e.g., [\"alz\", \"ctrl\"]).\n",
    "        selected_channels (list or None):\n",
    "            List of channel names to select. If None, all channels are used.\n",
    "        apply_smote (bool):\n",
    "            If True, SMOTE is applied to the source data to handle class imbalance.\n",
    "\n",
    "    Returns:\n",
    "        source_dataloader (DataLoader):\n",
    "            DataLoader for the source domain with tuples: (pte_data, psd_data, labels, participant_ids).\n",
    "            If SMOTE is applied, synthetic samples are assigned `participant_id = -1`.\n",
    "        target_dataloader (DataLoader):\n",
    "            DataLoader for the target domain with tuples: (pte_data, psd_data, labels).\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Setup\n",
    "    # -------------------------------------------------------------------------\n",
    "    ch_names = [\n",
    "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz'\n",
    "    ]\n",
    "    label_map = {cname: idx for idx, cname in enumerate(selected_classes)}\n",
    "\n",
    "    if selected_channels is None:\n",
    "        selected_channels = ch_names\n",
    "\n",
    "    # Get channel indices\n",
    "    try:\n",
    "        selected_indices = [ch_names.index(ch) for ch in selected_channels]\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"One or more selected channels are not in ch_names: {e}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Collect and sort .npz files for PTE and PSD\n",
    "    # -------------------------------------------------------------------------\n",
    "    pte_files = [f for f in os.listdir(pte_directory) if f.endswith(\".npz\")]\n",
    "    psd_files = [f for f in os.listdir(DE_directory) if f.endswith(\".npz\")]\n",
    "\n",
    "    # Sort by subject ID (assuming filenames like 'sub-10_*_alz.npz')\n",
    "    def extract_sub_id(filename):\n",
    "        match = re.search(r'sub-(\\d+)_.*\\.npz', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "\n",
    "    pte_files_sorted = sorted(pte_files, key=extract_sub_id)\n",
    "    psd_files_sorted = sorted(psd_files, key=extract_sub_id)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3) Prepare lists for source and target data (with participant IDs)\n",
    "    # -------------------------------------------------------------------------\n",
    "    source_pte_data_list, source_pte_labels_list, source_pte_pid_list = [], [], []\n",
    "    target_pte_data_list, target_pte_labels_list = [], []\n",
    "    source_psd_data_list, source_psd_labels_list, source_psd_pid_list = [], [], []\n",
    "    target_psd_data_list, target_psd_labels_list = [], []\n",
    "\n",
    "    # Separate MinMaxScalers for PTE and PSD\n",
    "    pte_scaler = MinMaxScaler()\n",
    "    psd_scaler = MinMaxScaler()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Load PTE data\n",
    "    # -------------------------------------------------------------------------\n",
    "    for file in pte_files_sorted:\n",
    "        match = re.search(r'sub-(\\d+)_.*_(\\w+)\\.npz', file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subject_id = int(match.group(1))\n",
    "        label_str = match.group(2).lower()\n",
    "\n",
    "        # Skip if label not in selected classes\n",
    "        if label_str not in selected_classes:\n",
    "            continue\n",
    "\n",
    "        label_idx = label_map[label_str]\n",
    "        full_path = os.path.join(pte_directory, file)\n",
    "\n",
    "        data_npz = np.load(full_path, allow_pickle=True)\n",
    "        if \"pte_data\" not in data_npz:\n",
    "            continue  # no PTE data\n",
    "\n",
    "        pte_data = data_npz[\"pte_data\"]  # shape: [N, 12, 5, 19, 19] (example)\n",
    "\n",
    "        # Select channels in the 4th and 5th dimensions (adjust if shape differs)\n",
    "        # For example: pte_data[:, :11, :, selected_indices, :][:, :11, :, :, selected_indices]\n",
    "        # Modify as needed for your real data shape\n",
    "        pte_data = pte_data[:, :11, :, selected_indices, :][:, :11, :, :, selected_indices]\n",
    "\n",
    "        # Normalize across the last dimension\n",
    "        orig_shape = pte_data.shape\n",
    "        pte_data_flat = pte_data.reshape(-1, orig_shape[-1])\n",
    "        pte_data_flat = pte_scaler.fit_transform(pte_data_flat)\n",
    "        pte_data = pte_data_flat.reshape(orig_shape)\n",
    "\n",
    "        # Build labels\n",
    "        labels = np.full((pte_data.shape[0],), label_idx, dtype=int)\n",
    "\n",
    "        if subject_id == target_participant:\n",
    "            # Target domain\n",
    "            target_pte_data_list.append(pte_data)\n",
    "            target_pte_labels_list.append(labels)\n",
    "        else:\n",
    "            # Source domain\n",
    "            source_pte_data_list.append(pte_data)\n",
    "            source_pte_labels_list.append(labels)\n",
    "            # Store participant IDs (one per sample)\n",
    "            source_pte_pid_list.extend([subject_id] * pte_data.shape[0])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Load PSD data\n",
    "    # -------------------------------------------------------------------------\n",
    "    for file in psd_files_sorted:\n",
    "        match = re.search(r'sub-(\\d+)_.*_(\\w+)\\.npz', file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subject_id = int(match.group(1))\n",
    "        label_str = match.group(2).lower()\n",
    "\n",
    "        if label_str not in selected_classes:\n",
    "            continue\n",
    "\n",
    "        label_idx = label_map[label_str]\n",
    "        full_path = os.path.join(DE_directory, file)\n",
    "\n",
    "        data_npz = np.load(full_path, allow_pickle=True)\n",
    "        if \"DE_features\" not in data_npz:\n",
    "            continue\n",
    "\n",
    "        psd_data = data_npz[\"DE_features\"]  # shape: [N, 12, n_channels, n_bands], etc.\n",
    "        # print(psd_data.shape)\n",
    "        \n",
    "        # Select channels (assume 2nd dimension is channels):\n",
    "        # e.g., psd_data[:, :, selected_indices, :]\n",
    "        psd_data = psd_data[:, selected_indices, :]\n",
    "\n",
    "        # Normalize\n",
    "        orig_shape = psd_data.shape\n",
    "        psd_data_flat = psd_data.reshape(-1, orig_shape[-1])\n",
    "        psd_data_flat = psd_scaler.fit_transform(psd_data_flat)\n",
    "        psd_data = psd_data_flat.reshape(orig_shape)\n",
    "\n",
    "        labels = np.full((psd_data.shape[0],), label_idx, dtype=int)\n",
    "\n",
    "        if subject_id == target_participant:\n",
    "            target_psd_data_list.append(psd_data)\n",
    "            target_psd_labels_list.append(labels)\n",
    "        else:\n",
    "            source_psd_data_list.append(psd_data)\n",
    "            source_psd_labels_list.append(labels)\n",
    "            source_psd_pid_list.extend([subject_id] * psd_data.shape[0])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Concatenate source & target data\n",
    "    # -------------------------------------------------------------------------\n",
    "    def concat_arrays(array_list):\n",
    "        return np.concatenate(array_list, axis=0) if array_list else None\n",
    "\n",
    "    # Source PTE\n",
    "    source_pte_data = concat_arrays(source_pte_data_list)\n",
    "    source_pte_labels = concat_arrays(source_pte_labels_list)\n",
    "    source_pte_pids = np.array(source_pte_pid_list) if source_pte_pid_list else None\n",
    "\n",
    "    # Target PTE\n",
    "    target_pte_data = concat_arrays(target_pte_data_list)\n",
    "    target_pte_labels = concat_arrays(target_pte_labels_list)\n",
    "\n",
    "    # Source PSD\n",
    "    source_psd_data = concat_arrays(source_psd_data_list)\n",
    "    source_psd_labels = concat_arrays(source_psd_labels_list)\n",
    "    source_psd_pids = np.array(source_psd_pid_list) if source_psd_pid_list else None\n",
    "\n",
    "    # Target PSD\n",
    "    target_psd_data = concat_arrays(target_psd_data_list)\n",
    "    target_psd_labels = concat_arrays(target_psd_labels_list)\n",
    "\n",
    "    # print(\"\\nSource PTE data shape:\", source_pte_data.shape if source_pte_data is not None else None)\n",
    "    # print(\"Source PSD data shape:\", source_psd_data.shape if source_psd_data is not None else None)\n",
    "    # print(\"Target PTE data shape:\", target_pte_data.shape if target_pte_data is not None else None)\n",
    "    # print(\"Target PSD data shape:\", target_psd_data.shape if target_psd_data is not None else None)\n",
    "    \n",
    "    # Quick sanity check\n",
    "    if (\n",
    "        source_pte_data is None or source_pte_labels is None or\n",
    "        source_psd_data is None or source_psd_labels is None\n",
    "    ):\n",
    "        raise ValueError(\"No valid source data found (PTE or PSD).\")\n",
    "    if (\n",
    "        target_pte_data is None or target_pte_labels is None or\n",
    "        target_psd_data is None or target_psd_labels is None\n",
    "    ):\n",
    "        raise ValueError(\"No valid target data found (PTE or PSD).\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 7) Optionally apply SMOTE on the source data\n",
    "    # -------------------------------------------------------------------------\n",
    "    if apply_smote:\n",
    "        print(\"\\nApplying SMOTE to the source data...\")\n",
    "\n",
    "        # Flatten PTE and PSD for concatenation\n",
    "        orig_pte_shape = source_pte_data.shape\n",
    "        orig_psd_shape = source_psd_data.shape\n",
    "\n",
    "        pte_flat = source_pte_data.reshape(orig_pte_shape[0], -1)\n",
    "        psd_flat = source_psd_data.reshape(orig_psd_shape[0], -1)\n",
    "\n",
    "        # Concatenate features for SMOTE\n",
    "        combined_features = np.concatenate([pte_flat, psd_flat], axis=1)\n",
    "        combined_labels = source_pte_labels  # same as PSD labels in your setup\n",
    "\n",
    "        # SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        combined_resampled, labels_resampled = sm.fit_resample(combined_features, combined_labels)\n",
    "\n",
    "        # Count how many new (synthetic) samples were added\n",
    "        num_original = combined_features.shape[0]\n",
    "        num_new = combined_resampled.shape[0] - num_original\n",
    "        print(f\"SMOTE created {num_new} synthetic samples.\")\n",
    "\n",
    "        # Split back into PTE and PSD\n",
    "        pte_dim = pte_flat.shape[1]\n",
    "        psd_dim = psd_flat.shape[1]\n",
    "\n",
    "        pte_resampled = combined_resampled[:, :pte_dim]\n",
    "        psd_resampled = combined_resampled[:, pte_dim:]\n",
    "\n",
    "        # Reshape back\n",
    "        source_pte_data = pte_resampled.reshape(\n",
    "            -1,\n",
    "            orig_pte_shape[1],\n",
    "            orig_pte_shape[2],\n",
    "            orig_pte_shape[3],\n",
    "            orig_pte_shape[4]\n",
    "        )\n",
    "        source_psd_data = psd_resampled.reshape(\n",
    "            -1,\n",
    "            orig_psd_shape[1],\n",
    "            orig_psd_shape[2]\n",
    "        )\n",
    "\n",
    "        # Update labels\n",
    "        source_pte_labels = labels_resampled\n",
    "        source_psd_labels = labels_resampled\n",
    "\n",
    "        # For new (synthetic) samples, assign participant_id = -1 so they can be excluded in threshold tuning\n",
    "        pid_extended = np.concatenate([\n",
    "            source_pte_pids,\n",
    "            np.full(num_new, -1, dtype=int)\n",
    "        ])\n",
    "        source_pte_pids = pid_extended\n",
    "        source_psd_pids = pid_extended\n",
    "    else:\n",
    "        print(\"\\nSMOTE not applied to the source data.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 8) Convert to PyTorch Tensors\n",
    "    # -------------------------------------------------------------------------\n",
    "    def to_tensor(data, dtype=torch.float):\n",
    "        return torch.from_numpy(data).type(dtype)\n",
    "\n",
    "    source_pte_data_tensor = to_tensor(source_pte_data, torch.float)\n",
    "    source_psd_data_tensor = to_tensor(source_psd_data, torch.float)\n",
    "    source_labels_tensor = to_tensor(source_pte_labels, torch.long)\n",
    "    source_pid_tensor = to_tensor(source_pte_pids, torch.long)\n",
    "\n",
    "    target_pte_data_tensor = to_tensor(target_pte_data, torch.float)\n",
    "    target_psd_data_tensor = to_tensor(target_psd_data, torch.float)\n",
    "    target_labels_tensor = to_tensor(target_pte_labels, torch.long)\n",
    "    # Target doesn't need a participant ID (single participant).\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 9) Build TensorDatasets & DataLoaders\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Source dataset has participant IDs so we can do threshold tuning\n",
    "    source_dataset = TensorDataset(\n",
    "        source_pte_data_tensor,\n",
    "        source_psd_data_tensor,\n",
    "        source_labels_tensor,\n",
    "        source_pid_tensor\n",
    "    )\n",
    "    target_dataset = TensorDataset(\n",
    "        target_pte_data_tensor,\n",
    "        target_psd_data_tensor,\n",
    "        target_labels_tensor\n",
    "    )\n",
    "\n",
    "    source_dataloader = DataLoader(\n",
    "        source_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    target_dataloader = DataLoader(\n",
    "        target_dataset, batch_size=len(target_dataset), shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    return source_dataloader, target_dataloader\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Example usage\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    selected_channels = ['O2', 'C3', 'C4', 'Cz', 'T5', 'T6']\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=6,\n",
    "        batch_size=32,\n",
    "        selected_classes=[\"ctrl\", \"alz\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True    # Control SMOTE usage here\n",
    "    )\n",
    "    print(f\"\\nSource data: {len(source_dataloader.dataset)} samples (including any synthetic)\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples (single participant)\")\n",
    "\n",
    "    # Check a sample from the source DataLoader\n",
    "    for pte_batch, psd_batch, labels_batch, pid_batch in source_dataloader:\n",
    "        print(\"PTE Batch Shape:\", pte_batch.shape)\n",
    "        print(\"PSD Batch Shape:\", psd_batch.shape)\n",
    "        print(\"Labels Batch Shape:\", labels_batch.shape)\n",
    "        print(\"Participant IDs Batch Shape:\", pid_batch.shape)\n",
    "        break\n",
    "\n",
    "    # Check the target DataLoader\n",
    "    for pte_batch, psd_batch, labels_batch in target_dataloader:\n",
    "        print(\"TARGET PTE Batch Shape:\", pte_batch.shape)\n",
    "        print(\"TARGET PSD Batch Shape:\", psd_batch.shape)\n",
    "        print(\"TARGET Labels Shape:\", labels_batch.shape)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from itertools import cycle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    source_dataloader,\n",
    "    target_dataloader,\n",
    "    criterion_label,\n",
    "    criterion_domain,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    device=\"cuda\",\n",
    "    alpha_entropy = 0.01\n",
    "):\n",
    "   \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    accuracy_history = []\n",
    "    domain_accuracy_history = []\n",
    "\n",
    "    # Create an infinite iterator over the target dataloader\n",
    "    target_iter = cycle(target_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_domain_correct = 0\n",
    "        total_domain_samples = 0\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "\n",
    "        for i, batch_src in enumerate(source_dataloader):\n",
    "\n",
    "            if len(batch_src) == 4:\n",
    "                source_pte, source_psd, source_labels, _ = batch_src\n",
    "            else:\n",
    "                source_pte, source_psd, source_labels = batch_src\n",
    "\n",
    "            # Grab target batch\n",
    "            batch_tgt = next(target_iter)\n",
    "            if len(batch_tgt) == 3:\n",
    "                target_pte, target_psd, _ = batch_tgt\n",
    "            else:\n",
    "                # e.g., (target_pte, target_psd) if unlabeled\n",
    "                target_pte, target_psd = batch_tgt\n",
    "\n",
    "\n",
    "            # Move data to device\n",
    "            source_pte = source_pte.to(device)\n",
    "            source_psd = source_psd.to(device)\n",
    "            source_labels = source_labels.to(device)\n",
    "\n",
    "            target_pte = target_pte.to(device)\n",
    "            target_psd = target_psd.to(device)\n",
    "\n",
    "\n",
    "            label_preds, _ = model(\n",
    "                source_pte, source_psd\n",
    "            )\n",
    " \n",
    "            label_preds_target, _ = model(\n",
    "                target_pte, target_psd\n",
    "            )\n",
    "\n",
    "\n",
    "            loss_label = criterion_label(label_preds, source_labels)\n",
    "\n",
    "\n",
    "            total_loss = loss_label\n",
    "            # Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # -------------------------------\n",
    "            # Update Metrics\n",
    "            # -------------------------------\n",
    "            epoch_loss += loss_label.item()\n",
    "\n",
    "            # Label prediction accuracy (source)\n",
    "            _, predicted = torch.max(label_preds, dim=1)\n",
    "            correct = (predicted == source_labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += source_labels.size(0)\n",
    "\n",
    "\n",
    "        epoch_accuracy = 100.0 * total_correct / total_samples if total_samples > 0 else 0\n",
    "        epoch_domain_accuracy = 100.0 * total_domain_correct / total_domain_samples if total_domain_samples > 0 else 0\n",
    "\n",
    "        accuracy_history.append(epoch_accuracy)\n",
    "        domain_accuracy_history.append(epoch_domain_accuracy)\n",
    "\n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        #       f\"Label Acc: {epoch_accuracy:.2f}%, \"\n",
    "        #       f\"Domain Acc: {epoch_domain_accuracy:.2f}%\")\n",
    "\n",
    "    return accuracy_history, domain_accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def test_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    criterion_label: torch.nn.Module,\n",
    "    device: str = \"cuda\",\n",
    "    num_classes: int = 2,\n",
    "    alz_threshold: float = 0.4\n",
    ") -> Tuple[float, float, float, np.ndarray, np.ndarray, np.ndarray, float, int]:\n",
    "  \n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds_softmax = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            # ------------------------------------------------------\n",
    "            # 1) Handle batch size: 3 items or 4 items\n",
    "            # ------------------------------------------------------\n",
    "            # If your test dataloader returns 4 items (pte_batch, psd_batch, labels, pid):\n",
    "            if len(batch) == 4:\n",
    "                pte_batch, psd_batch, labels, _ = batch\n",
    "            elif len(batch) == 3:\n",
    "                pte_batch, psd_batch, labels = batch\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"DataLoader should return (pte_batch, psd_batch, labels) or 4 items. Got {len(batch)} items.\"\n",
    "                )\n",
    "\n",
    "            # Move data to device\n",
    "            pte_batch = pte_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "          \n",
    "            label_preds, _ = model(pte_batch, psd_batch)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 4) Compute classification loss\n",
    "            # ------------------------------------------------------\n",
    "            loss = criterion_label(label_preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 5) Softmax for predicted probabilities\n",
    "            # ------------------------------------------------------\n",
    "            softmax_output = F.softmax(label_preds, dim=1)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 6) Hard predictions\n",
    "            # ------------------------------------------------------\n",
    "            _, predicted = torch.max(softmax_output, dim=1)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 7) Store predictions/probabilities/labels\n",
    "            # ------------------------------------------------------\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_preds_softmax.extend(softmax_output.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 8) Compute average loss\n",
    "    # ------------------------------------------------------\n",
    "    if len(test_dataloader) > 0:\n",
    "        avg_loss = total_loss / len(test_dataloader)\n",
    "    else:\n",
    "        avg_loss = 0.0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 9) Check if the participant has a single ground-truth label\n",
    "    # ------------------------------------------------------\n",
    "    all_labels = np.array(all_labels)\n",
    "    unique_lbls = np.unique(all_labels)\n",
    "    if len(unique_lbls) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Participant's test set has multiple labels: {unique_lbls}. \"\n",
    "            f\"Expected exactly 1 label per participant.\"\n",
    "        )\n",
    "\n",
    "    participant_true_label = unique_lbls[0]\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 10) Participant-level prediction\n",
    "    # ------------------------------------------------------\n",
    "    all_preds = np.array(all_preds)\n",
    "    alz_count = np.sum(all_preds == 1)\n",
    "    alz_ratio = alz_count / max(len(all_preds), 1)\n",
    "\n",
    "    if alz_ratio >= alz_threshold:\n",
    "        participant_pred_label = 1\n",
    "    else:\n",
    "        participant_pred_label = 0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 11) Construct participant-level confusion matrix\n",
    "    # ------------------------------------------------------\n",
    "    participant_conf_mat = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    participant_conf_mat[participant_true_label, participant_pred_label] += 1\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 12) Participant-level accuracy & F1\n",
    "    # ------------------------------------------------------\n",
    "    participant_acc = 100.0 if (participant_true_label == participant_pred_label) else 0.0\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    participant_f1 = f1_score(\n",
    "        [participant_true_label],\n",
    "        [participant_pred_label],\n",
    "        average='macro',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 13) Print debug info\n",
    "    # ------------------------------------------------------\n",
    "    print(f\"\\nParticipant True Label: {participant_true_label}\")\n",
    "    print(f\" -> #Predicted ALZ samples: {alz_count} / {len(all_preds)} = {alz_ratio:.2f}\")\n",
    "    print(f\" -> Threshold = {alz_threshold}; Final Participant Prediction: {participant_pred_label}\")\n",
    "    print(f\" -> Participant Accuracy: {participant_acc:.2f}%\")\n",
    "    print(f\" -> Participant F1 (Macro): {participant_f1:.4f}\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 14) Return results including alz_ratio and true label\n",
    "    # ------------------------------------------------------\n",
    "    all_preds_softmax = np.array(all_preds_softmax)  # shape: [N, num_classes]\n",
    "    return (\n",
    "        avg_loss,\n",
    "        participant_acc,\n",
    "        participant_f1,\n",
    "        participant_conf_mat,\n",
    "        all_preds_softmax,\n",
    "        all_labels,\n",
    "        alz_ratio,\n",
    "        participant_true_label\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def tune_threshold_on_source(\n",
    "    model,\n",
    "    source_dataloader,\n",
    "    device=\"cuda\",\n",
    "    thresholds=[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    num_classes=2\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    sample_preds = defaultdict(list)\n",
    "    participant_label = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in source_dataloader:\n",
    "            # If your source dataloader returns 4 items, including participant_id\n",
    "            if len(batch) == 4:\n",
    "                pte_batch, psd_batch, labels, pid_batch = batch\n",
    "            else:\n",
    "                raise ValueError(\"Expected Dataloader to return (pte, psd, labels, pid).\")\n",
    "\n",
    "            pte_batch = pte_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pid_batch = pid_batch.to(device)\n",
    "\n",
    "            # Forward pass (disable GRL in inference by setting lambda_=0)\n",
    "            label_preds, _ = model(pte_batch, psd_batch)\n",
    "\n",
    "            # Convert predictions to class=0/1\n",
    "            softmax_output = F.softmax(label_preds, dim=1)\n",
    "            _, predicted = torch.max(softmax_output, dim=1)\n",
    "\n",
    "            # Move to CPU\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            pid_batch = pid_batch.cpu().numpy()\n",
    "\n",
    "            # Store predictions for each participant\n",
    "            for pred, true_lbl, pid in zip(predicted, labels, pid_batch):\n",
    "                sample_preds[pid].append(pred)\n",
    "                # We assume all samples from participant pid share the same ground-truth label:\n",
    "                if pid not in participant_label:\n",
    "                    participant_label[pid] = true_lbl\n",
    "                else:\n",
    "                    # Optionally check that the label is consistent\n",
    "                    if participant_label[pid] != true_lbl:\n",
    "                        raise ValueError(f\"Inconsistent labels for participant {pid} in source data.\")\n",
    "\n",
    "    # Now we have sample-level predictions per participant. We'll try each threshold.\n",
    "    best_threshold = None\n",
    "    best_metric_val = -1.0\n",
    "\n",
    "    for thr in thresholds:\n",
    "        # For each threshold, generate participant-level predictions\n",
    "        # by counting how many samples predicted as class=1\n",
    "        part_level_preds = []\n",
    "        part_level_trues = []\n",
    "\n",
    "        for pid, preds_list in sample_preds.items():\n",
    "            true_lbl = participant_label[pid]\n",
    "            n_alz = sum([p == 1 for p in preds_list])\n",
    "            ratio = float(n_alz) / len(preds_list)\n",
    "            # Decide participant-level label\n",
    "            if ratio >= thr:\n",
    "                participant_pred = 1\n",
    "            else:\n",
    "                participant_pred = 0\n",
    "            \n",
    "            part_level_preds.append(participant_pred)\n",
    "            part_level_trues.append(true_lbl)\n",
    "\n",
    "        # Evaluate participant-level performance\n",
    "        # For example, we use F1 (macro):\n",
    "        f1 = f1_score(part_level_trues, part_level_preds, average='macro', zero_division=0)\n",
    "        acc = accuracy_score(part_level_trues, part_level_preds)\n",
    "\n",
    "        print(f\"[Threshold {thr}] -> F1={f1:.4f} | Acc={acc:.4f}\")\n",
    "\n",
    "        # Suppose we pick the threshold that maximizes participant-level F1\n",
    "        if f1 > best_metric_val:\n",
    "            best_metric_val = f1\n",
    "            best_threshold = thr\n",
    "\n",
    "    print(f\"\\n[Best Threshold] = {best_threshold} with F1={best_metric_val:.4f}\")\n",
    "    return best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Prediction Shape: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "# Define the Multi-Head Cross Attention Module\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "\n",
    "        super(MultiHeadCrossAttention, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
    "\n",
    "        # Apply MultiheadAttention; note that nn.MultiheadAttention expects inputs of shape (batch, seq, feature)\n",
    "        attn_output, attn_weights = self.multihead_attn(query, key, value, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        # Apply dropout\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        \n",
    "        # Add & Norm\n",
    "        output = self.layer_norm(query + attn_output)\n",
    "        \n",
    "        return output, attn_weights\n",
    "\n",
    "# Existing Transformer Classes (PteTransformer and PsdTransformer)\n",
    "class PteTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n",
    "        super(PteTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.position_encoding = nn.Parameter(torch.randn(1, 11, input_dim), requires_grad=True)\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)  # Project to desired output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, original_features)\n",
    "        \"\"\"\n",
    "        b = x.shape[0]\n",
    "        # Reshape to (batch_size, 11, input_dim//11) assuming input_dim is divisible by 11\n",
    "        x = x.reshape(b, 11, -1)\n",
    "        x = self.position_encoding + x  # (batch_size, 11, input_dim)\n",
    "        x = self.transformer(x)         # (batch_size, 11, input_dim)\n",
    "        x = self.output_layer(x)        # (batch_size, 11, output_dim)\n",
    "        return x\n",
    "\n",
    "class PsdTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n",
    "        super(PsdTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)  # Project to desired output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, original_features)\n",
    "        \"\"\"\n",
    "        # Assuming x is already of shape (batch_size, T_e, input_dim)\n",
    "        x = self.transformer(x)         # (batch_size, T_e, input_dim)\n",
    "        x = self.output_layer(x)        # (batch_size, T_e, output_dim)\n",
    "        return x\n",
    "\n",
    "# Updated Final Model with Multi-Head Cross Attention and DANN Components\n",
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pte_input_dim, pte_hidden_dim, pte_num_layers, pte_num_heads, pte_output_dim, pte_dropout,\n",
    "                 psd_input_dim, psd_hidden_dim, psd_num_layers, psd_num_heads, psd_output_dim, psd_dropout,\n",
    "                 cross_d_model, cross_num_heads,\n",
    "                 ):\n",
    "        super(FinalModel, self).__init__() \n",
    "\n",
    "        # Initialize PTE and PSD Transformers\n",
    "        self.pte_transformer = PteTransformer(\n",
    "            input_dim=pte_input_dim,\n",
    "            hidden_dim=pte_hidden_dim,\n",
    "            num_layers=pte_num_layers,\n",
    "            num_heads=pte_num_heads,\n",
    "            output_dim=pte_output_dim,\n",
    "            dropout=pte_dropout\n",
    "        )\n",
    "        \n",
    "        self.psd_transformer = PsdTransformer(\n",
    "            input_dim=psd_input_dim,\n",
    "            hidden_dim=psd_hidden_dim,\n",
    "            num_layers=psd_num_layers,\n",
    "            num_heads=psd_num_heads,\n",
    "            output_dim=psd_output_dim,\n",
    "            dropout=psd_dropout\n",
    "        )\n",
    "        \n",
    "        # Initialize Multi-Head Cross-Attention\n",
    "        self.cross_attention = MultiHeadCrossAttention(\n",
    "            d_model=cross_d_model,\n",
    "            num_heads=cross_num_heads,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        # Final Classifier for Label Prediction\n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(1408, 2)  # Adjust based on the sequence length (12 here)\n",
    "        )\n",
    "        \n",
    "    def forward(self, pte_input, psd_input):\n",
    "\n",
    "        # Pass through respective transformers\n",
    "        pte_encoded = self.pte_transformer(pte_input)  # (batch_size, T_pte=11, pte_output_dim=128)\n",
    "        # psd_encoded = self.psd_transformer(psd_input)  # (batch_size, T_psd=6, psd_output_dim=128)\n",
    "        \n",
    "        \n",
    "        # Label Prediction\n",
    "        label_pred = self.final_classifier(pte_encoded)  # (batch_size, 2)\n",
    "        \n",
    "        \n",
    "        return label_pred, None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input tensors\n",
    "    # Adjust the shapes based on your actual data\n",
    "    # For illustration, assuming:\n",
    "    # pte_input has 11 time steps, each with (input_dim_pte / 11) features\n",
    "    x_1 = torch.randn(32, 11 * 5 * 6 * 6)  # (batch_size, pte_original_features)\n",
    "    # psd_input has sequence length 6 with 5 features each\n",
    "    x_2 = torch.randn(32, 6, 5)            # (batch_size, psd_seq_length, psd_original_features)\n",
    "    \n",
    "    # Define the model parameters\n",
    "    input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "    hidden_dim_pte = 512\n",
    "    num_layers_pte = 2\n",
    "    num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "    output_dim_pte = 128\n",
    "    dropout_pte = 0.1\n",
    "    \n",
    "    input_dim_psd = 5\n",
    "    hidden_dim_psd = 512\n",
    "    num_layers_psd = 2\n",
    "    num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "    output_dim_psd = 128\n",
    "    dropout_psd = 0.1\n",
    "    \n",
    "    cross_d_model = 128\n",
    "    cross_num_heads = 8   # Number of heads in cross-attention\n",
    "    \n",
    "    # Initialize the DANN model\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "    \n",
    "    # Example forward pass\n",
    "    label_pred, _ = model(x_1, x_2)\n",
    "    print(\"Label Prediction Shape:\", label_pred.shape)        # Expected: (32, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set the seed for PyTorch (both CPU and CUDA)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "    # Ensure deterministic behavior in PyTorch (if applicable)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set the seed for sklearn (via check_random_state)\n",
    "    _ = check_random_state(seed)\n",
    "\n",
    "    print(f\"Seed set to: {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 42\n",
      "\n",
      "===== Training for participant: 1 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 72 synthetic samples.\n",
      "Source data: 920 samples\n",
      "Target data: 9 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Label Accuracy: 82.14%\n",
      "[Threshold 0.2] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 84.15%\n",
      "[Threshold 0.2] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8443\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 76 synthetic samples.\n",
      "Source data: 928 samples\n",
      "Target data: 5 samples\n",
      "Final Training Label Accuracy: 84.49%\n",
      "[Threshold 0.2] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8443\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 5 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 82.03%\n",
      "[Threshold 0.2] -> F1=0.7611 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.5] -> F1=0.7636 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7783\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.58%\n",
      "[Threshold 0.2] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8452 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8452\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 6 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "Source data: 918 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 81.36%\n",
      "[Threshold 0.2] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8452 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8452\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 10 = 0.10\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 7 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 82.59%\n",
      "[Threshold 0.2] -> F1=0.7804 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 8 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.81%\n",
      "[Threshold 0.2] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8293 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8293\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 9 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "Source data: 918 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 80.47%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 60 synthetic samples.\n",
      "Source data: 896 samples\n",
      "Target data: 21 samples\n",
      "Final Training Label Accuracy: 81.70%\n",
      "[Threshold 0.2] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 21 / 21 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 11 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 81.92%\n",
      "[Threshold 0.2] -> F1=0.7436 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.7436 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.7611 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7611 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7611\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 12 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 78.79%\n",
      "[Threshold 0.2] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8150 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8150\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 13 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.47%\n",
      "[Threshold 0.2] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8306 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8306\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 14 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 81.81%\n",
      "[Threshold 0.2] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8118\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 82.59%\n",
      "[Threshold 0.2] -> F1=0.8614 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8614 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8614 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8614 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8614\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 15 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 16 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 65 synthetic samples.\n",
      "Source data: 906 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.25%\n",
      "[Threshold 0.2] -> F1=0.8452 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8150 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8452\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 17 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.25%\n",
      "[Threshold 0.2] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 18 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.03%\n",
      "[Threshold 0.2] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 19 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 81.03%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.25%\n",
      "[Threshold 0.2] -> F1=0.7436 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.7436 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.7611 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7611 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7611\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 21 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.7611 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7952 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7952\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 22 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.47%\n",
      "[Threshold 0.2] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8458 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8458\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 23 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.48%\n",
      "[Threshold 0.2] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8150 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8150\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 24 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.13%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 25 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 83.48%\n",
      "[Threshold 0.2] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8443\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 11 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 26 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.47%\n",
      "[Threshold 0.2] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 27 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.80%\n",
      "[Threshold 0.2] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8150 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8301\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 28 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.47%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 29 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.25%\n",
      "[Threshold 0.2] -> F1=0.7969 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 30 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 72 synthetic samples.\n",
      "Source data: 920 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 82.14%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 31 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 62 synthetic samples.\n",
      "Source data: 900 samples\n",
      "Target data: 19 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8443\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 19 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 32 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.58%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 33 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 81.36%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8293 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8293\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 34 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 65 synthetic samples.\n",
      "Source data: 906 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 80.69%\n",
      "[Threshold 0.2] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8452 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8452\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 35 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.69%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8132 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8132\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 36 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.81%\n",
      "[Threshold 0.2] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8150 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8150 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8150\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 37 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 81.03%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7725 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7725\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 38 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 79.46%\n",
      "[Threshold 0.2] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8282\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 39 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 80.80%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7725 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7725\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 40 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.81%\n",
      "[Threshold 0.2] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 41 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 79.02%\n",
      "[Threshold 0.2] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8282\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 42 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 79.91%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7725 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7725\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 43 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.03%\n",
      "[Threshold 0.2] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 44 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.36%\n",
      "[Threshold 0.2] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 45 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 46 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 79.58%\n",
      "[Threshold 0.2] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 5 / 12 = 0.42\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 47 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.36%\n",
      "[Threshold 0.2] -> F1=0.8132 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8293 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8143 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8293\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 48 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.14%\n",
      "[Threshold 0.2] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7903 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7903\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 49 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.58%\n",
      "[Threshold 0.2] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.70%\n",
      "[Threshold 0.2] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 51 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 82.25%\n",
      "[Threshold 0.2] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 52 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.58%\n",
      "[Threshold 0.2] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 53 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 79.46%\n",
      "[Threshold 0.2] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8143 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8143\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 54 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 79.13%\n",
      "[Threshold 0.2] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 55 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 76.90%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8267\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 56 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.25%\n",
      "[Threshold 0.2] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 57 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.69%\n",
      "[Threshold 0.2] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 58 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.13%\n",
      "[Threshold 0.2] -> F1=0.7400 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.7580 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7756 | Acc=0.7846\n",
      "[Threshold 0.5] -> F1=0.7756 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7756\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 59 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.59%\n",
      "[Threshold 0.2] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8301 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8301 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8301\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 83.37%\n",
      "[Threshold 0.2] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8282\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 61 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.03%\n",
      "[Threshold 0.2] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8143 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8143\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 62 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.03%\n",
      "[Threshold 0.2] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8143 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8143 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8143\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 63 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.81%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 64 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.70%\n",
      "[Threshold 0.2] -> F1=0.7952 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8118 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8118\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 65 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 83.48%\n",
      "[Threshold 0.2] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.5] -> F1=0.8077 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8077\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statistics import mode, StatisticsError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize accumulators for participant-level metrics\n",
    "participant_scores = []       # Aggregated scores (e.g., alz_ratio) per participant\n",
    "participant_labels_list = []  # Ground-truth labels per participant\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)  # Ensure reproducibility\n",
    "\n",
    "# Define the model parameters\n",
    "# Define the model parameters\n",
    "input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "hidden_dim_pte = 512\n",
    "num_layers_pte = 2\n",
    "num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "output_dim_pte = 128\n",
    "dropout_pte = 0.4\n",
    "\n",
    "input_dim_psd = 5\n",
    "hidden_dim_psd = 512\n",
    "num_layers_psd = 2\n",
    "num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "output_dim_psd = 128\n",
    "dropout_psd = 0.4\n",
    "\n",
    "cross_d_model = 128\n",
    "cross_num_heads = 8   # Number of heads in cross-attention\n",
    "\n",
    "# Accumulators for overall metrics\n",
    "all_acc = []\n",
    "all_f1 = []\n",
    "all_conf = []\n",
    "\n",
    "# For global sample-level AUC\n",
    "global_probs = []\n",
    "global_labels = []\n",
    "\n",
    "best_thresholds = []  # Store the chosen threshold for each participant\n",
    "\n",
    "for participant in range(1, 66):\n",
    "    print(f\"\\n===== Training for participant: {participant} =====\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 1) Initialize the model\n",
    "    # --------------------------\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 2) Load data\n",
    "    #    (Ensure your source_dataloader returns (pte, psd, labels, participant_id))\n",
    "    # --------------------------\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=participant,\n",
    "        batch_size=128,\n",
    "        selected_classes=[\"ctrl\", \"alz\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Source data: {len(source_dataloader.dataset)} samples\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 3) Define Loss & Optimizer\n",
    "    # --------------------------\n",
    "    class_weights = torch.tensor([0.8, 1.0], dtype=torch.float32, device=device)\n",
    "    criterion_label = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_domain = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5) # 8e-5\n",
    "\n",
    "    # --------------------------\n",
    "    # 4) Train Model (DANN)\n",
    "    # --------------------------\n",
    "    num_epochs = 100\n",
    "    lambda_grl = 0.0  # or use a schedule\n",
    "    label_acc_history, domain_acc_history = train_model(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        target_dataloader=target_dataloader,\n",
    "        criterion_label=criterion_label,\n",
    "        criterion_domain=criterion_domain,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device    )\n",
    "    print(f\"Final Training Label Accuracy: {label_acc_history[-1]:.2f}%\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 5) Tune Threshold on Source\n",
    "    # --------------------------\n",
    "    # This step requires that your source_dataloader yield participant IDs\n",
    "    thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n",
    "    best_thr = tune_threshold_on_source(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        device=device,\n",
    "        thresholds=thresholds_to_try,\n",
    "        num_classes=2\n",
    "    )\n",
    "    best_thresholds.append(best_thr)\n",
    "\n",
    "    # --------------------------\n",
    "    # 6) Test on Target\n",
    "    # --------------------------\n",
    "    # We use the threshold we found above\n",
    "    test_loss, test_acc, test_f1_score_part, participant_conf_mat, \\\n",
    "        participant_preds_softmax, participant_labels, alz_ratio, participant_true_label = test_model(\n",
    "            model=model,\n",
    "            test_dataloader=target_dataloader,\n",
    "            criterion_label=criterion_label,\n",
    "            device=device,\n",
    "            num_classes=2,\n",
    "            alz_threshold=best_thr,  # <--- using the best threshold\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 7) Store Participant-Level Metrics\n",
    "    # --------------------------\n",
    "    all_acc.append(test_acc)\n",
    "    all_f1.append(test_f1_score_part)\n",
    "    all_conf.append(participant_conf_mat)\n",
    "\n",
    "    global_probs.append(participant_preds_softmax)\n",
    "    global_labels.append(participant_labels)\n",
    "\n",
    "    # Collect participant-level score and label for ROC AUC\n",
    "    participant_scores.append(alz_ratio)               # Using alz_ratio as the score\n",
    "    participant_labels_list.append(participant_true_label)  # Ground-truth label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Final Summary ==================\n",
      "Overall Participant-Level Accuracy: 78.46%\n",
      "Overall Participant-Level F1 (Macro): 0.7846\n",
      "Participant-Level Confusion Matrix (summed):\n",
      "[[22  7]\n",
      " [ 7 29]]\n",
      "\n",
      "Best thresholds chosen per participant:\n",
      "[0.3, 0.3, 0.2, 0.3, 0.2, 0.2, 0.5, 0.2, 0.2, 0.4, 0.4, 0.2, 0.5, 0.3, 0.2, 0.2, 0.3, 0.3, 0.2, 0.4, 0.4, 0.5, 0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.3, 0.2, 0.2, 0.2, 0.3, 0.5, 0.2, 0.2, 0.5, 0.4, 0.5, 0.3, 0.3, 0.5, 0.4, 0.3, 0.3, 0.2, 0.3, 0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.3, 0.4, 0.3, 0.4, 0.4, 0.2, 0.4, 0.2, 0.2, 0.4, 0.3, 0.3]\n",
      "Common threshold across all participants: 0.2\n",
      "\n",
      "Participant-Level ROC AUC: 0.8065\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Summarize results across participants\n",
    "# ------------------------------------------------------------------------------\n",
    "mean_accuracy = np.mean(all_acc)\n",
    "mean_f1 = np.mean(all_f1)\n",
    "total_conf_mat = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "print(\"\\n================== Final Summary ==================\")\n",
    "print(f\"Overall Participant-Level Accuracy: {mean_accuracy:.2f}%\")\n",
    "print(f\"Overall Participant-Level F1 (Macro): {mean_f1:.4f}\")\n",
    "print(\"Participant-Level Confusion Matrix (summed):\")\n",
    "print(total_conf_mat)\n",
    "\n",
    "# Show distribution of best thresholds across participants\n",
    "print(\"\\nBest thresholds chosen per participant:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "# If you want a single global threshold, you can do:\n",
    "try:\n",
    "    common_threshold = mode(best_thresholds)\n",
    "except StatisticsError:\n",
    "    # Fallback if no unique mode exists\n",
    "    common_threshold = np.median(best_thresholds)\n",
    "print(f\"Common threshold across all participants: {common_threshold}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Compute Participant-Level ROC AUC\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "participant_scores = np.array(participant_scores)           # shape: [num_participants]\n",
    "participant_labels = np.array(participant_labels_list)     # shape: [num_participants]\n",
    "\n",
    "# Check if there are both classes present\n",
    "unique_participant_labels = np.unique(participant_labels)\n",
    "if len(unique_participant_labels) == 2:\n",
    "    participant_auc = roc_auc_score(participant_labels, participant_scores)\n",
    "    print(f\"\\nParticipant-Level ROC AUC: {participant_auc:.4f}\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(participant_labels, participant_scores)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {participant_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Participant-Level ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, save the ROC curve plot\n",
    "    plt.savefig('participant_level_roc_curve.png')\n",
    "else:\n",
    "    print(\"\\nParticipant-Level ROC AUC not computed (only one class present).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[22  7]\n",
      " [ 7 29]]\n",
      "Accuracy:  0.785\n",
      "Precision: 0.806\n",
      "Recall:    0.806\n",
      "F1 score:  0.806\n",
      "Specificity: 0.759\n",
      "ROC AUC:   0.807\n",
      "Avg Precision: 0.782\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        29\n",
      "           1       0.81      0.81      0.81        36\n",
      "\n",
      "    accuracy                           0.78        65\n",
      "   macro avg       0.78      0.78      0.78        65\n",
      "weighted avg       0.78      0.78      0.78        65\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22  7]\n",
      " [ 7 29]]\n",
      "Accuracy:    0.785\n",
      "Precision:   0.806\n",
      "Recall:      0.806\n",
      "Specificity: 0.759\n",
      "F1 Score:    0.806\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participant_predictions = []\n",
    "for i in range(len(all_acc)):\n",
    "    if participant_labels[i] == 1:  # Non-control\n",
    "        predicted = 1 if all_acc[i] == 100.0 else 0\n",
    "    else:                           # Control\n",
    "        predicted = 0 if all_acc[i] == 100.0 else 1\n",
    "    participant_predictions.append(predicted)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, average_precision_score)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "# 1. If you want binary predictions, pick a threshold (commonly 0.5).\n",
    "# threshold = 0.5\n",
    "# participant_pred = (participant_scores >= threshold).astype(int)\n",
    "\n",
    "participant_pred = participant_predictions\n",
    "# 2. Confusion matrix (needs binary predictions)\n",
    "cm = confusion_matrix(participant_labels, participant_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Accuracy, Precision, Recall, F1 (all use binary predictions)\n",
    "acc = accuracy_score(participant_labels, participant_pred)\n",
    "prec = precision_score(participant_labels, participant_pred)\n",
    "rec = recall_score(participant_labels, participant_pred)\n",
    "f1 = f1_score(participant_labels, participant_pred)\n",
    "spec = specificity_score(participant_labels, participant_pred)\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 score:  {f1:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "\n",
    "# 4. ROC AUC (needs the raw probability or score, not just a hard prediction)\n",
    "auc = roc_auc_score(participant_labels, participant_scores)\n",
    "print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "# 5. Average Precision (also uses the raw score)\n",
    "avg_prec = average_precision_score(participant_labels, participant_scores)\n",
    "print(f\"Avg Precision: {avg_prec:.3f}\")\n",
    "\n",
    "# 6. Classification report (includes precision, recall, f1 for each class)\n",
    "report = classification_report(participant_labels, participant_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example confusion matrices (replace with your actual data)\n",
    "# all_conf = [\n",
    "#     [[22, 7],\n",
    "#      [4, 32]],\n",
    "#     # Add more confusion matrices if needed\n",
    "# ]\n",
    "\n",
    "# Sum the confusion matrices\n",
    "cm = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "# Unpack the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0        # a.k.a. Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:    {accuracy:.3f}\")\n",
    "print(f\"Precision:   {precision:.3f}\")\n",
    "print(f\"Recall:      {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1 Score:    {f1:.3f}\")\n",
    "\n",
    "# Define class labels\n",
    "labels = ['CN', \"AD\"]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    annot_kws={\"size\": 16}  # Increase annotation font size here\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = torch.tensor([1.0, 0.8], dtype=torch.float32, device=device)\n",
    "# Confusion Matrix:\n",
    "# [[25  4]\n",
    "#  [ 7 29]]\n",
    "# Accuracy:    0.831\n",
    "# Precision:   0.879\n",
    "# Recall:      0.806\n",
    "# Specificity: 0.862\n",
    "# F1 Score:    0.841\n",
    "## class_weights = torch.tensor([1.0, 0.6], dtype=torch.float32, device=device)\n",
    "# Confusion Matrix:\n",
    "# [[26  3]\n",
    "#  [ 7 29]]\n",
    "# Accuracy:    0.846\n",
    "# Precision:   0.906\n",
    "# Recall:      0.806\n",
    "# Specificity: 0.897\n",
    "# F1 Score:    0.853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ALZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 42\n",
      "\n",
      "===== Training for participant: 37 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Label Accuracy: 69.53%\n",
      "[Threshold 0.2] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7604 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7604\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 38 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 71.88%\n",
      "[Threshold 0.2] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7499 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7499\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 39 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 68.12%\n",
      "[Threshold 0.2] -> F1=0.6919 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.6919 | Acc=0.6923\n",
      "[Threshold 0.4] -> F1=0.6919 | Acc=0.6923\n",
      "[Threshold 0.5] -> F1=0.6919 | Acc=0.6923\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.6919\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 40 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 68.12%\n",
      "[Threshold 0.2] -> F1=0.6905 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7088 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7088\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 41 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 71.56%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7088 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7292\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 42 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 70.47%\n",
      "[Threshold 0.2] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7242 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7242\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 43 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.22%\n",
      "[Threshold 0.2] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 44 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 70.31%\n",
      "[Threshold 0.2] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7106 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7304\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 45 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.66%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7242 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7242\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 14 = 0.86\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 46 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 68.28%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 47 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.94%\n",
      "[Threshold 0.2] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7689 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7689\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 11 / 13 = 0.85\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 48 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 67.66%\n",
      "[Threshold 0.2] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7383 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 49 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.91%\n",
      "[Threshold 0.2] -> F1=0.6919 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7114 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7114\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.91%\n",
      "[Threshold 0.2] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 51 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 72.03%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7062 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7062\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 7 / 12 = 0.58\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 52 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 69.69%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7292 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7292\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 53 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.19%\n",
      "[Threshold 0.2] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 54 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.34%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7114 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7114\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 55 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.47%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7114 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7114\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 56 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.53%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7114 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7114\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 57 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.75%\n",
      "[Threshold 0.2] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.6882 | Acc=0.6923\n",
      "[Threshold 0.5] -> F1=0.6882 | Acc=0.6923\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7088\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 58 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 68.44%\n",
      "[Threshold 0.2] -> F1=0.7156 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7156 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7156 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.6923 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7156\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 59 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 71.09%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 70.31%\n",
      "[Threshold 0.2] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7604 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7604\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 61 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 72.50%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7114 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7114\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 62 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.38%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 63 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.16%\n",
      "[Threshold 0.2] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 64 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 73.12%\n",
      "[Threshold 0.2] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7423\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 65 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 71.09%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 66 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 72.79%\n",
      "[Threshold 0.2] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7383 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7383\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 67 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 69.40%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7062 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7062\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 68 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 71.61%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7477 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 9 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 69 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 70.31%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7242 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7242\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 2 / 10 = 0.20\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 70 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 131 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 7 samples\n",
      "Final Training Label Accuracy: 71.48%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7477 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 7 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 71 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 69.79%\n",
      "[Threshold 0.2] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7562 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7562\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 72 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 71.61%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7026 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7062\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 73 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 138 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 74.74%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 74 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 140 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 69.53%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7477 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 75 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 136 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 75.39%\n",
      "[Threshold 0.2] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7786 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7786 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7786 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7786\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 76 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.36%\n",
      "[Threshold 0.2] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7062 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7062 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7062\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 77 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 135 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 70.05%\n",
      "[Threshold 0.2] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7562 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7562\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 78 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 138 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 68.23%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.6923 | Acc=0.6923\n",
      "[Threshold 0.5] -> F1=0.6923 | Acc=0.6923\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7114\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 79 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 72.40%\n",
      "[Threshold 0.2] -> F1=0.7512 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7512 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7273 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7026 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7512\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 80 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 139 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 72.40%\n",
      "[Threshold 0.2] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7114 | Acc=0.7115\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7304\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 15 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 81 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.18%\n",
      "[Threshold 0.2] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7383 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7383\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 82 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 136 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 73.44%\n",
      "[Threshold 0.2] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7679 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7679\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 83 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 139 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 72.14%\n",
      "[Threshold 0.2] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7304 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7304\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 84 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 67.19%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7304 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7304\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 85 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 71.88%\n",
      "[Threshold 0.2] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7383 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7383\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 86 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 71.48%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7477 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 9 = 0.11\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 87 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 68.36%\n",
      "[Threshold 0.2] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7292 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7492\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 88 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.27%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statistics import mode, StatisticsError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize accumulators for participant-level metrics\n",
    "participant_scores = []       # Aggregated scores (e.g., alz_ratio) per participant\n",
    "participant_labels_list = []  # Ground-truth labels per participant\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)  # Ensure reproducibility\n",
    "\n",
    "# Define the model parameters\n",
    "# Define the model parameters\n",
    "input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "hidden_dim_pte = 512\n",
    "num_layers_pte = 2\n",
    "num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "output_dim_pte = 128\n",
    "dropout_pte = 0.4\n",
    "\n",
    "input_dim_psd = 5\n",
    "hidden_dim_psd = 512\n",
    "num_layers_psd = 2\n",
    "num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "output_dim_psd = 128\n",
    "dropout_psd = 0.4\n",
    "\n",
    "cross_d_model = 128\n",
    "cross_num_heads = 8   # Number of heads in cross-attention\n",
    "\n",
    "# Accumulators for overall metrics\n",
    "all_acc = []\n",
    "all_f1 = []\n",
    "all_conf = []\n",
    "\n",
    "# For global sample-level AUC\n",
    "global_probs = []\n",
    "global_labels = []\n",
    "\n",
    "best_thresholds = []  # Store the chosen threshold for each participant\n",
    "\n",
    "for participant in range(37, 89):\n",
    "    print(f\"\\n===== Training for participant: {participant} =====\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 1) Initialize the model\n",
    "    # --------------------------\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 2) Load data\n",
    "    #    (Ensure your source_dataloader returns (pte, psd, labels, participant_id))\n",
    "    # --------------------------\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=participant,\n",
    "        batch_size=128,\n",
    "        selected_classes=[\"ctrl\", \"ftd\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Source data: {len(source_dataloader.dataset)} samples\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 3) Define Loss & Optimizer\n",
    "    # --------------------------\n",
    "    class_weights = torch.tensor([1.0, 0.8], dtype=torch.float32, device=device)\n",
    "    criterion_label = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_domain = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5) # 8e-5\n",
    "\n",
    "    # --------------------------\n",
    "    # 4) Train Model (DANN)\n",
    "    # --------------------------\n",
    "    num_epochs = 100\n",
    "    lambda_grl = 0.0  # or use a schedule\n",
    "    label_acc_history, domain_acc_history = train_model(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        target_dataloader=target_dataloader,\n",
    "        criterion_label=criterion_label,\n",
    "        criterion_domain=criterion_domain,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device    )\n",
    "    print(f\"Final Training Label Accuracy: {label_acc_history[-1]:.2f}%\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 5) Tune Threshold on Source\n",
    "    # --------------------------\n",
    "    # This step requires that your source_dataloader yield participant IDs\n",
    "    thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n",
    "    best_thr = tune_threshold_on_source(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        device=device,\n",
    "        thresholds=thresholds_to_try,\n",
    "        num_classes=2\n",
    "    )\n",
    "    best_thresholds.append(best_thr)\n",
    "\n",
    "    # --------------------------\n",
    "    # 6) Test on Target\n",
    "    # --------------------------\n",
    "    # We use the threshold we found above\n",
    "    test_loss, test_acc, test_f1_score_part, participant_conf_mat, \\\n",
    "        participant_preds_softmax, participant_labels, alz_ratio, participant_true_label = test_model(\n",
    "            model=model,\n",
    "            test_dataloader=target_dataloader,\n",
    "            criterion_label=criterion_label,\n",
    "            device=device,\n",
    "            num_classes=2,\n",
    "            alz_threshold=best_thr,  # <--- using the best threshold\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 7) Store Participant-Level Metrics\n",
    "    # --------------------------\n",
    "    all_acc.append(test_acc)\n",
    "    all_f1.append(test_f1_score_part)\n",
    "    all_conf.append(participant_conf_mat)\n",
    "\n",
    "    global_probs.append(participant_preds_softmax)\n",
    "    global_labels.append(participant_labels)\n",
    "\n",
    "    # Collect participant-level score and label for ROC AUC\n",
    "    participant_scores.append(alz_ratio)               # Using alz_ratio as the score\n",
    "    participant_labels_list.append(participant_true_label)  # Ground-truth label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Final Summary ==================\n",
      "Overall Participant-Level Accuracy: 67.31%\n",
      "Overall Participant-Level F1 (Macro): 0.6731\n",
      "Participant-Level Confusion Matrix (summed):\n",
      "[[21  8]\n",
      " [ 9 14]]\n",
      "\n",
      "Best thresholds chosen per participant:\n",
      "[0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.2, 0.2, 0.5, 0.2, 0.2, 0.2, 0.3, 0.5, 0.2, 0.2, 0.5, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.5, 0.5, 0.2, 0.2, 0.2, 0.2, 0.2, 0.5, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.5, 0.2, 0.2, 0.3, 0.2]\n",
      "Common threshold across all participants: 0.2\n",
      "\n",
      "Participant-Level ROC AUC: 0.7294\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Summarize results across participants\n",
    "# ------------------------------------------------------------------------------\n",
    "mean_accuracy = np.mean(all_acc)\n",
    "mean_f1 = np.mean(all_f1)\n",
    "total_conf_mat = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "print(\"\\n================== Final Summary ==================\")\n",
    "print(f\"Overall Participant-Level Accuracy: {mean_accuracy:.2f}%\")\n",
    "print(f\"Overall Participant-Level F1 (Macro): {mean_f1:.4f}\")\n",
    "print(\"Participant-Level Confusion Matrix (summed):\")\n",
    "print(total_conf_mat)\n",
    "\n",
    "# Show distribution of best thresholds across participants\n",
    "print(\"\\nBest thresholds chosen per participant:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "# If you want a single global threshold, you can do:\n",
    "try:\n",
    "    common_threshold = mode(best_thresholds)\n",
    "except StatisticsError:\n",
    "    # Fallback if no unique mode exists\n",
    "    common_threshold = np.median(best_thresholds)\n",
    "print(f\"Common threshold across all participants: {common_threshold}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Compute Participant-Level ROC AUC\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "participant_scores = np.array(participant_scores)           # shape: [num_participants]\n",
    "participant_labels = np.array(participant_labels_list)     # shape: [num_participants]\n",
    "\n",
    "# Check if there are both classes present\n",
    "unique_participant_labels = np.unique(participant_labels)\n",
    "if len(unique_participant_labels) == 2:\n",
    "    participant_auc = roc_auc_score(participant_labels, participant_scores)\n",
    "    print(f\"\\nParticipant-Level ROC AUC: {participant_auc:.4f}\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(participant_labels, participant_scores)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {participant_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Participant-Level ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, save the ROC curve plot\n",
    "    plt.savefig('participant_level_roc_curve.png')\n",
    "else:\n",
    "    print(\"\\nParticipant-Level ROC AUC not computed (only one class present).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[21  8]\n",
      " [ 9 14]]\n",
      "Accuracy:  0.673\n",
      "Precision: 0.636\n",
      "Recall:    0.609\n",
      "F1 score:  0.622\n",
      "Specificity: 0.724\n",
      "ROC AUC:   0.729\n",
      "Avg Precision: 0.640\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71        29\n",
      "           1       0.64      0.61      0.62        23\n",
      "\n",
      "    accuracy                           0.67        52\n",
      "   macro avg       0.67      0.67      0.67        52\n",
      "weighted avg       0.67      0.67      0.67        52\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21  8]\n",
      " [ 9 14]]\n",
      "Accuracy:    0.673\n",
      "Precision:   0.636\n",
      "Recall:      0.609\n",
      "Specificity: 0.724\n",
      "F1 Score:    0.622\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participant_predictions = []\n",
    "for i in range(len(all_acc)):\n",
    "    if participant_labels[i] == 1:  # Non-control\n",
    "        predicted = 1 if all_acc[i] == 100.0 else 0\n",
    "    else:                           # Control\n",
    "        predicted = 0 if all_acc[i] == 100.0 else 1\n",
    "    participant_predictions.append(predicted)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, average_precision_score)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "# 1. If you want binary predictions, pick a threshold (commonly 0.5).\n",
    "# threshold = 0.5\n",
    "# participant_pred = (participant_scores >= threshold).astype(int)\n",
    "\n",
    "participant_pred = participant_predictions\n",
    "# 2. Confusion matrix (needs binary predictions)\n",
    "cm = confusion_matrix(participant_labels, participant_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Accuracy, Precision, Recall, F1 (all use binary predictions)\n",
    "acc = accuracy_score(participant_labels, participant_pred)\n",
    "prec = precision_score(participant_labels, participant_pred)\n",
    "rec = recall_score(participant_labels, participant_pred)\n",
    "f1 = f1_score(participant_labels, participant_pred)\n",
    "spec = specificity_score(participant_labels, participant_pred)\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 score:  {f1:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "\n",
    "# 4. ROC AUC (needs the raw probability or score, not just a hard prediction)\n",
    "auc = roc_auc_score(participant_labels, participant_scores)\n",
    "print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "# 5. Average Precision (also uses the raw score)\n",
    "avg_prec = average_precision_score(participant_labels, participant_scores)\n",
    "print(f\"Avg Precision: {avg_prec:.3f}\")\n",
    "\n",
    "# 6. Classification report (includes precision, recall, f1 for each class)\n",
    "report = classification_report(participant_labels, participant_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example confusion matrices (replace with your actual data)\n",
    "# all_conf = [\n",
    "#     [[22, 7],\n",
    "#      [4, 32]],\n",
    "#     # Add more confusion matrices if needed\n",
    "# ]\n",
    "\n",
    "# Sum the confusion matrices\n",
    "cm = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "# Unpack the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0        # a.k.a. Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:    {accuracy:.3f}\")\n",
    "print(f\"Precision:   {precision:.3f}\")\n",
    "print(f\"Recall:      {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1 Score:    {f1:.3f}\")\n",
    "\n",
    "# Define class labels\n",
    "labels = ['CN', \"AD\"]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    annot_kws={\"size\": 16}  # Increase annotation font size here\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
