{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "\n",
      "Source data: 918 samples (including any synthetic)\n",
      "Target data: 10 samples (single participant)\n",
      "PTE Batch Shape: torch.Size([32, 11, 5, 6, 6])\n",
      "PSD Batch Shape: torch.Size([32, 6, 5])\n",
      "Labels Batch Shape: torch.Size([32])\n",
      "Participant IDs Batch Shape: torch.Size([32])\n",
      "TARGET PTE Batch Shape: torch.Size([10, 11, 5, 6, 6])\n",
      "TARGET PSD Batch Shape: torch.Size([10, 6, 5])\n",
      "TARGET Labels Shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "def load_combined_data(\n",
    "    pte_directory,         # Directory containing the PTE .npz files\n",
    "    DE_directory,         # Directory containing the PSD .npz files\n",
    "    target_participant,\n",
    "    batch_size,\n",
    "    selected_classes=[\"alz\", \"ctrl\"],   # Which classes to load\n",
    "    selected_channels=None,             # Channels to select\n",
    "    apply_smote=True                    # Whether to apply SMOTE on the source data\n",
    "):\n",
    "    \"\"\"\n",
    "    Load data from separate directories for PTE and PSD, normalize, optionally apply SMOTE,\n",
    "    and create DataLoaders for source and target domains.\n",
    "\n",
    "    Args:\n",
    "        pte_directory (str):\n",
    "            Path to the directory containing .npz files with PTE data.\n",
    "        psd_directory (str):\n",
    "            Path to the directory containing .npz files with PSD data.\n",
    "        target_participant (int):\n",
    "            Subject ID to be used as the target domain.\n",
    "        batch_size (int):\n",
    "            Batch size for the source DataLoader.\n",
    "        selected_classes (list):\n",
    "            List of class labels to include (e.g., [\"alz\", \"ctrl\"]).\n",
    "        selected_channels (list or None):\n",
    "            List of channel names to select. If None, all channels are used.\n",
    "        apply_smote (bool):\n",
    "            If True, SMOTE is applied to the source data to handle class imbalance.\n",
    "\n",
    "    Returns:\n",
    "        source_dataloader (DataLoader):\n",
    "            DataLoader for the source domain with tuples: (pte_data, psd_data, labels, participant_ids).\n",
    "            If SMOTE is applied, synthetic samples are assigned `participant_id = -1`.\n",
    "        target_dataloader (DataLoader):\n",
    "            DataLoader for the target domain with tuples: (pte_data, psd_data, labels).\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Setup\n",
    "    # -------------------------------------------------------------------------\n",
    "    ch_names = [\n",
    "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz'\n",
    "    ]\n",
    "    label_map = {cname: idx for idx, cname in enumerate(selected_classes)}\n",
    "\n",
    "    if selected_channels is None:\n",
    "        selected_channels = ch_names\n",
    "\n",
    "    # Get channel indices\n",
    "    try:\n",
    "        selected_indices = [ch_names.index(ch) for ch in selected_channels]\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"One or more selected channels are not in ch_names: {e}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Collect and sort .npz files for PTE and PSD\n",
    "    # -------------------------------------------------------------------------\n",
    "    pte_files = [f for f in os.listdir(pte_directory) if f.endswith(\".npz\")]\n",
    "    psd_files = [f for f in os.listdir(DE_directory) if f.endswith(\".npz\")]\n",
    "\n",
    "    # Sort by subject ID (assuming filenames like 'sub-10_*_alz.npz')\n",
    "    def extract_sub_id(filename):\n",
    "        match = re.search(r'sub-(\\d+)_.*\\.npz', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "\n",
    "    pte_files_sorted = sorted(pte_files, key=extract_sub_id)\n",
    "    psd_files_sorted = sorted(psd_files, key=extract_sub_id)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3) Prepare lists for source and target data (with participant IDs)\n",
    "    # -------------------------------------------------------------------------\n",
    "    source_pte_data_list, source_pte_labels_list, source_pte_pid_list = [], [], []\n",
    "    target_pte_data_list, target_pte_labels_list = [], []\n",
    "    source_psd_data_list, source_psd_labels_list, source_psd_pid_list = [], [], []\n",
    "    target_psd_data_list, target_psd_labels_list = [], []\n",
    "\n",
    "    # Separate MinMaxScalers for PTE and PSD\n",
    "    pte_scaler = MinMaxScaler()\n",
    "    psd_scaler = MinMaxScaler()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Load PTE data\n",
    "    # -------------------------------------------------------------------------\n",
    "    for file in pte_files_sorted:\n",
    "        match = re.search(r'sub-(\\d+)_.*_(\\w+)\\.npz', file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subject_id = int(match.group(1))\n",
    "        label_str = match.group(2).lower()\n",
    "\n",
    "        # Skip if label not in selected classes\n",
    "        if label_str not in selected_classes:\n",
    "            continue\n",
    "\n",
    "        label_idx = label_map[label_str]\n",
    "        full_path = os.path.join(pte_directory, file)\n",
    "\n",
    "        data_npz = np.load(full_path, allow_pickle=True)\n",
    "        if \"pte_data\" not in data_npz:\n",
    "            continue  # no PTE data\n",
    "\n",
    "        pte_data = data_npz[\"pte_data\"]  # shape: [N, 12, 5, 19, 19] (example)\n",
    "\n",
    "        # Select channels in the 4th and 5th dimensions (adjust if shape differs)\n",
    "        # For example: pte_data[:, :11, :, selected_indices, :][:, :11, :, :, selected_indices]\n",
    "        # Modify as needed for your real data shape\n",
    "        pte_data = pte_data[:, :11, :, selected_indices, :][:, :11, :, :, selected_indices]\n",
    "\n",
    "        # Normalize across the last dimension\n",
    "        orig_shape = pte_data.shape\n",
    "        pte_data_flat = pte_data.reshape(-1, orig_shape[-1])\n",
    "        pte_data_flat = pte_scaler.fit_transform(pte_data_flat)\n",
    "        pte_data = pte_data_flat.reshape(orig_shape)\n",
    "\n",
    "        # Build labels\n",
    "        labels = np.full((pte_data.shape[0],), label_idx, dtype=int)\n",
    "\n",
    "        if subject_id == target_participant:\n",
    "            # Target domain\n",
    "            target_pte_data_list.append(pte_data)\n",
    "            target_pte_labels_list.append(labels)\n",
    "        else:\n",
    "            # Source domain\n",
    "            source_pte_data_list.append(pte_data)\n",
    "            source_pte_labels_list.append(labels)\n",
    "            # Store participant IDs (one per sample)\n",
    "            source_pte_pid_list.extend([subject_id] * pte_data.shape[0])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Load PSD data\n",
    "    # -------------------------------------------------------------------------\n",
    "    for file in psd_files_sorted:\n",
    "        match = re.search(r'sub-(\\d+)_.*_(\\w+)\\.npz', file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subject_id = int(match.group(1))\n",
    "        label_str = match.group(2).lower()\n",
    "\n",
    "        if label_str not in selected_classes:\n",
    "            continue\n",
    "\n",
    "        label_idx = label_map[label_str]\n",
    "        full_path = os.path.join(DE_directory, file)\n",
    "\n",
    "        data_npz = np.load(full_path, allow_pickle=True)\n",
    "        if \"DE_features\" not in data_npz:\n",
    "            continue\n",
    "\n",
    "        psd_data = data_npz[\"DE_features\"]  # shape: [N, 12, n_channels, n_bands], etc.\n",
    "        # print(psd_data.shape)\n",
    "        \n",
    "        # Select channels (assume 2nd dimension is channels):\n",
    "        # e.g., psd_data[:, :, selected_indices, :]\n",
    "        psd_data = psd_data[:, selected_indices, :]\n",
    "\n",
    "        # Normalize\n",
    "        orig_shape = psd_data.shape\n",
    "        psd_data_flat = psd_data.reshape(-1, orig_shape[-1])\n",
    "        psd_data_flat = psd_scaler.fit_transform(psd_data_flat)\n",
    "        psd_data = psd_data_flat.reshape(orig_shape)\n",
    "\n",
    "        labels = np.full((psd_data.shape[0],), label_idx, dtype=int)\n",
    "\n",
    "        if subject_id == target_participant:\n",
    "            target_psd_data_list.append(psd_data)\n",
    "            target_psd_labels_list.append(labels)\n",
    "        else:\n",
    "            source_psd_data_list.append(psd_data)\n",
    "            source_psd_labels_list.append(labels)\n",
    "            source_psd_pid_list.extend([subject_id] * psd_data.shape[0])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Concatenate source & target data\n",
    "    # -------------------------------------------------------------------------\n",
    "    def concat_arrays(array_list):\n",
    "        return np.concatenate(array_list, axis=0) if array_list else None\n",
    "\n",
    "    # Source PTE\n",
    "    source_pte_data = concat_arrays(source_pte_data_list)\n",
    "    source_pte_labels = concat_arrays(source_pte_labels_list)\n",
    "    source_pte_pids = np.array(source_pte_pid_list) if source_pte_pid_list else None\n",
    "\n",
    "    # Target PTE\n",
    "    target_pte_data = concat_arrays(target_pte_data_list)\n",
    "    target_pte_labels = concat_arrays(target_pte_labels_list)\n",
    "\n",
    "    # Source PSD\n",
    "    source_psd_data = concat_arrays(source_psd_data_list)\n",
    "    source_psd_labels = concat_arrays(source_psd_labels_list)\n",
    "    source_psd_pids = np.array(source_psd_pid_list) if source_psd_pid_list else None\n",
    "\n",
    "    # Target PSD\n",
    "    target_psd_data = concat_arrays(target_psd_data_list)\n",
    "    target_psd_labels = concat_arrays(target_psd_labels_list)\n",
    "\n",
    "    # print(\"\\nSource PTE data shape:\", source_pte_data.shape if source_pte_data is not None else None)\n",
    "    # print(\"Source PSD data shape:\", source_psd_data.shape if source_psd_data is not None else None)\n",
    "    # print(\"Target PTE data shape:\", target_pte_data.shape if target_pte_data is not None else None)\n",
    "    # print(\"Target PSD data shape:\", target_psd_data.shape if target_psd_data is not None else None)\n",
    "    \n",
    "    # Quick sanity check\n",
    "    if (\n",
    "        source_pte_data is None or source_pte_labels is None or\n",
    "        source_psd_data is None or source_psd_labels is None\n",
    "    ):\n",
    "        raise ValueError(\"No valid source data found (PTE or PSD).\")\n",
    "    if (\n",
    "        target_pte_data is None or target_pte_labels is None or\n",
    "        target_psd_data is None or target_psd_labels is None\n",
    "    ):\n",
    "        raise ValueError(\"No valid target data found (PTE or PSD).\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 7) Optionally apply SMOTE on the source data\n",
    "    # -------------------------------------------------------------------------\n",
    "    if apply_smote:\n",
    "        print(\"\\nApplying SMOTE to the source data...\")\n",
    "\n",
    "        # Flatten PTE and PSD for concatenation\n",
    "        orig_pte_shape = source_pte_data.shape\n",
    "        orig_psd_shape = source_psd_data.shape\n",
    "\n",
    "        pte_flat = source_pte_data.reshape(orig_pte_shape[0], -1)\n",
    "        psd_flat = source_psd_data.reshape(orig_psd_shape[0], -1)\n",
    "\n",
    "        # Concatenate features for SMOTE\n",
    "        combined_features = np.concatenate([pte_flat, psd_flat], axis=1)\n",
    "        combined_labels = source_pte_labels  # same as PSD labels in your setup\n",
    "\n",
    "        # SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        combined_resampled, labels_resampled = sm.fit_resample(combined_features, combined_labels)\n",
    "\n",
    "        # Count how many new (synthetic) samples were added\n",
    "        num_original = combined_features.shape[0]\n",
    "        num_new = combined_resampled.shape[0] - num_original\n",
    "        print(f\"SMOTE created {num_new} synthetic samples.\")\n",
    "\n",
    "        # Split back into PTE and PSD\n",
    "        pte_dim = pte_flat.shape[1]\n",
    "        psd_dim = psd_flat.shape[1]\n",
    "\n",
    "        pte_resampled = combined_resampled[:, :pte_dim]\n",
    "        psd_resampled = combined_resampled[:, pte_dim:]\n",
    "\n",
    "        # Reshape back\n",
    "        source_pte_data = pte_resampled.reshape(\n",
    "            -1,\n",
    "            orig_pte_shape[1],\n",
    "            orig_pte_shape[2],\n",
    "            orig_pte_shape[3],\n",
    "            orig_pte_shape[4]\n",
    "        )\n",
    "        source_psd_data = psd_resampled.reshape(\n",
    "            -1,\n",
    "            orig_psd_shape[1],\n",
    "            orig_psd_shape[2]\n",
    "        )\n",
    "\n",
    "        # Update labels\n",
    "        source_pte_labels = labels_resampled\n",
    "        source_psd_labels = labels_resampled\n",
    "\n",
    "        # For new (synthetic) samples, assign participant_id = -1 so they can be excluded in threshold tuning\n",
    "        pid_extended = np.concatenate([\n",
    "            source_pte_pids,\n",
    "            np.full(num_new, -1, dtype=int)\n",
    "        ])\n",
    "        source_pte_pids = pid_extended\n",
    "        source_psd_pids = pid_extended\n",
    "    else:\n",
    "        print(\"\\nSMOTE not applied to the source data.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 8) Convert to PyTorch Tensors\n",
    "    # -------------------------------------------------------------------------\n",
    "    def to_tensor(data, dtype=torch.float):\n",
    "        return torch.from_numpy(data).type(dtype)\n",
    "\n",
    "    source_pte_data_tensor = to_tensor(source_pte_data, torch.float)\n",
    "    source_psd_data_tensor = to_tensor(source_psd_data, torch.float)\n",
    "    source_labels_tensor = to_tensor(source_pte_labels, torch.long)\n",
    "    source_pid_tensor = to_tensor(source_pte_pids, torch.long)\n",
    "\n",
    "    target_pte_data_tensor = to_tensor(target_pte_data, torch.float)\n",
    "    target_psd_data_tensor = to_tensor(target_psd_data, torch.float)\n",
    "    target_labels_tensor = to_tensor(target_pte_labels, torch.long)\n",
    "    # Target doesn't need a participant ID (single participant).\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 9) Build TensorDatasets & DataLoaders\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Source dataset has participant IDs so we can do threshold tuning\n",
    "    source_dataset = TensorDataset(\n",
    "        source_pte_data_tensor,\n",
    "        source_psd_data_tensor,\n",
    "        source_labels_tensor,\n",
    "        source_pid_tensor\n",
    "    )\n",
    "    target_dataset = TensorDataset(\n",
    "        target_pte_data_tensor,\n",
    "        target_psd_data_tensor,\n",
    "        target_labels_tensor\n",
    "    )\n",
    "\n",
    "    source_dataloader = DataLoader(\n",
    "        source_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    target_dataloader = DataLoader(\n",
    "        target_dataset, batch_size=len(target_dataset), shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    return source_dataloader, target_dataloader\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Example usage\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    selected_channels = ['O2', 'C3', 'C4', 'Cz', 'T5', 'T6']\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=6,\n",
    "        batch_size=32,\n",
    "        selected_classes=[\"ctrl\", \"alz\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True    # Control SMOTE usage here\n",
    "    )\n",
    "    print(f\"\\nSource data: {len(source_dataloader.dataset)} samples (including any synthetic)\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples (single participant)\")\n",
    "\n",
    "    # Check a sample from the source DataLoader\n",
    "    for pte_batch, psd_batch, labels_batch, pid_batch in source_dataloader:\n",
    "        print(\"PTE Batch Shape:\", pte_batch.shape)\n",
    "        print(\"PSD Batch Shape:\", psd_batch.shape)\n",
    "        print(\"Labels Batch Shape:\", labels_batch.shape)\n",
    "        print(\"Participant IDs Batch Shape:\", pid_batch.shape)\n",
    "        break\n",
    "\n",
    "    # Check the target DataLoader\n",
    "    for pte_batch, psd_batch, labels_batch in target_dataloader:\n",
    "        print(\"TARGET PTE Batch Shape:\", pte_batch.shape)\n",
    "        print(\"TARGET PSD Batch Shape:\", psd_batch.shape)\n",
    "        print(\"TARGET Labels Shape:\", labels_batch.shape)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from itertools import cycle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    source_dataloader,\n",
    "    target_dataloader,\n",
    "    criterion_label,\n",
    "    criterion_domain,\n",
    "    optimizer,\n",
    "    num_epochs=10,\n",
    "    device=\"cuda\",\n",
    "    alpha_entropy = 0.01\n",
    "):\n",
    "   \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    accuracy_history = []\n",
    "    domain_accuracy_history = []\n",
    "\n",
    "    # Create an infinite iterator over the target dataloader\n",
    "    target_iter = cycle(target_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_domain_correct = 0\n",
    "        total_domain_samples = 0\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "\n",
    "        for i, batch_src in enumerate(source_dataloader):\n",
    "\n",
    "            if len(batch_src) == 4:\n",
    "                source_pte, source_psd, source_labels, _ = batch_src\n",
    "            else:\n",
    "                source_pte, source_psd, source_labels = batch_src\n",
    "\n",
    "            # Grab target batch\n",
    "            batch_tgt = next(target_iter)\n",
    "            if len(batch_tgt) == 3:\n",
    "                target_pte, target_psd, _ = batch_tgt\n",
    "            else:\n",
    "                # e.g., (target_pte, target_psd) if unlabeled\n",
    "                target_pte, target_psd = batch_tgt\n",
    "\n",
    "\n",
    "            # Move data to device\n",
    "            source_pte = source_pte.to(device)\n",
    "            source_psd = source_psd.to(device)\n",
    "            source_labels = source_labels.to(device)\n",
    "\n",
    "            target_pte = target_pte.to(device)\n",
    "            target_psd = target_psd.to(device)\n",
    "\n",
    "\n",
    "            label_preds, _ = model(\n",
    "                source_pte, source_psd\n",
    "            )\n",
    " \n",
    "            label_preds_target, _ = model(\n",
    "                target_pte, target_psd\n",
    "            )\n",
    "\n",
    "\n",
    "            loss_label = criterion_label(label_preds, source_labels)\n",
    "\n",
    "\n",
    "            total_loss = loss_label\n",
    "            # Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # -------------------------------\n",
    "            # Update Metrics\n",
    "            # -------------------------------\n",
    "            epoch_loss += loss_label.item()\n",
    "\n",
    "            # Label prediction accuracy (source)\n",
    "            _, predicted = torch.max(label_preds, dim=1)\n",
    "            correct = (predicted == source_labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += source_labels.size(0)\n",
    "\n",
    "\n",
    "        epoch_accuracy = 100.0 * total_correct / total_samples if total_samples > 0 else 0\n",
    "        epoch_domain_accuracy = 100.0 * total_domain_correct / total_domain_samples if total_domain_samples > 0 else 0\n",
    "\n",
    "        accuracy_history.append(epoch_accuracy)\n",
    "        domain_accuracy_history.append(epoch_domain_accuracy)\n",
    "\n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        #       f\"Label Acc: {epoch_accuracy:.2f}%, \"\n",
    "        #       f\"Domain Acc: {epoch_domain_accuracy:.2f}%\")\n",
    "\n",
    "    return accuracy_history, domain_accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def test_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    criterion_label: torch.nn.Module,\n",
    "    device: str = \"cuda\",\n",
    "    num_classes: int = 2,\n",
    "    alz_threshold: float = 0.4\n",
    ") -> Tuple[float, float, float, np.ndarray, np.ndarray, np.ndarray, float, int]:\n",
    "  \n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds_softmax = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            # ------------------------------------------------------\n",
    "            # 1) Handle batch size: 3 items or 4 items\n",
    "            # ------------------------------------------------------\n",
    "            # If your test dataloader returns 4 items (pte_batch, psd_batch, labels, pid):\n",
    "            if len(batch) == 4:\n",
    "                pte_batch, psd_batch, labels, _ = batch\n",
    "            elif len(batch) == 3:\n",
    "                pte_batch, psd_batch, labels = batch\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"DataLoader should return (pte_batch, psd_batch, labels) or 4 items. Got {len(batch)} items.\"\n",
    "                )\n",
    "\n",
    "            # Move data to device\n",
    "            pte_batch = pte_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "          \n",
    "            label_preds, _ = model(pte_batch, psd_batch)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 4) Compute classification loss\n",
    "            # ------------------------------------------------------\n",
    "            loss = criterion_label(label_preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 5) Softmax for predicted probabilities\n",
    "            # ------------------------------------------------------\n",
    "            softmax_output = F.softmax(label_preds, dim=1)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 6) Hard predictions\n",
    "            # ------------------------------------------------------\n",
    "            _, predicted = torch.max(softmax_output, dim=1)\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 7) Store predictions/probabilities/labels\n",
    "            # ------------------------------------------------------\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_preds_softmax.extend(softmax_output.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 8) Compute average loss\n",
    "    # ------------------------------------------------------\n",
    "    if len(test_dataloader) > 0:\n",
    "        avg_loss = total_loss / len(test_dataloader)\n",
    "    else:\n",
    "        avg_loss = 0.0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 9) Check if the participant has a single ground-truth label\n",
    "    # ------------------------------------------------------\n",
    "    all_labels = np.array(all_labels)\n",
    "    unique_lbls = np.unique(all_labels)\n",
    "    if len(unique_lbls) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Participant's test set has multiple labels: {unique_lbls}. \"\n",
    "            f\"Expected exactly 1 label per participant.\"\n",
    "        )\n",
    "\n",
    "    participant_true_label = unique_lbls[0]\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 10) Participant-level prediction\n",
    "    # ------------------------------------------------------\n",
    "    all_preds = np.array(all_preds)\n",
    "    alz_count = np.sum(all_preds == 1)\n",
    "    alz_ratio = alz_count / max(len(all_preds), 1)\n",
    "\n",
    "    if alz_ratio >= alz_threshold:\n",
    "        participant_pred_label = 1\n",
    "    else:\n",
    "        participant_pred_label = 0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 11) Construct participant-level confusion matrix\n",
    "    # ------------------------------------------------------\n",
    "    participant_conf_mat = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    participant_conf_mat[participant_true_label, participant_pred_label] += 1\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 12) Participant-level accuracy & F1\n",
    "    # ------------------------------------------------------\n",
    "    participant_acc = 100.0 if (participant_true_label == participant_pred_label) else 0.0\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    participant_f1 = f1_score(\n",
    "        [participant_true_label],\n",
    "        [participant_pred_label],\n",
    "        average='macro',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 13) Print debug info\n",
    "    # ------------------------------------------------------\n",
    "    print(f\"\\nParticipant True Label: {participant_true_label}\")\n",
    "    print(f\" -> #Predicted ALZ samples: {alz_count} / {len(all_preds)} = {alz_ratio:.2f}\")\n",
    "    print(f\" -> Threshold = {alz_threshold}; Final Participant Prediction: {participant_pred_label}\")\n",
    "    print(f\" -> Participant Accuracy: {participant_acc:.2f}%\")\n",
    "    print(f\" -> Participant F1 (Macro): {participant_f1:.4f}\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 14) Return results including alz_ratio and true label\n",
    "    # ------------------------------------------------------\n",
    "    all_preds_softmax = np.array(all_preds_softmax)  # shape: [N, num_classes]\n",
    "    return (\n",
    "        avg_loss,\n",
    "        participant_acc,\n",
    "        participant_f1,\n",
    "        participant_conf_mat,\n",
    "        all_preds_softmax,\n",
    "        all_labels,\n",
    "        alz_ratio,\n",
    "        participant_true_label\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def tune_threshold_on_source(\n",
    "    model,\n",
    "    source_dataloader,\n",
    "    device=\"cuda\",\n",
    "    thresholds=[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    num_classes=2\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    sample_preds = defaultdict(list)\n",
    "    participant_label = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in source_dataloader:\n",
    "            # If your source dataloader returns 4 items, including participant_id\n",
    "            if len(batch) == 4:\n",
    "                pte_batch, psd_batch, labels, pid_batch = batch\n",
    "            else:\n",
    "                raise ValueError(\"Expected Dataloader to return (pte, psd, labels, pid).\")\n",
    "\n",
    "            pte_batch = pte_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pid_batch = pid_batch.to(device)\n",
    "\n",
    "            # Forward pass (disable GRL in inference by setting lambda_=0)\n",
    "            label_preds, _ = model(pte_batch, psd_batch)\n",
    "\n",
    "            # Convert predictions to class=0/1\n",
    "            softmax_output = F.softmax(label_preds, dim=1)\n",
    "            _, predicted = torch.max(softmax_output, dim=1)\n",
    "\n",
    "            # Move to CPU\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            pid_batch = pid_batch.cpu().numpy()\n",
    "\n",
    "            # Store predictions for each participant\n",
    "            for pred, true_lbl, pid in zip(predicted, labels, pid_batch):\n",
    "                sample_preds[pid].append(pred)\n",
    "                # We assume all samples from participant pid share the same ground-truth label:\n",
    "                if pid not in participant_label:\n",
    "                    participant_label[pid] = true_lbl\n",
    "                else:\n",
    "                    # Optionally check that the label is consistent\n",
    "                    if participant_label[pid] != true_lbl:\n",
    "                        raise ValueError(f\"Inconsistent labels for participant {pid} in source data.\")\n",
    "\n",
    "    # Now we have sample-level predictions per participant. We'll try each threshold.\n",
    "    best_threshold = None\n",
    "    best_metric_val = -1.0\n",
    "\n",
    "    for thr in thresholds:\n",
    "        # For each threshold, generate participant-level predictions\n",
    "        # by counting how many samples predicted as class=1\n",
    "        part_level_preds = []\n",
    "        part_level_trues = []\n",
    "\n",
    "        for pid, preds_list in sample_preds.items():\n",
    "            true_lbl = participant_label[pid]\n",
    "            n_alz = sum([p == 1 for p in preds_list])\n",
    "            ratio = float(n_alz) / len(preds_list)\n",
    "            # Decide participant-level label\n",
    "            if ratio >= thr:\n",
    "                participant_pred = 1\n",
    "            else:\n",
    "                participant_pred = 0\n",
    "            \n",
    "            part_level_preds.append(participant_pred)\n",
    "            part_level_trues.append(true_lbl)\n",
    "\n",
    "        # Evaluate participant-level performance\n",
    "        # For example, we use F1 (macro):\n",
    "        f1 = f1_score(part_level_trues, part_level_preds, average='macro', zero_division=0)\n",
    "        acc = accuracy_score(part_level_trues, part_level_preds)\n",
    "\n",
    "        print(f\"[Threshold {thr}] -> F1={f1:.4f} | Acc={acc:.4f}\")\n",
    "\n",
    "        # Suppose we pick the threshold that maximizes participant-level F1\n",
    "        if f1 > best_metric_val:\n",
    "            best_metric_val = f1\n",
    "            best_threshold = thr\n",
    "\n",
    "    print(f\"\\n[Best Threshold] = {best_threshold} with F1={best_metric_val:.4f}\")\n",
    "    return best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n",
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Prediction Shape: torch.Size([32, 2])\n",
      "Attention Weights Shape: torch.Size([32, 11, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "FinalModel (FinalModel)                                      [32, 11, 180]        [32, 2]              --                   True\n",
       "├─PteTransformer (pte_transformer)                           [32, 11, 180]        [32, 11, 128]        318,032              True\n",
       "│    └─TransformerEncoder (transformer)                      [32, 11, 180]        [32, 11, 180]        --                   True\n",
       "│    │    └─ModuleList (layers)                              --                   --                   632,104              True\n",
       "│    └─Linear (output_layer)                                 [32, 11, 180]        [32, 11, 128]        23,168               True\n",
       "├─PsdTransformer (psd_transformer)                           [32, 6, 5]           [32, 6, 128]         5,777                True\n",
       "│    └─TransformerEncoder (transformer)                      [32, 6, 5]           [32, 6, 5]           --                   True\n",
       "│    │    └─ModuleList (layers)                              --                   --                   11,554               True\n",
       "│    └─Linear (output_layer)                                 [32, 6, 5]           [32, 6, 128]         768                  True\n",
       "├─MultiHeadCrossAttention (cross_attention)                  --                   [32, 11, 128]        --                   True\n",
       "│    └─MultiheadAttention (multihead_attn)                   [32, 11, 128]        [32, 11, 128]        66,048               True\n",
       "│    └─Dropout (dropout)                                     [32, 11, 128]        [32, 11, 128]        --                   --\n",
       "│    └─LayerNorm (layer_norm)                                [32, 11, 128]        [32, 11, 128]        256                  True\n",
       "├─Sequential (final_classifier)                              [32, 11, 128]        [32, 2]              --                   True\n",
       "│    └─Flatten (0)                                           [32, 11, 128]        [32, 1408]           --                   --\n",
       "│    └─Dropout (1)                                           [32, 1408]           [32, 1408]           --                   --\n",
       "│    └─Linear (2)                                            [32, 1408]           [32, 2]              2,818                True\n",
       "============================================================================================================================================\n",
       "Total params: 1,060,525\n",
       "Trainable params: 1,060,525\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 13.11\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 8.46\n",
       "Params size (MB): 1.64\n",
       "Estimated Total Size (MB): 10.36\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "# Define the Multi-Head Cross Attention Module\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "\n",
    "        super(MultiHeadCrossAttention, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
    "\n",
    "        # Apply MultiheadAttention; note that nn.MultiheadAttention expects inputs of shape (batch, seq, feature)\n",
    "        attn_output, attn_weights = self.multihead_attn(query, key, value, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        # Apply dropout\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        \n",
    "        # Add & Norm\n",
    "        output = self.layer_norm(query + attn_output)\n",
    "        \n",
    "        return output, attn_weights\n",
    "\n",
    "# Existing Transformer Classes (PteTransformer and PsdTransformer)\n",
    "class PteTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n",
    "        super(PteTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.position_encoding = nn.Parameter(torch.randn(1, 11, input_dim), requires_grad=True)\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)  # Project to desired output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, original_features)\n",
    "        \"\"\"\n",
    "        b = x.shape[0]\n",
    "        # Reshape to (batch_size, 11, input_dim//11) assuming input_dim is divisible by 11\n",
    "        x = x.reshape(b, 11, -1)\n",
    "        x = self.position_encoding + x  # (batch_size, 11, input_dim)\n",
    "        x = self.transformer(x)         # (batch_size, 11, input_dim)\n",
    "        x = self.output_layer(x)        # (batch_size, 11, output_dim)\n",
    "        return x\n",
    "\n",
    "class PsdTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n",
    "        super(PsdTransformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)  # Project to desired output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, original_features)\n",
    "        \"\"\"\n",
    "        # Assuming x is already of shape (batch_size, T_e, input_dim)\n",
    "        x = self.transformer(x)         # (batch_size, T_e, input_dim)\n",
    "        x = self.output_layer(x)        # (batch_size, T_e, output_dim)\n",
    "        return x\n",
    "\n",
    "# Updated Final Model with Multi-Head Cross Attention and DANN Components\n",
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pte_input_dim, pte_hidden_dim, pte_num_layers, pte_num_heads, pte_output_dim, pte_dropout,\n",
    "                 psd_input_dim, psd_hidden_dim, psd_num_layers, psd_num_heads, psd_output_dim, psd_dropout,\n",
    "                 cross_d_model, cross_num_heads,\n",
    "                 ):\n",
    "        super(FinalModel, self).__init__() \n",
    "\n",
    "        # Initialize PTE and PSD Transformers\n",
    "        self.pte_transformer = PteTransformer(\n",
    "            input_dim=pte_input_dim,\n",
    "            hidden_dim=pte_hidden_dim,\n",
    "            num_layers=pte_num_layers,\n",
    "            num_heads=pte_num_heads,\n",
    "            output_dim=pte_output_dim,\n",
    "            dropout=pte_dropout\n",
    "        )\n",
    "        \n",
    "        self.psd_transformer = PsdTransformer(\n",
    "            input_dim=psd_input_dim,\n",
    "            hidden_dim=psd_hidden_dim,\n",
    "            num_layers=psd_num_layers,\n",
    "            num_heads=psd_num_heads,\n",
    "            output_dim=psd_output_dim,\n",
    "            dropout=psd_dropout\n",
    "        )\n",
    "        \n",
    "        # Initialize Multi-Head Cross-Attention\n",
    "        self.cross_attention = MultiHeadCrossAttention(\n",
    "            d_model=cross_d_model,\n",
    "            num_heads=cross_num_heads,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        # Final Classifier for Label Prediction\n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(1408, 2)  # Adjust based on the sequence length (12 here)\n",
    "        )\n",
    "        \n",
    "    def forward(self, pte_input, psd_input):\n",
    "\n",
    "        # Pass through respective transformers\n",
    "        pte_encoded = self.pte_transformer(pte_input)  # (batch_size, T_pte=11, pte_output_dim=128)\n",
    "        psd_encoded = self.psd_transformer(psd_input)  # (batch_size, T_psd=6, psd_output_dim=128)\n",
    "        \n",
    "        # print(psd_encoded.shape)\n",
    "        # Apply multi-head cross-attention: Let pte_encoded attend to psd_encoded\n",
    "        cross_attn_output, attn_weights = self.cross_attention(\n",
    "            query=pte_encoded,      # (batch_size, T_q=11, d_model=128)\n",
    "            key=psd_encoded,        # (batch_size, T_k=6, d_model=128)\n",
    "            value=psd_encoded       # (batch_size, T_k=6, d_model=128)\n",
    "        )\n",
    "        \n",
    "        # Label Prediction\n",
    "        label_pred = self.final_classifier(cross_attn_output)  # (batch_size, 2)\n",
    "        \n",
    "        \n",
    "        return label_pred, attn_weights\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input tensors\n",
    "    # Adjust the shapes based on your actual data\n",
    "    # For illustration, assuming:\n",
    "    # pte_input has 11 time steps, each with (input_dim_pte / 11) features\n",
    "    x_1 = torch.randn(32, 11 * 5 * 6 * 6)  # (batch_size, pte_original_features)\n",
    "    # psd_input has sequence length 6 with 5 features each\n",
    "    x_2 = torch.randn(32, 6, 5)            # (batch_size, psd_seq_length, psd_original_features)\n",
    "    \n",
    "    # Define the model parameters\n",
    "    input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "    hidden_dim_pte = 512\n",
    "    num_layers_pte = 2\n",
    "    num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "    output_dim_pte = 128\n",
    "    dropout_pte = 0.1\n",
    "    \n",
    "    input_dim_psd = 5\n",
    "    hidden_dim_psd = 512\n",
    "    num_layers_psd = 2\n",
    "    num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "    output_dim_psd = 128\n",
    "    dropout_psd = 0.1\n",
    "    \n",
    "    cross_d_model = 128\n",
    "    cross_num_heads = 8   # Number of heads in cross-attention\n",
    "    \n",
    "    # Initialize the DANN model\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "    \n",
    "    # Example forward pass\n",
    "    label_pred, attn_weights = model(x_1, x_2)\n",
    "    print(\"Label Prediction Shape:\", label_pred.shape)        # Expected: (32, 2)\n",
    "    print(\"Attention Weights Shape:\", attn_weights.shape)\n",
    "    \n",
    "# summary(model, input_size=[(32, 11 * 5 * 6 * 6), (32, 6, 5)], col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20)\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model,\n",
    "        input_size=[(32, 11, 5 * 6 * 6), (32, 6, 5)], # (batch_size, color_channels, height, width)\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set the seed for PyTorch (both CPU and CUDA)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "    # Ensure deterministic behavior in PyTorch (if applicable)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set the seed for sklearn (via check_random_state)\n",
    "    _ = check_random_state(seed)\n",
    "\n",
    "    print(f\"Seed set to: {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 42\n",
      "\n",
      "===== Training for participant: 1 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE created 72 synthetic samples.\n",
      "Source data: 920 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 82.70%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8443\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 84.82%\n",
      "[Threshold 0.2] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8755\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 76 synthetic samples.\n",
      "Source data: 928 samples\n",
      "Target data: 5 samples\n",
      "Final Training Label Accuracy: 84.04%\n",
      "[Threshold 0.2] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8755\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 5 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 83.48%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8282\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 85.27%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8762 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8762\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 6 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "Source data: 918 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 84.71%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8914 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8919 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8919\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 5 / 10 = 0.50\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 7 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.58%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8603 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8755\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 8 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.03%\n",
      "[Threshold 0.2] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.9075 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9075\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 9 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 71 synthetic samples.\n",
      "Source data: 918 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 82.37%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8452 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 60 synthetic samples.\n",
      "Source data: 896 samples\n",
      "Target data: 21 samples\n",
      "Final Training Label Accuracy: 81.47%\n",
      "[Threshold 0.2] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8416\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 21 / 21 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 11 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 79.69%\n",
      "[Threshold 0.2] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8603 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 12 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 80.13%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8594\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 13 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.03%\n",
      "[Threshold 0.2] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8919 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8919\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 14 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 81.70%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8118 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8267\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 82.81%\n",
      "[Threshold 0.2] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.9071 | Acc=0.9077\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8919 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.9071\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 15 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 16 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 65 synthetic samples.\n",
      "Source data: 906 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.70%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8603 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 17 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8603 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 18 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.48%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8443 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8603 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 19 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 84.93%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8603 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8603\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 15 = 0.87\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.36%\n",
      "[Threshold 0.2] -> F1=0.7216 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.7400 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.7783 | Acc=0.7846\n",
      "[Threshold 0.5] -> F1=0.7952 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7952\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 21 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 66 synthetic samples.\n",
      "Source data: 908 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 82.25%\n",
      "[Threshold 0.2] -> F1=0.7400 | Acc=0.7538\n",
      "[Threshold 0.3] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7952 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7952\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 22 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 83.71%\n",
      "[Threshold 0.2] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.9077 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9077\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 13 = 0.77\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 23 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.36%\n",
      "[Threshold 0.2] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8769 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8923 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8923\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 13 = 0.54\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 24 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 81.58%\n",
      "[Threshold 0.2] -> F1=0.7580 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8431 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8431\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 25 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 84.60%\n",
      "[Threshold 0.2] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8755\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 11 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 26 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 83.04%\n",
      "[Threshold 0.2] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8431\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 27 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 81.81%\n",
      "[Threshold 0.2] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.4] -> F1=0.8769 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8923 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8923\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 28 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8922 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8922\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 29 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 79.91%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8762 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8762\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 30 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 72 synthetic samples.\n",
      "Source data: 920 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 83.15%\n",
      "[Threshold 0.2] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8431 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8431\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 9 / 9 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 31 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 62 synthetic samples.\n",
      "Source data: 900 samples\n",
      "Target data: 19 samples\n",
      "Final Training Label Accuracy: 82.81%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.9077 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9077\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 19 = 0.63\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 32 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 68 synthetic samples.\n",
      "Source data: 912 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 83.15%\n",
      "[Threshold 0.2] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8282 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8282 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8431\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 33 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 70 synthetic samples.\n",
      "Source data: 916 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8762 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8762\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 34 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 65 synthetic samples.\n",
      "Source data: 906 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.14%\n",
      "[Threshold 0.2] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8919 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8919\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 35 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 69 synthetic samples.\n",
      "Source data: 914 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 81.81%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8762 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8762\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 36 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 67 synthetic samples.\n",
      "Source data: 910 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 83.93%\n",
      "[Threshold 0.2] -> F1=0.8914 | Acc=0.8923\n",
      "[Threshold 0.3] -> F1=0.8922 | Acc=0.8923\n",
      "[Threshold 0.4] -> F1=0.8922 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.9077 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9077\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 37 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 81.92%\n",
      "[Threshold 0.2] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8594 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 38 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.03%\n",
      "[Threshold 0.2] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8755\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 39 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 80.25%\n",
      "[Threshold 0.2] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7501 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7725 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7725\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 14 = 0.07\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 40 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8594 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 41 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 81.47%\n",
      "[Threshold 0.2] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8914 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.9071 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9071\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 42 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.70%\n",
      "[Threshold 0.2] -> F1=0.7167 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.7167 | Acc=0.7385\n",
      "[Threshold 0.4] -> F1=0.7167 | Acc=0.7385\n",
      "[Threshold 0.5] -> F1=0.7543 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7543\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 16 = 0.06\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 43 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.25%\n",
      "[Threshold 0.2] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8267 | Acc=0.8308\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8267\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 13 = 0.23\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 44 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.92%\n",
      "[Threshold 0.2] -> F1=0.8745 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.9075 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9075\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 45 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 84.60%\n",
      "[Threshold 0.2] -> F1=0.8745 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.8907 | Acc=0.8923\n",
      "[Threshold 0.4] -> F1=0.9071 | Acc=0.9077\n",
      "[Threshold 0.5] -> F1=0.9071 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.9071\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 9 / 14 = 0.64\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 46 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 83.48%\n",
      "[Threshold 0.2] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8745 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8914 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8914 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8914\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 12 = 0.25\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 47 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.48%\n",
      "[Threshold 0.2] -> F1=0.8745 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8914 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.9075 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.9075\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 13 = 0.15\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 48 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 97 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 81.47%\n",
      "[Threshold 0.2] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.4] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.8431 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8431\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 49 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.47%\n",
      "[Threshold 0.2] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8914 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8914\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.92%\n",
      "[Threshold 0.2] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8099 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8443 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8443\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 6 / 13 = 0.46\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 51 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 83.71%\n",
      "[Threshold 0.2] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8594 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 12 = 0.17\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 52 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 82.92%\n",
      "[Threshold 0.2] -> F1=0.7871 | Acc=0.8000\n",
      "[Threshold 0.3] -> F1=0.8225 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.7929 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.8099 | Acc=0.8154\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8225\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 53 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.36%\n",
      "[Threshold 0.2] -> F1=0.8907 | Acc=0.8923\n",
      "[Threshold 0.3] -> F1=0.8755 | Acc=0.8769\n",
      "[Threshold 0.4] -> F1=0.8762 | Acc=0.8769\n",
      "[Threshold 0.5] -> F1=0.8762 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8907\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 54 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 83.26%\n",
      "[Threshold 0.2] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8594 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 55 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 80.58%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.4] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7929 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7929\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 56 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.81%\n",
      "[Threshold 0.2] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8755\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 9 / 13 = 0.69\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 57 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 83.82%\n",
      "[Threshold 0.2] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8594 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8594 | Acc=0.8615\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8594\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 58 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 80.92%\n",
      "[Threshold 0.2] -> F1=0.7167 | Acc=0.7385\n",
      "[Threshold 0.3] -> F1=0.7358 | Acc=0.7538\n",
      "[Threshold 0.4] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.5] -> F1=0.7756 | Acc=0.7846\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7756\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 1 / 12 = 0.08\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 59 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 84.26%\n",
      "[Threshold 0.2] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8603 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8919 | Acc=0.8923\n",
      "[Threshold 0.5] -> F1=0.8919 | Acc=0.8923\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8919\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 93 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 84.15%\n",
      "[Threshold 0.2] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.3] -> F1=0.8416 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8267 | Acc=0.8308\n",
      "[Threshold 0.5] -> F1=0.8431 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8431\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 61 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 82.03%\n",
      "[Threshold 0.2] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.3] -> F1=0.8248 | Acc=0.8308\n",
      "[Threshold 0.4] -> F1=0.8431 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8755\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 62 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.92%\n",
      "[Threshold 0.2] -> F1=0.8745 | Acc=0.8769\n",
      "[Threshold 0.3] -> F1=0.8907 | Acc=0.8923\n",
      "[Threshold 0.4] -> F1=0.9071 | Acc=0.9077\n",
      "[Threshold 0.5] -> F1=0.9071 | Acc=0.9077\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.9071\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 63 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 94 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 85.94%\n",
      "[Threshold 0.2] -> F1=0.7725 | Acc=0.7846\n",
      "[Threshold 0.3] -> F1=0.8077 | Acc=0.8154\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8755 | Acc=0.8769\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8755\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 64 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 82.48%\n",
      "[Threshold 0.2] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.3] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.4] -> F1=0.8582 | Acc=0.8615\n",
      "[Threshold 0.5] -> F1=0.8431 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8582\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 65 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 95 synthetic samples.\n",
      "Source data: 938 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 83.82%\n",
      "[Threshold 0.2] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7543 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7903 | Acc=0.8000\n",
      "[Threshold 0.5] -> F1=0.7903 | Acc=0.8000\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7903\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statistics import mode, StatisticsError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize accumulators for participant-level metrics\n",
    "participant_scores = []       # Aggregated scores (e.g., alz_ratio) per participant\n",
    "participant_labels_list = []  # Ground-truth labels per participant\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)  # Ensure reproducibility\n",
    "\n",
    "# Define the model parameters\n",
    "# Define the model parameters\n",
    "input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "hidden_dim_pte = 512\n",
    "num_layers_pte = 2\n",
    "num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "output_dim_pte = 128\n",
    "dropout_pte = 0.4\n",
    "\n",
    "input_dim_psd = 5\n",
    "hidden_dim_psd = 512\n",
    "num_layers_psd = 2\n",
    "num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "output_dim_psd = 128\n",
    "dropout_psd = 0.4\n",
    "\n",
    "cross_d_model = 128\n",
    "cross_num_heads = 8   # Number of heads in cross-attention\n",
    "\n",
    "# Accumulators for overall metrics\n",
    "all_acc = []\n",
    "all_f1 = []\n",
    "all_conf = []\n",
    "\n",
    "# For global sample-level AUC\n",
    "global_probs = []\n",
    "global_labels = []\n",
    "\n",
    "best_thresholds = []  # Store the chosen threshold for each participant\n",
    "\n",
    "for participant in range(1, 66):\n",
    "    print(f\"\\n===== Training for participant: {participant} =====\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 1) Initialize the model\n",
    "    # --------------------------\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 2) Load data\n",
    "    #    (Ensure your source_dataloader returns (pte, psd, labels, participant_id))\n",
    "    # --------------------------\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=participant,\n",
    "        batch_size=128,\n",
    "        selected_classes=[\"ctrl\", \"alz\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Source data: {len(source_dataloader.dataset)} samples\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 3) Define Loss & Optimizer\n",
    "    # --------------------------\n",
    "    class_weights = torch.tensor([0.8, 1.0], dtype=torch.float32, device=device)\n",
    "    criterion_label = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_domain = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5) # 8e-5\n",
    "\n",
    "    # --------------------------\n",
    "    # 4) Train Model (DANN)\n",
    "    # --------------------------\n",
    "    num_epochs = 100\n",
    "    lambda_grl = 0.0  # or use a schedule\n",
    "    label_acc_history, domain_acc_history = train_model(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        target_dataloader=target_dataloader,\n",
    "        criterion_label=criterion_label,\n",
    "        criterion_domain=criterion_domain,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device    )\n",
    "    print(f\"Final Training Label Accuracy: {label_acc_history[-1]:.2f}%\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 5) Tune Threshold on Source\n",
    "    # --------------------------\n",
    "    # This step requires that your source_dataloader yield participant IDs\n",
    "    thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n",
    "    best_thr = tune_threshold_on_source(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        device=device,\n",
    "        thresholds=thresholds_to_try,\n",
    "        num_classes=2\n",
    "    )\n",
    "    best_thresholds.append(best_thr)\n",
    "\n",
    "    # --------------------------\n",
    "    # 6) Test on Target\n",
    "    # --------------------------\n",
    "    # We use the threshold we found above\n",
    "    test_loss, test_acc, test_f1_score_part, participant_conf_mat, \\\n",
    "        participant_preds_softmax, participant_labels, alz_ratio, participant_true_label = test_model(\n",
    "            model=model,\n",
    "            test_dataloader=target_dataloader,\n",
    "            criterion_label=criterion_label,\n",
    "            device=device,\n",
    "            num_classes=2,\n",
    "            alz_threshold=best_thr,  # <--- using the best threshold\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 7) Store Participant-Level Metrics\n",
    "    # --------------------------\n",
    "    all_acc.append(test_acc)\n",
    "    all_f1.append(test_f1_score_part)\n",
    "    all_conf.append(participant_conf_mat)\n",
    "\n",
    "    global_probs.append(participant_preds_softmax)\n",
    "    global_labels.append(participant_labels)\n",
    "\n",
    "    # Collect participant-level score and label for ROC AUC\n",
    "    participant_scores.append(alz_ratio)               # Using alz_ratio as the score\n",
    "    participant_labels_list.append(participant_true_label)  # Ground-truth label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Final Summary ==================\n",
      "Overall Participant-Level Accuracy: 83.08%\n",
      "Overall Participant-Level F1 (Macro): 0.8308\n",
      "Participant-Level Confusion Matrix (summed):\n",
      "[[22  7]\n",
      " [ 4 32]]\n",
      "\n",
      "Best thresholds chosen per participant:\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.4, 0.3, 0.4, 0.2, 0.3, 0.4, 0.3, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.4, 0.5, 0.5, 0.4, 0.5, 0.5, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.4, 0.3, 0.2, 0.5, 0.5, 0.5, 0.4, 0.5, 0.4, 0.5, 0.5, 0.4, 0.5, 0.2, 0.4]\n",
      "Common threshold across all participants: 0.5\n",
      "\n",
      "Participant-Level ROC AUC: 0.8214\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Summarize results across participants\n",
    "# ------------------------------------------------------------------------------\n",
    "mean_accuracy = np.mean(all_acc)\n",
    "mean_f1 = np.mean(all_f1)\n",
    "total_conf_mat = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "print(\"\\n================== Final Summary ==================\")\n",
    "print(f\"Overall Participant-Level Accuracy: {mean_accuracy:.2f}%\")\n",
    "print(f\"Overall Participant-Level F1 (Macro): {mean_f1:.4f}\")\n",
    "print(\"Participant-Level Confusion Matrix (summed):\")\n",
    "print(total_conf_mat)\n",
    "\n",
    "# Show distribution of best thresholds across participants\n",
    "print(\"\\nBest thresholds chosen per participant:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "# If you want a single global threshold, you can do:\n",
    "try:\n",
    "    common_threshold = mode(best_thresholds)\n",
    "except StatisticsError:\n",
    "    # Fallback if no unique mode exists\n",
    "    common_threshold = np.median(best_thresholds)\n",
    "print(f\"Common threshold across all participants: {common_threshold}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Compute Participant-Level ROC AUC\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "participant_scores = np.array(participant_scores)           # shape: [num_participants]\n",
    "participant_labels = np.array(participant_labels_list)     # shape: [num_participants]\n",
    "\n",
    "# Check if there are both classes present\n",
    "unique_participant_labels = np.unique(participant_labels)\n",
    "if len(unique_participant_labels) == 2:\n",
    "    participant_auc = roc_auc_score(participant_labels, participant_scores)\n",
    "    print(f\"\\nParticipant-Level ROC AUC: {participant_auc:.4f}\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(participant_labels, participant_scores)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {participant_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Participant-Level ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, save the ROC curve plot\n",
    "    plt.savefig('participant_level_roc_curve.png')\n",
    "else:\n",
    "    print(\"\\nParticipant-Level ROC AUC not computed (only one class present).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_predictions = []\n",
    "for i in range(len(all_acc)):\n",
    "    if participant_labels[i] == 1:  # Non-control\n",
    "        predicted = 1 if all_acc[i] == 100.0 else 0\n",
    "    else:                           # Control\n",
    "        predicted = 0 if all_acc[i] == 100.0 else 1\n",
    "    participant_predictions.append(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[22  7]\n",
      " [ 4 32]]\n",
      "Accuracy:  0.831\n",
      "Precision: 0.821\n",
      "Recall:    0.889\n",
      "F1 score:  0.853\n",
      "Specificity: 0.759\n",
      "ROC AUC:   0.821\n",
      "Avg Precision: 0.810\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        29\n",
      "           1       0.82      0.89      0.85        36\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.83      0.82      0.83        65\n",
      "weighted avg       0.83      0.83      0.83        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, average_precision_score)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "# 1. If you want binary predictions, pick a threshold (commonly 0.5).\n",
    "# threshold = 0.5\n",
    "# participant_pred = (participant_scores >= threshold).astype(int)\n",
    "\n",
    "participant_pred = participant_predictions\n",
    "# 2. Confusion matrix (needs binary predictions)\n",
    "cm = confusion_matrix(participant_labels, participant_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Accuracy, Precision, Recall, F1 (all use binary predictions)\n",
    "acc = accuracy_score(participant_labels, participant_pred)\n",
    "prec = precision_score(participant_labels, participant_pred)\n",
    "rec = recall_score(participant_labels, participant_pred)\n",
    "f1 = f1_score(participant_labels, participant_pred)\n",
    "spec = specificity_score(participant_labels, participant_pred)\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 score:  {f1:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "\n",
    "# 4. ROC AUC (needs the raw probability or score, not just a hard prediction)\n",
    "auc = roc_auc_score(participant_labels, participant_scores)\n",
    "print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "# 5. Average Precision (also uses the raw score)\n",
    "avg_prec = average_precision_score(participant_labels, participant_scores)\n",
    "print(f\"Avg Precision: {avg_prec:.3f}\")\n",
    "\n",
    "# 6. Classification report (includes precision, recall, f1 for each class)\n",
    "report = classification_report(participant_labels, participant_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[22  7]\n",
      " [ 4 32]]\n",
      "Accuracy:    0.831\n",
      "Precision:   0.821\n",
      "Recall:      0.889\n",
      "Specificity: 0.759\n",
      "F1 Score:    0.853\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example confusion matrices (replace with your actual data)\n",
    "# all_conf = [\n",
    "#     [[22, 7],\n",
    "#      [4, 32]],\n",
    "#     # Add more confusion matrices if needed\n",
    "# ]\n",
    "\n",
    "# Sum the confusion matrices\n",
    "cm = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "# Unpack the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0        # a.k.a. Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:    {accuracy:.3f}\")\n",
    "print(f\"Precision:   {precision:.3f}\")\n",
    "print(f\"Recall:      {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1 Score:    {f1:.3f}\")\n",
    "\n",
    "# Define class labels\n",
    "labels = ['CN', \"AD\"]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    annot_kws={\"size\": 16}  # Increase annotation font size here\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = torch.tensor([1.0, 0.8], dtype=torch.float32, device=device)\n",
    "# Confusion Matrix:\n",
    "# [[25  4]\n",
    "#  [ 7 29]]\n",
    "# Accuracy:    0.831\n",
    "# Precision:   0.879\n",
    "# Recall:      0.806\n",
    "# Specificity: 0.862\n",
    "# F1 Score:    0.841\n",
    "## class_weights = torch.tensor([1.0, 0.6], dtype=torch.float32, device=device)\n",
    "# Confusion Matrix:\n",
    "# [[26  3]\n",
    "#  [ 7 29]]\n",
    "# Accuracy:    0.846\n",
    "# Precision:   0.906\n",
    "# Recall:      0.806\n",
    "# Specificity: 0.897\n",
    "# F1 Score:    0.853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ALZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 42\n",
      "\n",
      "===== Training for participant: 37 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Label Accuracy: 69.22%\n",
      "[Threshold 0.2] -> F1=0.8459 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8253 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8424 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8424 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8459\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 38 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.53%\n",
      "[Threshold 0.2] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7692 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7692\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 39 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 64.84%\n",
      "[Threshold 0.2] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7661 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7692\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 40 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 68.91%\n",
      "[Threshold 0.2] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7661 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7692\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 16 = 0.12\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 41 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 68.12%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7304 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7304\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 42 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 63.59%\n",
      "[Threshold 0.2] -> F1=0.8051 | Acc=0.8077\n",
      "[Threshold 0.3] -> F1=0.8003 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8051\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 16 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 43 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 71.09%\n",
      "[Threshold 0.2] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7271 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7492\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 44 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.53%\n",
      "[Threshold 0.2] -> F1=0.8253 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8253\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 45 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.53%\n",
      "[Threshold 0.2] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7636 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7865\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 3 / 14 = 0.21\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 46 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 68.75%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7454 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 2 / 12 = 0.17\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 47 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.22%\n",
      "[Threshold 0.2] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7786 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7512 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7969\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 48 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 108 synthetic samples.\n",
      "Source data: 744 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 70.00%\n",
      "[Threshold 0.2] -> F1=0.7304 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7499 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7692\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 11 / 16 = 0.69\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 49 =====\n",
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Label Accuracy: 69.69%\n",
      "[Threshold 0.2] -> F1=0.7692 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8074 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.8065 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7865 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8074\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 66.88%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7308 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7308 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7308 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7308\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 10 / 13 = 0.77\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 51 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 69.84%\n",
      "[Threshold 0.2] -> F1=0.7884 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7884 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7878 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7884\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 12 / 12 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 52 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 66.56%\n",
      "[Threshold 0.2] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7692 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7692\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 53 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.66%\n",
      "[Threshold 0.2] -> F1=0.7636 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7604 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7636\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 54 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 67.34%\n",
      "[Threshold 0.2] -> F1=0.7308 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7499 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7499\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 55 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 62.81%\n",
      "[Threshold 0.2] -> F1=0.7884 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.8237 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8237\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 56 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 69.38%\n",
      "[Threshold 0.2] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.7304 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7304\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 57 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 65.94%\n",
      "[Threshold 0.2] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7477 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7499\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 58 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 65.94%\n",
      "[Threshold 0.2] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.3] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.4] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8154\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 59 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 72.50%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7636 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7661\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 112 synthetic samples.\n",
      "Source data: 752 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 69.06%\n",
      "[Threshold 0.2] -> F1=0.8649 | Acc=0.8654\n",
      "[Threshold 0.3] -> F1=0.8237 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8424 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8216 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8649\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 8 / 12 = 0.67\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 61 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 68.44%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7689 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7689 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7689\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 62 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 66.88%\n",
      "[Threshold 0.2] -> F1=0.8237 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7744 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8237\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 63 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 111 synthetic samples.\n",
      "Source data: 750 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 73.44%\n",
      "[Threshold 0.2] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7242 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7271\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 11 / 13 = 0.85\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 64 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 68.44%\n",
      "[Threshold 0.2] -> F1=0.7636 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7562 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7562 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7636\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 0 / 14 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 65 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 110 synthetic samples.\n",
      "Source data: 748 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.22%\n",
      "[Threshold 0.2] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7499 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7679\n",
      "\n",
      "Participant True Label: 0\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 66 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 71.35%\n",
      "[Threshold 0.2] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7383 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7744 | Acc=0.7885\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7744\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 9 = 0.78\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 67 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 68.23%\n",
      "[Threshold 0.2] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7636 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7679\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 68 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 70.44%\n",
      "[Threshold 0.2] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7271 | Acc=0.7308\n",
      "[Threshold 0.4] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7242 | Acc=0.7308\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7679\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 9 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 69 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 70.44%\n",
      "[Threshold 0.2] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.3] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7819 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.8375 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8375\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 6 / 10 = 0.60\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 70 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 131 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 7 samples\n",
      "Final Training Label Accuracy: 71.09%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8188 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8216\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 7 / 7 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 71 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 71.61%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.7969 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.7451 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8188\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 8 / 10 = 0.80\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 72 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 69.66%\n",
      "[Threshold 0.2] -> F1=0.7242 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7969 | Acc=0.8077\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7969\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 73 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 138 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 69.79%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7846 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.8030 | Acc=0.8077\n",
      "[Threshold 0.5] -> F1=0.8402 | Acc=0.8462\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.8402\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 1 / 14 = 0.07\n",
      " -> Threshold = 0.5; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 74 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 140 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 16 samples\n",
      "Final Training Label Accuracy: 70.70%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7423 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 16 / 16 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 75 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 136 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 69.66%\n",
      "[Threshold 0.2] -> F1=0.7636 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.8154\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 76 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.44%\n",
      "[Threshold 0.2] -> F1=0.8216 | Acc=0.8269\n",
      "[Threshold 0.3] -> F1=0.8402 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8402 | Acc=0.8462\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.8402\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 4 / 13 = 0.31\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 77 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 135 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 11 samples\n",
      "Final Training Label Accuracy: 68.23%\n",
      "[Threshold 0.2] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7292 | Acc=0.7308\n",
      "[Threshold 0.5] -> F1=0.7661 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7661\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 11 / 11 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 78 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 138 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 14 samples\n",
      "Final Training Label Accuracy: 67.06%\n",
      "[Threshold 0.2] -> F1=0.7114 | Acc=0.7115\n",
      "[Threshold 0.3] -> F1=0.6923 | Acc=0.6923\n",
      "[Threshold 0.4] -> F1=0.7106 | Acc=0.7115\n",
      "[Threshold 0.5] -> F1=0.6905 | Acc=0.6923\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7114\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 14 / 14 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 79 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 72.53%\n",
      "[Threshold 0.2] -> F1=0.8341 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8112 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.8112 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.7115 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8341\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 13 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 80 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 139 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 72.14%\n",
      "[Threshold 0.2] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.4] -> F1=0.7865 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7679 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7865\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 15 = 0.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 81 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 70.70%\n",
      "[Threshold 0.2] -> F1=0.8375 | Acc=0.8462\n",
      "[Threshold 0.3] -> F1=0.8154 | Acc=0.8269\n",
      "[Threshold 0.4] -> F1=0.7693 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7451 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8375\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 13 / 13 = 1.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 82 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 136 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 12 samples\n",
      "Final Training Label Accuracy: 70.57%\n",
      "[Threshold 0.2] -> F1=0.7661 | Acc=0.7692\n",
      "[Threshold 0.3] -> F1=0.7423 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7604 | Acc=0.7692\n",
      "[Threshold 0.5] -> F1=0.7604 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7661\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 0 / 12 = 0.00\n",
      " -> Threshold = 0.2; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n",
      "\n",
      "===== Training for participant: 83 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 139 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 15 samples\n",
      "Final Training Label Accuracy: 68.23%\n",
      "[Threshold 0.2] -> F1=0.6882 | Acc=0.6923\n",
      "[Threshold 0.3] -> F1=0.7088 | Acc=0.7115\n",
      "[Threshold 0.4] -> F1=0.7499 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7689 | Acc=0.7692\n",
      "\n",
      "[Best Threshold] = 0.5 with F1=0.7689\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 15 / 15 = 1.00\n",
      " -> Threshold = 0.5; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 84 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 64.45%\n",
      "[Threshold 0.2] -> F1=0.7308 | Acc=0.7308\n",
      "[Threshold 0.3] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7492 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7492\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.3; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 85 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 67.71%\n",
      "[Threshold 0.2] -> F1=0.8818 | Acc=0.8846\n",
      "[Threshold 0.3] -> F1=0.8402 | Acc=0.8462\n",
      "[Threshold 0.4] -> F1=0.8188 | Acc=0.8269\n",
      "[Threshold 0.5] -> F1=0.8154 | Acc=0.8269\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.8818\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 6 / 9 = 0.67\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 86 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 133 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 9 samples\n",
      "Final Training Label Accuracy: 67.84%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7454 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7454 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.2 with F1=0.7477\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 4 / 9 = 0.44\n",
      " -> Threshold = 0.2; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 87 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 134 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 10 samples\n",
      "Final Training Label Accuracy: 66.41%\n",
      "[Threshold 0.2] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.4] -> F1=0.7878 | Acc=0.7885\n",
      "[Threshold 0.5] -> F1=0.7499 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.4 with F1=0.7878\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 10 / 10 = 1.00\n",
      " -> Threshold = 0.4; Final Participant Prediction: 1\n",
      " -> Participant Accuracy: 100.00%\n",
      " -> Participant F1 (Macro): 1.0000\n",
      "\n",
      "===== Training for participant: 88 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.dharia-ra/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the source data...\n",
      "SMOTE created 137 synthetic samples.\n",
      "Source data: 776 samples\n",
      "Target data: 13 samples\n",
      "Final Training Label Accuracy: 66.93%\n",
      "[Threshold 0.2] -> F1=0.7492 | Acc=0.7500\n",
      "[Threshold 0.3] -> F1=0.7679 | Acc=0.7692\n",
      "[Threshold 0.4] -> F1=0.7477 | Acc=0.7500\n",
      "[Threshold 0.5] -> F1=0.7477 | Acc=0.7500\n",
      "\n",
      "[Best Threshold] = 0.3 with F1=0.7679\n",
      "\n",
      "Participant True Label: 1\n",
      " -> #Predicted ALZ samples: 3 / 13 = 0.23\n",
      " -> Threshold = 0.3; Final Participant Prediction: 0\n",
      " -> Participant Accuracy: 0.00%\n",
      " -> Participant F1 (Macro): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from statistics import mode, StatisticsError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize accumulators for participant-level metrics\n",
    "participant_scores = []       # Aggregated scores (e.g., alz_ratio) per participant\n",
    "participant_labels_list = []  # Ground-truth labels per participant\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)  # Ensure reproducibility\n",
    "\n",
    "# Define the model parameters\n",
    "# Define the model parameters\n",
    "input_dim_pte = 180   # Example: 11 * 5 * 6 * 6 = 180\n",
    "hidden_dim_pte = 512\n",
    "num_layers_pte = 2\n",
    "num_heads_pte = 5     # Typically, num_heads should divide d_model\n",
    "output_dim_pte = 128\n",
    "dropout_pte = 0.4\n",
    "\n",
    "input_dim_psd = 5\n",
    "hidden_dim_psd = 512\n",
    "num_layers_psd = 2\n",
    "num_heads_psd = 5    # Typically, num_heads should divide d_model\n",
    "output_dim_psd = 128\n",
    "dropout_psd = 0.4\n",
    "\n",
    "cross_d_model = 128\n",
    "cross_num_heads = 8   # Number of heads in cross-attention\n",
    "\n",
    "# Accumulators for overall metrics\n",
    "all_acc = []\n",
    "all_f1 = []\n",
    "all_conf = []\n",
    "\n",
    "# For global sample-level AUC\n",
    "global_probs = []\n",
    "global_labels = []\n",
    "\n",
    "best_thresholds = []  # Store the chosen threshold for each participant\n",
    "\n",
    "for participant in range(37, 89):\n",
    "    print(f\"\\n===== Training for participant: {participant} =====\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 1) Initialize the model\n",
    "    # --------------------------\n",
    "    model = FinalModel(\n",
    "        pte_input_dim=input_dim_pte, \n",
    "        pte_hidden_dim=hidden_dim_pte, \n",
    "        pte_num_layers=num_layers_pte, \n",
    "        pte_num_heads=num_heads_pte, \n",
    "        pte_output_dim=output_dim_pte, \n",
    "        pte_dropout=dropout_pte,\n",
    "        psd_input_dim=input_dim_psd, \n",
    "        psd_hidden_dim=hidden_dim_psd, \n",
    "        psd_num_layers=num_layers_psd, \n",
    "        psd_num_heads=num_heads_psd, \n",
    "        psd_output_dim=output_dim_psd, \n",
    "        psd_dropout=dropout_psd,\n",
    "        cross_d_model=cross_d_model, \n",
    "        cross_num_heads=cross_num_heads\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 2) Load data\n",
    "    #    (Ensure your source_dataloader returns (pte, psd, labels, participant_id))\n",
    "    # --------------------------\n",
    "    source_dataloader, target_dataloader = load_combined_data(\n",
    "        pte_directory=\"features\",\n",
    "        DE_directory=\"DE_features_single_window\",\n",
    "        target_participant=participant,\n",
    "        batch_size=128,\n",
    "        selected_classes=[\"ctrl\", \"ftd\"],\n",
    "        selected_channels=selected_channels,\n",
    "        apply_smote=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Source data: {len(source_dataloader.dataset)} samples\")\n",
    "    print(f\"Target data: {len(target_dataloader.dataset)} samples\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 3) Define Loss & Optimizer\n",
    "    # --------------------------\n",
    "    class_weights = torch.tensor([1.0, 0.8], dtype=torch.float32, device=device)\n",
    "    criterion_label = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_domain = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5) # 8e-5\n",
    "\n",
    "    # --------------------------\n",
    "    # 4) Train Model (DANN)\n",
    "    # --------------------------\n",
    "    num_epochs = 100\n",
    "    lambda_grl = 0.0  # or use a schedule\n",
    "    label_acc_history, domain_acc_history = train_model(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        target_dataloader=target_dataloader,\n",
    "        criterion_label=criterion_label,\n",
    "        criterion_domain=criterion_domain,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device    )\n",
    "    print(f\"Final Training Label Accuracy: {label_acc_history[-1]:.2f}%\")\n",
    "\n",
    "    # --------------------------\n",
    "    # 5) Tune Threshold on Source\n",
    "    # --------------------------\n",
    "    # This step requires that your source_dataloader yield participant IDs\n",
    "    thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n",
    "    best_thr = tune_threshold_on_source(\n",
    "        model=model,\n",
    "        source_dataloader=source_dataloader,\n",
    "        device=device,\n",
    "        thresholds=thresholds_to_try,\n",
    "        num_classes=2\n",
    "    )\n",
    "    best_thresholds.append(best_thr)\n",
    "\n",
    "    # --------------------------\n",
    "    # 6) Test on Target\n",
    "    # --------------------------\n",
    "    # We use the threshold we found above\n",
    "    test_loss, test_acc, test_f1_score_part, participant_conf_mat, \\\n",
    "        participant_preds_softmax, participant_labels, alz_ratio, participant_true_label = test_model(\n",
    "            model=model,\n",
    "            test_dataloader=target_dataloader,\n",
    "            criterion_label=criterion_label,\n",
    "            device=device,\n",
    "            num_classes=2,\n",
    "            alz_threshold=best_thr,  # <--- using the best threshold\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 7) Store Participant-Level Metrics\n",
    "    # --------------------------\n",
    "    all_acc.append(test_acc)\n",
    "    all_f1.append(test_f1_score_part)\n",
    "    all_conf.append(participant_conf_mat)\n",
    "\n",
    "    global_probs.append(participant_preds_softmax)\n",
    "    global_labels.append(participant_labels)\n",
    "\n",
    "    # Collect participant-level score and label for ROC AUC\n",
    "    participant_scores.append(alz_ratio)               # Using alz_ratio as the score\n",
    "    participant_labels_list.append(participant_true_label)  # Ground-truth label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Final Summary ==================\n",
      "Overall Participant-Level Accuracy: 71.15%\n",
      "Overall Participant-Level F1 (Macro): 0.7115\n",
      "Participant-Level Confusion Matrix (summed):\n",
      "[[21  8]\n",
      " [ 7 16]]\n",
      "\n",
      "Best thresholds chosen per participant:\n",
      "[0.2, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.3, 0.3, 0.2, 0.5, 0.2, 0.3, 0.5, 0.5, 0.2, 0.4, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.4, 0.5, 0.2, 0.2, 0.5, 0.3, 0.3, 0.5, 0.5, 0.2, 0.4, 0.3, 0.5, 0.2, 0.2, 0.3, 0.2, 0.2, 0.5, 0.3, 0.2, 0.2, 0.4, 0.3]\n",
      "Common threshold across all participants: 0.2\n",
      "\n",
      "Participant-Level ROC AUC: 0.7526\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Summarize results across participants\n",
    "# ------------------------------------------------------------------------------\n",
    "mean_accuracy = np.mean(all_acc)\n",
    "mean_f1 = np.mean(all_f1)\n",
    "total_conf_mat = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "print(\"\\n================== Final Summary ==================\")\n",
    "print(f\"Overall Participant-Level Accuracy: {mean_accuracy:.2f}%\")\n",
    "print(f\"Overall Participant-Level F1 (Macro): {mean_f1:.4f}\")\n",
    "print(\"Participant-Level Confusion Matrix (summed):\")\n",
    "print(total_conf_mat)\n",
    "\n",
    "# Show distribution of best thresholds across participants\n",
    "print(\"\\nBest thresholds chosen per participant:\")\n",
    "print(best_thresholds)\n",
    "\n",
    "# If you want a single global threshold, you can do:\n",
    "try:\n",
    "    common_threshold = mode(best_thresholds)\n",
    "except StatisticsError:\n",
    "    # Fallback if no unique mode exists\n",
    "    common_threshold = np.median(best_thresholds)\n",
    "print(f\"Common threshold across all participants: {common_threshold}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Compute Participant-Level ROC AUC\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "participant_scores = np.array(participant_scores)           # shape: [num_participants]\n",
    "participant_labels = np.array(participant_labels_list)     # shape: [num_participants]\n",
    "\n",
    "# Check if there are both classes present\n",
    "unique_participant_labels = np.unique(participant_labels)\n",
    "if len(unique_participant_labels) == 2:\n",
    "    participant_auc = roc_auc_score(participant_labels, participant_scores)\n",
    "    print(f\"\\nParticipant-Level ROC AUC: {participant_auc:.4f}\")\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(participant_labels, participant_scores)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {participant_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Participant-Level ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, save the ROC curve plot\n",
    "    plt.savefig('participant_level_roc_curve.png')\n",
    "else:\n",
    "    print(\"\\nParticipant-Level ROC AUC not computed (only one class present).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_predictions = []\n",
    "for i in range(len(all_acc)):\n",
    "    if participant_labels[i] == 1:  # Non-control\n",
    "        predicted = 1 if all_acc[i] == 100.0 else 0\n",
    "    else:                           # Control\n",
    "        predicted = 0 if all_acc[i] == 100.0 else 1\n",
    "    participant_predictions.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[21  8]\n",
      " [ 7 16]]\n",
      "Accuracy:  0.712\n",
      "Precision: 0.667\n",
      "Recall:    0.696\n",
      "F1 score:  0.681\n",
      "Specificity: 0.724\n",
      "ROC AUC:   0.753\n",
      "Avg Precision: 0.671\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74        29\n",
      "           1       0.67      0.70      0.68        23\n",
      "\n",
      "    accuracy                           0.71        52\n",
      "   macro avg       0.71      0.71      0.71        52\n",
      "weighted avg       0.71      0.71      0.71        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, average_precision_score)\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "# 1. If you want binary predictions, pick a threshold (commonly 0.5).\n",
    "# threshold = 0.5\n",
    "# participant_pred = (participant_scores >= threshold).astype(int)\n",
    "\n",
    "participant_pred = participant_predictions\n",
    "# 2. Confusion matrix (needs binary predictions)\n",
    "cm = confusion_matrix(participant_labels, participant_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 3. Accuracy, Precision, Recall, F1 (all use binary predictions)\n",
    "acc = accuracy_score(participant_labels, participant_pred)\n",
    "prec = precision_score(participant_labels, participant_pred)\n",
    "rec = recall_score(participant_labels, participant_pred)\n",
    "f1 = f1_score(participant_labels, participant_pred)\n",
    "spec = specificity_score(participant_labels, participant_pred)\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 score:  {f1:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "\n",
    "# 4. ROC AUC (needs the raw probability or score, not just a hard prediction)\n",
    "auc = roc_auc_score(participant_labels, participant_scores)\n",
    "print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "# 5. Average Precision (also uses the raw score)\n",
    "avg_prec = average_precision_score(participant_labels, participant_scores)\n",
    "print(f\"Avg Precision: {avg_prec:.3f}\")\n",
    "\n",
    "# 6. Classification report (includes precision, recall, f1 for each class)\n",
    "report = classification_report(participant_labels, participant_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[21  8]\n",
      " [ 7 16]]\n",
      "Accuracy:    0.712\n",
      "Precision:   0.667\n",
      "Recall:      0.696\n",
      "Specificity: 0.724\n",
      "F1 Score:    0.681\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example confusion matrices (replace with your actual data)\n",
    "# all_conf = [\n",
    "#     [[22, 7],\n",
    "#      [4, 32]],\n",
    "#     # Add more confusion matrices if needed\n",
    "# ]\n",
    "\n",
    "# Sum the confusion matrices\n",
    "cm = np.sum(np.array(all_conf), axis=0)\n",
    "\n",
    "# Unpack the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (tp + tn) / cm.sum()\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0        # a.k.a. Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Accuracy:    {accuracy:.3f}\")\n",
    "print(f\"Precision:   {precision:.3f}\")\n",
    "print(f\"Recall:      {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1 Score:    {f1:.3f}\")\n",
    "\n",
    "# Define class labels\n",
    "labels = ['CN', \"FTD\"]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    annot_kws={\"size\": 16}  # Increase annotation font size here\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
